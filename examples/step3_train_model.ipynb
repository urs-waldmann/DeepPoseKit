{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jgraving/deepposekit/blob/master/examples/step3_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPoseKit Step 3 - Train a model\n",
    "\n",
    "This is step 3 of the example notebooks for using DeepPoseKit. This notebook shows you how to use your annotated data to train a deep learning model applying data augmentation and using callbacks for logging the training process and saving the best model during training.\n",
    "\n",
    "**NOTE**: If you run into problems, you can help us improve DeepPoseKit by [opening an issue](https://github.com/jgraving/deepposekit/issues/new) or [submitting a pull request](https://help.github.com/en/articles/creating-a-pull-request-from-a-fork)\n",
    "\n",
    "**If you're using Colab**: make sure to go to the “Runtime” dropdown menu, select “Change runtime type” and select `GPU` in the \"Hardware accelerator\" drop-down menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already installed DeepPoseKit you can run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U deepposekit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from deepposekit.io import TrainingGenerator, DataGenerator\n",
    "from deepposekit.augment import FlipAxis\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "from deepposekit.models import (StackedDenseNet,\n",
    "                                DeepLabCut,\n",
    "                                StackedHourglass,\n",
    "                                LEAP)\n",
    "from deepposekit.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from deepposekit.callbacks import Logger, ModelCheckpoint\n",
    "\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "HOME = expanduser(\"~\") if not IN_COLAB else '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few example datasets to choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set_merged_3.h5',\n",
       " '/home/urs/Documents/programming/my_data_spider/spider_annotation_set.h5',\n",
       " '/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set_merged_2.h5',\n",
       " '/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set_merged.h5',\n",
       " '/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(HOME + '/Documents/programming/my_data_spider/*annotation*.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a `DataGenerator`\n",
    "This creates a `DataGenerator` for loading annotated data. You can also look at the doc string for more explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'annotated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Creates a data generator for accessing an annotation set.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "datapath : str\n",
       "    The path to the annotations file. Must be .h5\n",
       "    e.g. '/path/to/file.h5'\n",
       "dataset : str\n",
       "    The key for the image dataset in the annotations file.\n",
       "    e.g. 'images'\n",
       "mode : str\n",
       "    The mode for loading and saving data.\n",
       "    Must be 'unannotated', 'annotated', or \"full\"\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Initializes the BaseGenerator class.\n",
       "If graph and swap_index are not defined,\n",
       "they are set to a vector of -1 corresponding\n",
       "to keypoints shape\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/DeepPoseKit/lib/python3.7/site-packages/deepposekit/io/DataGenerator.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/urs/anaconda3/envs/DeepPoseKit/lib/python3.7/site-packages/deepposekit/io/DataGenerator.py:81: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.annotated = np.all(h5file[\"annotated\"].value, axis=1)\n"
     ]
    }
   ],
   "source": [
    "data_generator = DataGenerator(HOME + '/Documents/programming/my_data_spider/spider_cropped_annotation_set_merged_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing the generator, e.g. `data_generator[0]` returns an image-keypoints pair, which you can then visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, keypoints = data_generator[0]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "image = image[0] if image.shape[-1] is 3 else image[0, ..., 0]\n",
    "cmap = None if image.shape[-1] is 3 else 'gray'\n",
    "plt.imshow(image, cmap=cmap, interpolation='none')\n",
    "for idx, jdx in enumerate(data_generator.graph):\n",
    "    if jdx > -1:\n",
    "        plt.plot(\n",
    "            [keypoints[0, idx, 0], keypoints[0, jdx, 0]],\n",
    "            [keypoints[0, idx, 1], keypoints[0, jdx, 1]],\n",
    "            'r-'\n",
    "        )\n",
    "plt.scatter(keypoints[0, :, 0], keypoints[0, :, 1], c=np.arange(data_generator.keypoints_shape[0]), s=50, cmap=plt.cm.hsv, zorder=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an augmentation pipeline\n",
    "DeepPoseKit works with augmenters from the [imgaug package](https://github.com/aleju/imgaug).\n",
    "This is a short example using spatial augmentations with axis flipping and affine transforms\n",
    "See https://github.com/aleju/imgaug for more documentation on augmenters.\n",
    "\n",
    "`deepposekit.augment.FlipAxis` takes the `DataGenerator` as an argument to get the keypoint swapping information defined in the annotation set. When the images are mirrored keypoints for left and right sides are swapped to avoid \"confusing\" the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/urs/anaconda3/envs/DeepPoseKit/lib/python3.7/site-packages/imgaug/augmenters/flip.py:986: DeprecationWarning: The parameter `deterministic` is deprecated in `imgaug.augmenters.meta.Augmenter`. Use `.to_deterministic()` to switch into deterministic mode.\n",
      "  random_state=random_state, deterministic=deterministic)\n"
     ]
    }
   ],
   "source": [
    "augmenter = []\n",
    "\n",
    "augmenter.append(FlipAxis(data_generator, axis=0))  # flip image up-down\n",
    "augmenter.append(FlipAxis(data_generator, axis=1))  # flip image left-right \n",
    "\n",
    "sometimes = []\n",
    "sometimes.append(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "                            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                            shear=(-8, 8),\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL,\n",
    "                            mode=ia.ALL)\n",
    "                 )\n",
    "sometimes.append(iaa.Affine(scale=(0.8, 1.2),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter.append(iaa.Sometimes(0.75, sometimes))\n",
    "augmenter.append(iaa.Affine(rotate=(-180, 180),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter = iaa.Sequential(augmenter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image-keypoints pair, apply augmentation, visualize it. Rerun this cell to see multiple random augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, keypoints = data_generator[0]\n",
    "image, keypoints = augmenter(images=image, keypoints=keypoints)\n",
    "plt.figure(figsize=(5,5))\n",
    "image = image[0] if image.shape[-1] is 3 else image[0, ..., 0]\n",
    "cmap = None if image.shape[-1] is 3 else 'gray'\n",
    "plt.imshow(image, cmap=cmap, interpolation='none')\n",
    "for idx, jdx in enumerate(data_generator.graph):\n",
    "    if jdx > -1:\n",
    "        plt.plot(\n",
    "            [keypoints[0, idx, 0], keypoints[0, jdx, 0]],\n",
    "            [keypoints[0, idx, 1], keypoints[0, jdx, 1]],\n",
    "            'r-'\n",
    "        )\n",
    "plt.scatter(keypoints[0, :, 0], keypoints[0, :, 1], c=np.arange(data_generator.keypoints_shape[0]), s=50, cmap=plt.cm.hsv, zorder=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a `TrainingGenerator`\n",
    "This creates a `TrainingGenerator` from the `DataGenerator` for training the model with annotated data. The `TrainingGenerator` uses the `DataGenerator` to load image-keypoints pairs and then applies the augmentation and draws the confidence maps for training the model.\n",
    "\n",
    "If you're using `StackedDenseNet`, `StackedHourglass`, or `DeepLabCut` you should set `downsample_factor=2` for 1/4x outputs or `downsample_factor=3` for 1/8x outputs (1/8x is faster). Here it is set to `downsample_factor=3` to maximize speed. If you are using `LEAP` you should set the `downsample_factor=0` for 1x outputs.\n",
    "\n",
    "The `validation_split` argument defines how many training examples to use for validation during training. If your dataset is small (such as initial annotations for active learning), you can set this to `validation_split=0`, which will just use the training set for model fitting. However, when using callbacks, make sure to set `monitor=\"loss\"` instead of `monitor=\"val_loss\"`.\n",
    "\n",
    "Visualizing the outputs in the next section also works best with `downsample_factor=0`.\n",
    "\n",
    "You can also look at the doc string for more explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_train': 9,\n",
       " 'n_validation': 2,\n",
       " 'validation_split': 0.2,\n",
       " 'downsample_factor': 3,\n",
       " 'output_shape': (48, 48),\n",
       " 'n_output_channels': 54,\n",
       " 'shuffle': True,\n",
       " 'sigma': 5,\n",
       " 'output_sigma': 0.625,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 1,\n",
       " 'random_seed': 1,\n",
       " 'augmenter': True,\n",
       " 'datapath': '/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set.h5',\n",
       " 'dataset': 'images',\n",
       " 'generator': 'DataGenerator',\n",
       " 'n_samples': 11,\n",
       " 'image_shape': (384, 384, 3),\n",
       " 'keypoints_shape': (26, 2)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = TrainingGenerator(generator=data_generator,\n",
    "                                    downsample_factor=3,\n",
    "                                    augmenter=augmenter,\n",
    "                                    sigma=5,\n",
    "                                    validation_split=0.2, \n",
    "                                    use_graph=True,\n",
    "                                    random_seed=1,\n",
    "                                    graph_scale=1)\n",
    "train_generator.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the `TrainingGenerator` output\n",
    "This plots the training data output from the `TrainingGenerator` to ensure that the augmentation is working and the confidence maps look good. Rerun this cell to see random augmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAJOCAYAAACum+PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9ebBt2V0e9v323me4977Xk6QWUreMghiCBqQIkBCTSbAZBEbGDgRMyoYCRFK4nEqomKGcGFMeZBcVyg7EQU5AODYWo6LGtJFBGISxJBBiEihQsixQo6ZbavXw3h3O2cPKH2t/a3/rd/Z9775uve7b762v6tY9d5+917T3Pes73+9bv2UhBBQUFBQUFBQUFJwN1VPdgIKCgoKCgoKCpxMKeSooKCgoKCgouAYU8lRQUFBQUFBQcA0o5KmgoKCgoKCg4BpQyFNBQUFBQUFBwTWgkKeCgoKCgoKCgmtAIU8FZ4aZ/Z6ZfcFT3Y6CgoKCAsDMvsDM7nuq23EzonmqG1Dw9EEI4UVPdRsKCgoKzgozewOA+0IIf+upbkvBjYWiPBUUFBQUFMzAzK6rwHC9yy+4fijkqeDMMLMPmNmfM7PvNrOfMLN/YWaXzOx3zeyTzew7zexBM/ugmX2RXPcNZvbe8dz3m9m3uHL/ppndb2YfMrNvMrNgZp84vrcys+81sz82swfM7P80s70nu+8FBQXXF+Pny3ea2e+b2cNm9sNmtpb3v9nM3mdmHzWze8zsueNxM7PvGz97HjWz3zGzF5vZawF8HYC/aWaXzexnxvPT58v49xvM7O+Or7/AzO4zs283sz8F8MPj8S83s98ys0fM7D+Y2addoR9fZGZ/MLbl/zCzXzazbxrf+3oz+9WxvR8F8N1m9gIz+0Uze8jMPmJm/9LMbjvruIznfNvY//vN7Bue+N0ouBoKeSp4vPgLAP4fALcD+E0Ab0F8nu4C8D0AflDOfRDAlwO4BcA3APg+M3s5AJjZlwD4nwD8OQCfCODPunr+IYBPBvCy8f27APyv16VHBQUFTzW+DsAXA3gB4v/93wIAM/uvAPwDAF8N4DkA/gjAG8drvgjA54/n3wbgvwHwUAjh9QD+JYB/FEK4EEL4C2dsw8cBuAPAxwN47fhZ9UMAvgXAMxA/2+4xs5W/0MyeCeAnAXzneO4fAPhsd9orAbwfwJ0A/h4AG/v2XACfCuB5AL77LOMi7b0V8bPxGwH8gJndfsa+FjxOFPJU8HjxKyGEt4QQOgA/AeBZAF4XQmgRP9Sez29PIYSfDSH8xxDxywD+LYDPG8v5agA/HEL4vRDCEYC/wwrMzAB8M4D/MYTw0RDCJQB/H8DXPFmdLCgoeFLx/SGED4YQPopILL52PP51AH4ohPDuEMIGkZy8ysyeD6AFcBHAfw7AQgjvDSHc/wTaMAD42yGETQjhGPEz6AdDCO8MIfQhhB8BsAHwWTPXvhrA74UQfnr8bPwnAP7UnfOhEML/HkLoQgjHIYT3hRB+fqzvwwD+N+x+iTxtXDD2/3tCCG0I4V4AlwF8yhPof8EZUMhTwePFA/L6GMBHQgi9/A0AFwDAzL7UzN4xyu2PIH7APHM857kAPihl6etnAdgH8BujXP4IgJ8bjxcUFNx40P//P0L8fMD4+4/4RgjhMoCHANwVQvhFAN8P4AcAPGBmrzezW55AGz4cQjiRvz8ewLfxM2j8HHqetE2RfZ6FEAIAvxpO+wgzu9PM3mhmf2JmjwH4F5g+H+eu0XEBosrWyd9HGD97C64fCnkquK4Ype2fAvC9AJ4dQrgNwL2IUjUA3A/gbrnkefL6I4hE7EUhhNvGn1tDCOWDoaDgxoT+//8ZAB8aX38IkcQAAMzsADEs9icAEEL4JyGETwfwIsSw1v88nhpm6jhC/FJGfJx731/zQQB/Tz6Dbgsh7IcQ/tVM2dnn2aie3+3O8eX/g/HYp4UQbgHw32L6fCROG5eCpwiFPBVcbywBrAB8GEBnZl+K6FEgfhzAN5jZp5rZPsTPFEIYAPwzRI/UnQBgZneZ2Rc/aa0vKCh4MvGtZna3md0B4LsA/Nh4/EcRPydeNn4h+/sA3hlC+ICZfaaZvdLMFgAOAZwAoAr+AIBPcHX8FoC/Ymb16Ln0ITKPfwbgvxvrMDM7MLMvM7OLM+f+LICXmNlftLiS7luxS848LiKG2h4xs7swET/FaeNS8BShkKeC64rRp/Q3EEnSwwD+CoB75P1/g+gL+HcA3gfg7eNbm/H3t4/H3zFK2r+AEs8vKLhR8aOInsj3jz9/FwBCCG8F8L8gqtj3Ixqn6X28BZHgPIwY0noIUekGgP8bwAvHcNv/Ox77HxAXvDyC6KXi8VmEEN6F6Hv6/rGO9wH4+lPO/QiArwLwj8Z2vBDAuzB9ns3h7wB4OYBHEcnXT8+cMzsuBU8dLIZkCwrOB8zsUwG8B8DKxfELCgpuYJjZBwB8UwjhF57qtnysYGYVoufp60II/+5xlvEB3GDjciOgKE8FTznM7CvNbDkur/2HAH6mEKeCgoKnI8zsi83stjG8+F2I/qV3PMXNKvgYo5CngvOAb0H0RP1HRK/Cf//UNqegoKDgceNViJ9lH0EMD/7FMeVBwQ2E6xa2G414/xhADeD/CiG87rpUVFBQUFBQUFDwJOK6kCczqwH8IYA/jxjv/XUAXxtC+P2PeWUFBQUFBQUFBU8irtemhK8A8L4QwvsBwMzeCOA1AGbJ0x3r28JdB8+5Tk0peDx4eO9Sem1miOlKgNPItp5zVoQQTi3vtDrmjrGcubL4vr/+tP5cqQ9ajl7Ha/zxEMJVx22unb6uqqquaZyGYdgpw8xw29GTnx7rTw7vx0dPHrm2B+Mc4FqV86WtwhoHT0rbCgoKnjyc4BDbsNn5DLte5Oku5BlR70PczyfB4qaNrwWA5x58HN786h++Tk0puBb8wuf9Dvq+x2azQdd1CCGgqio0TYOqqrKJme+ZGRaLRZqkeU7f96jrGsAuWWHZbdtm9TdNk5U/DEOqg+Xwb/7uug7b7TadCyC1ta5r9H2fHZvrC9tZ13VGZHht3/foui6dw7p4vpmlujabaVUyy2U9wzCka7V+T9p4zmKxwHK5xDAMaUy0fZ6gmRlOTk7QtT2GMeH7YrFAVVX4y7/zeXiy8Zp7n357lI7K+Q9AlHMzu+dKyvkaB3ilfeGT1cSCgoInCe8Mb509fr3I09w3zeyr87hp4+sB4CXP+NSSL+EpwM9/7m8nAhBCSARBJ+6u6xIBIFkilJjoxE5ipERBrxuGIdUzRwqUcCmZ6fseTdNgGIZEGJqmSe03MzRNk9rJOheLRXqfx5SUkWTxmhACwoDUPo+2bTMyt1rF/UFJOLuuywiNjhPbyP6TeHkyxLb1fY++77P69Hy2V48vl0sAW0TRBKmsN730P+Arf9vvUVowg2tSzgsKCm4+XC/ydB/ydPJ3o6STPzf4uVe9GwBQhUmdIVFQssCJnq8BZOpO3/dp4lZyoGRICZQSCiVd/rcqVgCysJWSMK/eaLs1jMjfSki0nzyuqlkIk+rk+8++LRaLRNaGYUjlqnrG9wm+JoGaa7u+1v7yPY4N26rjEPc0jT9RQAEMFSqrUNVlce0ZcVXlHMjV83W220dBQcGNjutFnn4dwCeZ2X+GuPfQ1yBmli54kvEzn/HORGY46S6rZUYU2rbNwmQaClJS4UNZWgb/1t/6Wn1JniwoAaIaQ8LVNE1qA1+r2kKsVqtMkVosFuk930aOA8kOyYcSFV7Xdu0OIaRKRcLE95qmScoY69AQHusnaWKfDTOeJpvawPq6rstClnyf4wYAVQWY1Vit9tC2Leq6zgjwva98F179zs9AwRVxVeUcyNXzW+yOop4XFNxEuC7kKYTQmdlfB/AWxNjBD4UQfu961FWQ42df8esApvCPhV2z92azyZQUhr30HA3ReeXEe3VUTVHMmaD1eh4jmSA5AiY1SH1VSnwYbmSokXWroqV+JbYHQKYYKZR8hRBgFbBer5OapMSSobSu69C2beYL43iyfE/M+DK2sRvfq/N2jOOxWCwSSdtsNolIcVzUQxbbNY0dQ5pjqQAsU9MKTkVRzgsKCq6I66U8IYRwL4B7r1f5BTkYiuN2mF4F0olcj7dtm9QTTtRKXLyRWcmNV6nmzvfwHiJvQGfZWt+VFC2qZn7FG71CADJypoRDvVyqgOkYkAyRnPg2+tCajjUJjIYJY3lVauNp46W+MbZVlTlVwgAgRG4EWEhtpddrIrnzHq6CHRTlvKCg4Iq4buSp4PqB6hIghMLNiTqBe3JA5UnDcVRRdBUZMKlBquio+qNQQqEhOm+I3glRISdlahQ3M2y323QOlSANOQKTasS6ttttIic0gus5elzbtdlsMoLJMSFYZtM0aOoFDFUyjKtCpfdBlb3Yv6nP8XzAqlFls6gsWW+oakMIPUKwTEVj/9VTVlcNYCEjtWqUj+pVvrKxYB5FOS8oKLgaCnl6GuHeV74rvphxV6iJW+F9Rjqx+/AbiYGatnlsTiHxipBXhnwoUNukEz/Pn1OWfJupkmk6BAApdBZXmk1hR6/ekDDNtc+H7ebq03AnmgBYQN9PqxNJ/JRsarlUhcxU/ZoI1tAHWT0I8GZn9eo4okI19qVpJsLrz4uIz8ibXvYr+MrfevLTFjydUJTzgoKCK6GQp3OKez79HcnHk9SRfjcBo1eV5kiBN3rPJV2cC7+pcqRhLK8oaY4kNZ1rWMorTz5cp8RG0xNoOXVdJxWK0L/btkXTNFgul9m1zHOkniptJ71EvKaqqkzp4bk0oSsB09AfVSG23ZNDous69H2LxWKBxWKBujY0zTIZx7u+HVUnkl6uhMyTZs6FS0ketW3DMKDvBkwLGCd/VUFBQUHBtaOQp3MGro6jEsQ0AleDhumofKji5MNlSrI03KVhrLn8Qno9f2u4TolcvoQ+b6sqM3PKlrbX+5kIVdlU3Tk5OUlkDEBGepS4MSRHT5SqO5546oo8JbUM7dV1jbZtUw4otkdTLrBsEqbYR0PTLMZ6prFQkurvG8vRYySgcwqhH8e5sGlBQUFBwdlRyNNTiHtf+a4d42+FXVVB4QkRkPua9Py584CoEKkPRxUpvq8Ex2PORK5tIJEgUdFl9YQu11clbC7cRFKn9fjwI987OTnJSNNqtdq5jmbsk5OTTKFiW7Q9PE5Fi/2rqir1EZh8ZCStvG65XKZ2sC/D0KGq9rL2A0BPUzqGnTGOfYrqk4ZX9X4ul8ssQecwDNGXVVfox5UELPtnX/Hr+LJf+8zZ+1tQUFBQcGUU8vQUgCvjapvCXBry8rgSIeJrDa9R/fCKjSaq1NeqFPG3KjkAkrqipOtKipESCL9UfzJKz4e1fHk0Put57OucOkaSw7IXi0V2Xgyb9VmZfd/vJP/Util54zkIhr7r0Q/TNjbEaVnS4+uAEKa+cCw6dECoEBCy8pSUAZZ5u7quS8RM77WZobI8w/gwDBhcOwsKCgoKrh2FPF1n3PvKd+2s6qqrKZSjBEYnfB+uIebUJA3VbbfbjCBpKMeHf3hc96XTUJuZZXvPKekwsxQO07Zqpm0NJZGcqDplFlfPAfM5ong+1SO/sg5A8jf5rOSqNDGM5zOLqz9Is33zPnjCxNdpxVu/SyLN4nYt7A/HgYT28PBwhzTx2ei6DghReQohYLmckltOhGdqE4mihnn1OQpDl4jqtAoP6MPpKRIKCgoKCq6OQp4+hvjXn/lrAHLlxrC7Ik0nf10tpuTJe4eA+QSWJB8hhDRJUmnRcJa2wYfRVHHyS+IJJSP62u9ZpwqYJmtkqEzLYxJHkgCWoe1Tk7fuW6ckk+8pyWA79bjP7K0pF0j66FviZrxVRWI3rdBj7qZ+DIF1HdD1k9rHfmno0m9lQzKoIVJDBRjQ9wO6bouqQtZGoMqUP/Vm6TOSPF3jCsS0cnKICTmbusEwTGNRUFBQUHBtKOTpY4B7Pv0dAIB202ZJFUlmgGkTXVU59DWVGVWJPOnR43N7nikJmVtRx+OngeHD03xK7JdO6Fqeb7OGrk7zSanipP0HdpUZLZ9Eyu+RB+QZxZUk8Rr+qDrE96jCaUbxxYI5p+qM3IYhD/8psfOGe95/biOjpCcMQF0pIUVGLFk3MKmEmkRTx0z9XSRqXdfF58LCqILF1YU/+4p34st+bWfLtoKCgoKCq6CQp8eBn/q0X8kIQbeZvsUztKQG5LqusVqtktIATPl+dFWWhoqA3YmQ52sobs5PxHr5vhIIHtPfvnxVkOgfApDUFCUwWqf3L6lKQvWJvilfhob+vIGdYS8SB5bN66nsaFZxTX1A+PBp27bYbDZYLBaJ7NZ1jcWiTmRWfUfDoAkn+xS6jMRriWZRp9DmdrtNClYscxHvcR99S0099XtABxjQdW1qJ8edRMknK6VS1dRVCvOxnVwR2NZtzDyOaGgPIW45U1VI41lQUFBQcO0o5OmM+IkX/zKAcXKyPMyl5GGxWKTNYElClBSoSqGkhZOeV2l4HonJdrtN6pL3CSnUIK4b4Ppy+aOmYg0LznmmruSX0XNYpxINKiZ+4qZSoykBtJ7lcplIAceNZenGxt6zRHj1KoSYhVwzirO/IUxhVJ+lO7bJ0lY27CvPaZomhf6GYUhtWzT0V40VWci2fWnbNvnVVqvFFcdZ28tnoOvbLJVCeo6qgLqaVDRYXO03t7dfQUFBQcHZUMjTKXjLZ/9mmtAAoJbEglRAOLFS8VAyxHAJJ3ROxlRfvLpExYdqB3/ow2EdZoajo6OkZKxWq6RM+BVfLN+v5PPL6TVBpPYB2N2LDtg1nhMkPmqSrqoqkQKqQToObA+Jia7Q0/N1pZ+SDfX/EJrHiR4wnwKB90fVKjW0m00EjWM0qXcMydXZWLGdi8UCfReJ03IRSVPbxsSXkx+s3gkpRnI59skG0ONU11P7NeRXN9WUTLObyJv60UjsSD5DCOiHDk1TJZJfUFBQUHBtKORJ8K8/89emibC3bGL0S8/9Fh8AZid6rz55NcF/+1cTN8nQaXmQgCnnj/p8WK56hLQdWoaGpbTeOahZXPuuJIOkybe167qMzDAbuBI3T8RUlfPjxXEmEVRlScdqLu2C5q9iPxiKY3vqOg+Z6lhPJmwg7sZbZ+PB9jCDeGo7dp8Feq+m8V+j71vUVZMR4TmVi/dd++OJ9KQmyrhWVJ1KyoKCgoKCx4ObmjzRu5Sw3U0B4Fd7AdNERuWDP5zI6V/SPcZUWZozZOtxVQ68l4XtmstcrSRGjxOZSXlUI3hclS6vpCjhUqKjYUitQ8NRvE7JJw3MJAJKxtSoPdcPVc/YFz2uRnIlcpqp/eTkBABSSI33meMbf4fsGk+42FeqVJ5M+9Bqan/oU8hQyaOOfdM0aJopBUG7He9pMATZ667ve3TtqB42VXa/SPBJCgHAwnhfqylX1L2vfBde/c7PQEFBQUHB2XFTkqcff9EvxUnSffPWCVtVBFUbgIkA0Nei23/wt6oVJBOaOoATvCpDDF8pqSF8ugIf+vMkxCtVOrGrQsZzrpY40ZMZn+Xal6feJO237oOn4+tfe7WJZEF/zxFTQgmc5lHyypgSJvYlkprckK8meo7vpJpNq+smxTBev91ukwoFAEPXp9d675Uw8n2Wt9lsRnI3jg2qlGMqmfCr6V9ZlTQ1t9fj8Gh4ci4sW1BQUFBwZdzw5OlHP+UXsjCHmaGp8lVihA/DaZhLQ1YemnpAfTkawlMFQtUMndj39/fR9/3OMnxvnmaZmu+Ik6/Pf8TJUydw7buSC5bNtrGcOSVIlRKqVppJm33yYao5ksZJnCEo5qniCj2C/jNN66Dbp/g2ahLMYRgywktSa2ZpCxW22YcPASSzu9ZJEhZCbqjXVYjr9TqpScMwoG7yceLKPIY09Z5tNhsg5AQZIYb/tttt9kzyGdPnhs8a/WPpeesAWEhlvOllv4qv/K3P2bkvBQUFBQXzuGHJ0xs/9RcjicFuPiFgV4nRSd5DJ1NPuICJYHCSJpFQ0sMJU1UGTU/Aa/Q8baeqM3qcZcy13597Wp/mxkQzg+u1c6TL1+3brL4l7+PxIcJhGLDZbJJypMktvWKk4645oXyo0LfPe6D85suxnAbAkBYFsD/r9RpHR0fJMzRHWAHAKmDRLDICbWboh5CplV4dy9S1MWlm6lOoMIQuO88ra1U9PTvqQ+u6DoYpYSYspDQGBQUFBQXXhhuCPL3pZb+aJQ/cbrdpdZxOoDrhqheE38rpe+Fyc05MGhJSEsMfTXTJiVxNzHq+enMIbwLWJf6eOKm3RkmWhhm1XBIzT2Q8AeE4qMlYw5XsC8dGw4aaNJPj4XMkaVhMPUmqAGkqA1WLOLbqO1J1BYiq1Hq9znxEGjodhgGr1Qp1XeP4+Di1V8kWx3dSCocsDxX7slisdp4hElmWS68cfyuBCwPSSrd2O+ZwwuhPCkMiVFp33/cY+kmxXO+NmeUxZi8fzeh9GzJFUNF22517D0x74BUUFBQUnA1PS/L0ppf9ajY5+hASQyV8jxOX7rnmwxvA5B+hoVj9NaflGAKmpf6cPE8zQwN5niFVZPjat1F9QgrvCdLf/hw1aysJUM+Vto3jpp4czR2kiTOJYZhCScDk9WL9XmUimESSuZGYx0rDTBwPqlBKeKjg+LQRfisXtp0r/dhmJY/6LMRUEEscHl4a+16PZCTffqaqKuzv7yeix3oj+e6y/kTSUmOwAYClcaUfjgZ21tF226QWVVVMhlnXNaqmSgbxvp88eOyn3+PPP1/Z84gB/TCR0oKCgoKCq+NpQ57e/PK3A8jNzUqMdALUSdsTCyUInKB5XIkLME1KmuNnLkTF38wn5BUnJSnebOxVCR+C07b4c/m+9n2OqGk7NcznCRDr8GFKXXHoxw+YVq35tmubtR0hhEQalNCowqV99yTXh+e4ckzr86sOtUxvvqfKqF4khg77PiCEHmZDluGcIIFi3i0SFBK0xbhqzhM11hdCQDP+GybvnGzVYtJOttuTafaJY+LVTb0nUV0cSXGfPzsFBQUFBWfDuSVPP/mSt6Vv+HVdJ+/SXCiMr/WYhp4IlsWJqeu6LOeQlufVCx+20/xEVLq4mSxNyaxHQ238WxNHArspBZTEzIVhlEBpTii+p54YHyLk+d6Q7okTz1fipJM/+8hJX/dbCyEkQkPDMutSc/Rms8lSPmgyUIKkVlM/sKzVaoWqqrC3t5cpiHqekjJdEadKoh4HIqE6OTmJIeDxXu/v72djOYV9DXVtWK1Wqf00qwPR/zQMQwytDSF7DljOdrtFVVcwy71cYQgpuSZJt8HQ1FFpa4fdnFoaUtXnxS886IdpocNPvuRt+K9/9/NRUFBQUHB1nDvy9JMveRuA079lK/x2Jx7eq+QJgpIiTi6qmihZmfM8KTnRa/3qNK+WkUwoGfFqzZyJfY5EzSlLfnLm+yzPt+UsmCOp+t7ccTVGkwxoiGqufL03WgZX4ZGgqRIITCvx+NqbwJWweXLqx5Fj5EOoWkcsI/dV0UDuE3+GEBCQq2+6cMArabqhNEm+Dw1nzwsq9KFPZNz74nR1IsvUcSgoKCgouDacC/L00OpR/Mgn/JuoJAwrLBYL7O3tAZgmeA2v8QOf5uU54qQhO04cnJQ4MXqjM8tPeXFcVnEf/lBix60+vHpFL46as70HSQmNDx+pUVpVKo6Dz5ukfQ0hJC+REoLlcrmzJJ/t8MRCFTP2yU+6ai7nOarq6H3zZE2JHM9bLpfZ/aaKo2RM28UwG9U8kgxvmFbv01xIUwmJD5UBwOZki67txy1R+mROn+7RaXsedrPPqLaf4xafsz5t8xLPWyIEQ98NsCoazhPRGhUon/DU309/TEkhf37ixb+Mr3rPn91pZ0FBQUFBjidEnszsAwAuAegBdCGEzzCzOwD8GIDnA/gAgK8OITx8tbL8RKd+DRIVKgH6LV0JiA9R+XCWKk96nk4gPM9fM6fScHLTMJ0nV03TZEkd59QgT1aIuT7ybw1JKhljf5QA8BiJD8NknjSot2lubHSi1zp0nHVVnobGvBrnlUWtt65rrNdrHB4e7txfr6hQVVHiyvc0DYT2c26s/ZiT5Db1lFKgbhgOC9kzEq+ZjOmsO7Y1tlFTEpjlewnqKsIpTYJXhgbUDTAMuyQ6hBB3iQHg/o2ycn0Y2B8vKCgoKDgbPhbK038ZQviI/P0dAN4aQnidmX3H+Pe3X6kAJTOcGI6OjpJSpB/2VFaoBNGk7UNVWiavUZWDf3OFlIKTsic2XHHH8jlxUeXQCZvmYlUVgF3viVdBONlzEvbhJTUEszwNFTE0pmOp5E/f13O0XtbD8j2B5N8ktP4clqljZWaZSqj18lySMLZRiZAvz4ewqNbpKkiOu5JmVWJYnt7voRflUJQuWBCVLzf/R1N5N93jAWgWJEg5eYqr9gZJsHma2lWBuaYiSDYBBEvpCWCAGWBWYRg6AJGwxX7mhJ/KnF8koe0oKCgoKLg6rkfY7jUAvmB8/SMAfglXIU/ApAJo/p8pjDG/9xonM51olRipyuP3GGOdOoFqviOvdihhUGjOHDWd++X5rG+OWAH5lhqqRGjdcyZ07ZP2n2V5dUnHza9i09xWPO5DdF6l4D3ha/6eI3h8rcRR+8Fz/LVz9fr35rxbrJcEWUNX2k+v1GkbGSo0WwHGMcyfIV6TxsFqRz5rmFFpmrxOYYhmcm0Ty1R1iQqWMR+TBdRNhRBs1gPGPteimum4st/0cPEar/4WFBQUFMzjiZKnAODfmlkA8IMhhNcDeHYI4X4ACCHcb2Z3zl1oZq8F8FoAuO2227KtJaiukCQwNLNcLtE0TSIfDK34veC88qGTLD1IWSdmJmjNG8T3VA0iTjNva3jRT9Z+0taQFkNq7AdJmVeMVKUhvI9F+6YhIk8+lZCRdCkh0z4p4VFyqfdLlUGep8RUSaX+1nNpLPeqoSe/Ov4T0ZhPFOlDh2qkpnrYrCLhYLi16zqsViu03RZdtx3vUZeFK5sGqCq3wi2MZMym3FB6P6qqQrD5tBWbzSbtZxcVqzD6qya/F1XTXNmcVKe4Fc20ytATYN57EigqhsX3VFBQUHB1PFHy9O09A98AACAASURBVDkhhA+NBOnnzez/O+uFI9F6PQDcfffdgZMAw3Dchyw1dJzMvH/Fh4yAfKm2EiOdSD2B8uqFkiWvDOjE7JfOs2wfQtRwlq62I5Rc+DpPU72UBPnwi1dSlMDMqUk6Xnqu9k2VQB/yOS3sw7pIRpVknUai5u4Px0jbpWE8vUZVFL7HFWuEJ4h6f6gOMmS3XC1w6VKPup5SEXCBwJTMczfhqSeyOubZc2s1AkJStnitbq/iCbFX3aZnbyKRfZ8nzfTP62KxQFVVKdu5/2JQUFBQUDCPJ0SeQggfGn8/aGZvAvAKAA+Y2XNG1ek5AB48S1m6iat+iPPbNVeuaUJDVU68QiJtzFQST3zUA0JypgqMhhGBfCsX3XrDm5aVwLFMPaZExqsq3kRNhYPqyGq1SiqKGtK1fi3fp0PQenUsTiNB2n8dM44p28VyPGlUcqYEk+Oh5EVJhfcvVVXM56Tbv5Bk+PCm3muScJIdDd/5fuzt7aGqDFVtKXdUCAEXLlzAZnMMM8N2u802L47tbxD9TeP2NDZtPQPbDZXyPg/DgLoayU09jdOUkbxC227Sl4ph2F0Zqc9cCDVCiKbz1Wp3AQH7rpnGVfU9jQQXFBQUFEx43OTJzA4AVCGES+PrLwLwPQDuAfDXALxu/P3mM5SVfvMDnmE6ZmvmRKTqD5UIXdYN5JOF5ubRiVUJlZILH6ZTVYOTCydgKgP6jV5VFW/c9oqO/s3rVB3xCo2+rwRLw1GbzQZ932O1Wu3Up2RFy9D2XO0+eSKl3rI5tUoVMH+OkrfVapXeJzmalupPoS6/b56Oga760+MkBz41Be9/225QVTEUvFqtYGYpVQafs8PDw9Hw3ifivks+KoQQt2TpBtm4t57Un+VilZ4jfW5CCECwRLTatk3KkOa3CsHSM+2JE8eSREuzyV9plSqfBX4B+KlP+xX85d/5vCs+CwUFBQU3M56I8vRsAG8aJ+IGwI+GEH7OzH4dwI+b2TcC+GMAX3XWAnWy58S6XC6xWCxwcnKShS30Gn9cJwyfJkC/fc+FeTyBUFWGkyTrIKnR13wPmM/0rGTMh/58//113uekxEnrmctarmV4FYiv6TO6UhhOr/NjqX3zxMyb4H1YEkBSiDQHlS+b/WIZ2kcN601KzHzYlufMET5tM9NQbDab8dxpnz8lZUqC42q4KeRWhxpNE3MyMX2F7tFHMtW2Larasn5QbSJ0Dzv9ksC6VMmjKqnPVCR5bcrWPhcK9atPCwoKCgpyPO5PyRDC+wG8dOb4QwC+8FrLU8VHJz1+sOuGrlLXzuo0fU9DOjyXYTedfFX18YRgu91mE4oSJnpFOGGpUuI9Rf44+6ehNr8fm/dQaXhKJ0z9UdKiREn/nvMXqTmb/ZwjLpz8Nex32v3UEJ7eB9ZJsz9TGFBd8eSJK+W0Lr3vfiyIOeUv9q0Dl/7H523yN9GovdlscHx8jK7rkv8ujskU2poUsGpUoyYf1qOPPDarLpHYcCsfeqe0zTpuSpjNKvT9NgsX8/9FF01QHauqmMKg63J/XF3bqOqGbPsZ3vO+K/vdFRQUFFwJ5+YrpldhgHyFmMIrT+pr4aSjPiYNwfmcUZ7EsC2n1adhQ6+g+BVe+tuX6X1InqAoeTxNFdMJj2VQUfDhMr1GVyGqKsdQD5Ab9xVKvDwR9HVSzdJx8v1lH9q2zepSJY/nzI2hJyaeqMa+ATFv0m56BhKgybvEcOyAo6OjVBav67oBiwVGNSgSJ+/z4j1UQtp1HUId+971LS4cXEwrK4fQJ8O4Ic9B5UNyq9UKXdcl8sU+875FQp/ffw3VsW1sl6pP6f+v2J4KCgoKrohzQ57Uy8MPeSoODz/88I5fRSdSVZAIkinvF1Jy40mY5r0B8hV3rFt9WcMw7Gy/EkLIthDhBKVJHKlacdLzobe5cJQPc3FrGkJJDSdHjokPa2632zRBa8hSfTxqyGYbWIb3HbFu9ntObfK/qeRcKUzo1Seeowkm9d7MlUGljLmZzAybzQZVJQlErc7udd+3eOSRoxS207LjPRxQVSFtKM1FDPRXLRYLHBwcoO97bNtYF+/zdohq5WOXHk3XEDqeDFkTHLvVapX8bBqe5bO73Z6kcqfno5J728OsGclSkymVYQCqkbj/3Gf9Jr7kHf/FzngWFBQUFJwj8jTnUXnPe96D97znPfiKr/iKdB4nIa9QceLzIRzvldEVXQqaZXkeJ/m57UP4N/c2Y52q+syVXVVV8m7xm76ah/0qtTlSxXZpYlBf15XG2JfjPWaqTrD/miJijryql8oTDfpu9J74id+TRq1TCQZ/a1hPt2eZa9PUnpx4chNfhN0UFn3f4/j4OOuvvk+ywhV3mlKA7a+bOibAxAKVTfvseQ+SHy9VKVV90pWHvN57rrbbbaZKxfMqNM2krnXdNt2DHbM65Hkv+TILCgoKTsW5IU9zBukXvehFeOELX5iFyPR9IA+fadhvzhxOguXNzAAyosDydRLzXiMAmcLDSc/nEiI4warxnSujdBWdLiX3oUTWT8Kg9ep7PpymCg/VC07cnhyoWkaiwfOUtHjPjSdjek+VOFC18ve8qqqknqiyxPKVQHhPlPZtKhvg471cLmE2KXzcOy4ShoihDxjFKCyXaxwcHOD4+HgnHMhErWr2bhqqfAExX+yAYYhtWa/XcYwHYKj6TCnjvVGvHQl5Xes9nRYusA+qSrG8CxcujCvz4jgypUU/bjkTx9XQ9wyVRhN8ZZPqm1bdDXm4tqCgoKBgwrkhT8BuvqbTPEj6vlc7VFlSc7emFdDJ0EMVFP3b10soWSGp4eSuRIyKgxKnOf/QXL9VsVFilVQOp9jNjdkuuaiystkGVXp4XDf59R4rLceHUn1bNCeVV9oY0lQC5svX8bySwhiJKL1OudKWqTcjeapqQ0BACFN7uEBBQ48+KSf7sF4vMzUqPguxH4tmiTAEBExZ01k/fziu6/Uafd9juVyirmN4MbZ9IuS60bIS9cViIXtBLkHTeHz24yrBvs/HYbvdwlAB9RQ+7vtxzzwAP/eqd+NL3v5yFBQUFBTkOFfkSSfAyaA77cvlSQZ9Iaq8cHJShcmrO/SMcDLTRIlzE7v+1klbSQZJBVdmeQWH12s+I10FRkWmbdvZJfY68SuRCCGkFWLA5PHRSVJ9XzzOegjtj2+zwpv658aEPiBV0/i+mpUVecLJPB/R3HOh94T99kk3AaBp8hxgw9CNJM0wDLGsNqlh0+bI2+3JqP4sdtQnnsPnar1eJ7ICMBQbVxAeHR3Fa0cipx45es/6vgc3+12v1zg8PEzEj23XPEwsd7lc4uBgb2xTJFVTX2sMQze2s0bbkkwGDIMkyRwmImZm0bRueR6tgoKCgoIc54Y8cQJWsuRVCFVt/DFVg3Ry56TH8Il/X+vgFh6qZOg1qnYpuWEZ3tvDsJwayz15ULXFrwTjub7NBBUoDVFSAVHi5hUeHle/FUFCOZfyYNdHtJt9XMNqJLde+fEeIvZlbvUY3+NvVd+UEGr/IlGeyjG3oS/VQZKnqAAhqT1RBZu2NgkhoKkXE2lqJgI0efACFotVuo80xCNY2otxsVhkIc7VaoXtdovNyRYB0eDNFXhVVWFvb4UQDOSIes/29/cxDEPyZk0Z+muEkCt0+eKD6fmp6xqocrWQ5ZdcTwUFBQWn49x8QnozrCdPwG7GalWDVIVQA7GusPOqiU62fkKfaw/L0Ime2aB9/T60o+1VcqKERr07SnpYjrZnThXy5mvCpybQ8nRs1ISuZXkypePH30qCSPp8mEtDfjrW3hjvDdwAMlO2lulVrGm8DdHfM/nDWNf0DHCVoaXXqvSQCAIxvcDB6sLY8ZAIjTezJ7/WABgq2LjnnSFXD7P+WQDCpOpRTY1tyUOpPIfPXtf1qV/x2Wx3lEbFzhePMKq24BeIPiXxLCgoKCiYx7khT5pawK9G4t+XLl3CxYsXEyHy4S0f1lMTtyZV5MSh3iGt25MsJS46sc8l6KRHyE9cXp2hCuWzgavqpMZpVXyoeDBMowREyRfboeZiHSNNqcAJlwkrtS2nhXA8aaXSpH3xm9v6MKgqenpc61U1ktCQoIbQ1JweFZ/pXvJ+0ftT1wztNYkgcmVcVVXo+jZTy4aBex/m2+1E83Wb97tvgRC3eaH66H1mEUMK5dZVM21DVAGRAE7jGAZJ0tp3sEr7NHmc+Mz7xQSaGHS6aUgKnNm04pV9ufeV78Kr3/kZs/e/oKCg4GbFuSBP/hu5V1z44a+r3ryao0SJZam/JFuWLXUqUdCcSyzbm3NPm/T5HokI26OKB8kD2+OTYWpZPreUHy9P5OaUKPqI9BwlbIQnrPxbVSxVcLQ8P75KYrUc9s+rh57w6X1n26hi+WeEBFSfCVUIWf5uO6f7W9c1DBUqs6jCVBPZ9vdVx2uun7rfIjDlKdP7xvKGYSKVZgPqegGDPL9h13u2Q0BRgSsHaW7nWA3D9ExMimK+atMrjJGs8f7W2TgWFBQUFEw4F+SJUIWFm6EC00S6t7eXQimZWlBNSQBJFvhNnERDFZorEQA1lutk5xNsKjj5eFKSQj6jiZx9o5mak90cmVAyR8+M1k0vEXMN8VolidoXHWPv2/L5rXwKhrm+8nziNBP4aWFWkh++z21wlFD60JGuLKSaw7oBpDEeooEJozaVyjs5GTeJDoYQgGax2Gk323J4eIi6rrG3v876GNsORAIWyYZ/rvj8Nk2DRROVuLjaLm7vYjZ5q+IKxACgx9CPxnULCN3o60KF5WqBumrQ1NHQnbZ0MUNlFYAGTWPjeFUIwRDCgOPjTQrHAlPKDe0Ln2uSub7n/yDQNBVclLGgoKCgAOeIPPlwzmq12knUqEvdl8slNptNpjzw+hBCtn2FqiK6YsljTkFR7w4nfeJK6pCGAJUMKLlTBckrAV5h03MZpmI/u65Ly+R141jfLlW/SMwUmgxT6/J+MH/sSuOo90T76UNyvo/efK+o62kFHc8/Pj7OFcuZNtObVlfT/fR+roBo/tZwo5K+vE+8Vzlx5viyfXk7oqHbP5tJARpigsoQQvRNVciId99Nz66qRj731FwYdA7T/8SkqHKMY1vLPncFBQUFHueGPPHDfrlcJqWFyRz95NX3Pfb39xOxAvLl8N7LpNcCEzHSrWD4voYDSdI4MZGYaJiJ9Skx4/VqVOY1qqZ5bxehoScNF7KMg4ODzNhsZjg6OtpZrcc2zIUqvRdpTu3RydmH1MymPFYkYnovqL4wjYInTaxTx4iKHO+/v3dUnpSokFjTN6QqlN4LIBJyw2S4rmoSzLy/Q+iwf7CHvhvSFixMAVFVeYJWtl3bxc2E+25ACJuJ0K8WoxkbAGK9wwAsFkK8EDN96z0fuoDepr5wVSjvlRIofbY0VKrjmF6HMb/VMCbKNPqiKjTNMhHOGxVm9kMAvhzAgyGEF4/H7gDwYwCeD+ADAL46hPDwU9XGgqc5rvLlJUOReZ9WODeGBlVe1Dui36Q5aVOBoklYwSzWfd9ju91mk8hc2I4TPYmKEioFjdd+5Za2X0kLkCs9nIBVJdPwmCdmrFOJ2pzvxvuTSFA0W7QnhEqW9G8/uapXy/vDtJ3eT6aqGYmQHtP2UNkjafYh0zkoaSFRnlPpvI+Mz09Vx7xL/tnR5wsAmsV0v+q6xnLZZPm0/BYzyaCNKm37wjau91aZQX+xWGCxWO0SRQzpWiXMTH8Qn+kOXbfNjlF99Irf3P3S+8uxnFv8wMUDP/3St516L57meAOAL3HHvgPAW0MInwTgrePfBQUFBRnOhfKkH+LANDly8vUTiZIPKh40xZI0EZzYNGmmN97qknofkuJ7JycnqTz9Nk7VQckFJ28qA6oeqe+E53qQUHBy90v+qWxwAtfwoV+FpiuxvBJzGmFSIqDk5LQxmoOa4nm9qlUcQw0fnla2EqM5cuXvq9a3O8YBy7pBqKb+aKhUx0AV0HgfptWfzP4d2zUldI33fiKRe/vrjDCqUqXPgapZIfTot30KL8atUqJfyiuq8TlpoqpmuxtGa1oNraeqKgx9QN8F9NamJJ6xbTFJaPR/bZIp/UZDCOFtZvZ8d/g1AL5gfP0jAH4JwLc/aY0qKCh4WuDcfyp6YkUFyG+BAuTLtr3nQ43IhE4o/j0/2QHTN3E1UquKogqNV3f0t54/Z8iem1QJJYN+6xANcc5Nlto373dS5Y/l6fmeaHkC6P+mmuGJmqakmAvHnqUPGor0fQCQEUV9r4b4wNw4+/FtmiYzsEeP2ZT8UtXRlLxzmMaGPzqOfJY5Xvwd80zFEB5DquqZ0/6rLw0AmmaJuq5TiJvj6Ikw70lOuMewt9kYspu7r5GY/vRL/z3+0m9/7s543YB4dgjhfgAIIdxvZneedqKZvRbAawFgjf0nqXkFBQXnAeeGPKlxWsMuOqGSNPjd4wmqAd5Izolq7tu+TmKeIACTd0bJCqEr8Ng2TlCsj+exj3MkjiqVkoO5iZ1KlqprfiUiJ3wlDyxPs1vTw+VDmZrNm+Xybw1N6pipsqIEgePl/VyaFZ1t4LVatl/hOPmO5k3/6V4OAXAZ0tPrIKTMkUj1jMXNfrukOkXi3I9bp1TYbDYscRqHuhpX8oUUhoTFZ4qbDGt7Yj8D6ppepYCqiqG9RbNEwBRu22yOQS+SEvblIipOcXPffCse9aTpsSkcizF8OWbVrxiCraBZyllGQY4QwusBvB4AbrE7imGloOAmwrkhTww7eB8NkCsSJDEAcHR0lJ1HVcD7efibYRgNnan6o8RAlRgep9dKv8UzVMbfqtqw3MVikZa+z9XlSZOGoeb6AyCFKjVEqWSN5XOFmRJQfY8TKt/jhrg+Mzfr9+EwbZOSO+0/oURLQ7AkIxquVfKr3i0lcDpu6TnoB6AyVAAGm/xFyRs2TKqgDVPITtWzGK7qMAwd2jaGPGnI7/s2jQXN5tG/tEjX9v2YmqBvhcAYzJrUjuihWsIsIAQ+8z2ACvt7B7GOyoV860UK2fIYx2uz2STyw/5xzEhQlahmyqnFFYPDwNQZcZPkEKaNjCN5uynwgJk9Z1SdngPgwae6QQVPD9S33bp78NnP2jlk21MWYcwdXy13DoXDo51j/Ycf2r126HePFXzMcC7IEyfIK/lovCkZiD6k5XKZQkGqtngliyEjnzSS0HLVY6WmX05GGo5Ss7kP0/F9qmRUl3zITPs/pzjNpUTwXiW2Sb1fwESelITMKU2qhpAIMJcUj2sIyBMrDRXNhTUJTdWgZMyPAcfVn+PJp3/tSbGqNP5ee0O5EkuCySe3223yIwFqGM89dSRGamiPz0eFplmkveumtjjPFau3mEdqGAYMfcBiXP3GMfX/K9Nz3e0Y6DVbvVnAMGj2+LjIR5XCabPtGiFsEdW1m0Z5ugfAXwPwuvH3m5/a5hQUFJxHnAvypOTDT8KcBHR1GdH3PY6PjzNjMsvz3hBeq+Euns+9vHRLCw3hqTrE11Q0VHlRgqe5oXTJ+Fz+Il0ZxnZquWy/748qVNvtNoUzNTyp5bDvSgR5Did/qnLr9Tqd69uhYTcgV5xYX9dNIS/v/SF8CHCOOCqJOi2cyTJqRC9TIk5WAcHlkqoMNio9vRjVm4Z+IU31UGO73aSwagiTX4mrPVMCU6vH1ARAHyaTvd6jrtumZ73vBvSdKmgjAY45MmEQRa/ts1ChJlhl+W23TeM+KavDmEy2Ax+d4DKX931IatqUMHNA2zJse5BSSNxoMLN/hWgOf6aZ3QfgbyOSph83s28E8McAvuqpa2FBQcF5xbkgT56o6A+TY+qKLDUd8xpvHNeQhtajypFXawj6clifKkLexMu/tQxPfLTcuT7740pMtP1z6pambWA5vt96vieV+p7/rQoT/2ablOBpGI7XKxHz5EhN2Zr9WsNxqjqp2qT+HQ1RAUA/Jqu0ft5b5ts4plNKxCLWl/d5Wr2W50yq6xr7+xcSOVY1D5j6O5EOlgtUVqNZVkkNZb+oNrGtfd8jDEgePpIYlmtm4yq5uJ0L1bG6jhnU+Wwzoap60PwXkUnVanZWZfLe3PPp78BX/MZn4UZBCOFrT3nrC5/UhhQUFDztcC7IE5f/e2WBExBXufFHN4r15IbX6eSpky6hySppCFdVigTE/1ZViiqPhqB8m+b8Qd47NJeNWseGYTQqD15d4morIIYyT/NJrdfrHVVNPVtzXqjlcpmFofyWKaxDPUlsk5brQ5meMF66dAkXLkQywvo0a7aqY2wj+8KyVOXRFZrtkIexliOZAIAe0ziwvL6fyiMBPDg4wGazwTB0Wb6mymoYcrKN0QdVVVUKfU7PYpfSAvB9PkN1M43LMAxot3FbH0ONLkzEh6HV6FcKKbTIBRR93yX1k6pZ1w1YrdZjO7psDOP/CtMgTOk3OJa8t/v7ZUVZQUFBAXBOyBOA9OGvyoCqTapEzZEMT0qUtGTbb4TccKxhNMIrV/o3r9PJXcv27fHGcCWBLMuTKlXhgCknEtUt/uhGyZzQOZHyep7HCdCrSBrC4d/eC6TtVYKoyo+qIdo2xVwokuWv12scHR0lFW+xWODk5GRnP7btdgszS3vh6b2hYrjdbrG/Widy0IWJ+LZti3o5JRKN24+QnMUM201TJdP8YrFIyVFXqxX6PvedhTBk91bvdVpxBySvU8rBFCxlXuc41s3Yxm2XxpT/E12b58JaLBbjarwpLLpY1BgGw8lJm76QTPdpUglJ1nJzfpPuP1Ml8H6ynX3f462f/7v4wre9BAUFNzVm7AN2cLBzbHvnxZ1j9cnuF1AACDOOhKO7dr+w1Nvd+W//V052jvWPPTZbT8HHBlclT3YNWxhYnFX+MYBXAzgC8PUhhHefpSG63YgPt2iYbY446aTsl7cTcyGcabf5ea+NXsd6OZlNptppcvH7tGnOKQ1V6eTL33MGa80rpZOZkkEqTjymJMqTGm2fhsToR1KFj8qRJ3oMD2pKAw2t8hz2UYmcEjhVzXRVWNd12Gw2iayQSOk9myPWvEfJCL+d+tIOfUrh0LYtHu0fRRWAC7deiHWEgGGzQd+HpD7WdY2mXowG7oncMiklxyPWGbc6oRoUQsAtt1zMxlzDwxyLro8KX9uOxzfTs1PXNdbr9USqISvlbBzDcauYuFJ12gMyhJiug5sP1/Ui9V/9Y1Ty2K71eo3FYoG9vb2UFFafV587q6CgoOBmxVm2Z3kDzr6FwZcC+KTx57UA/ulZGjGnUBCnEYy5kNjc6iwlG3PK1BxxUqKlSgzbEL/lL1IiRU7+PKaTqPph+LfmE/K+Hd9GKgM6+bEObmeiZuzFYpHSPvh+a311XafrtX6Or6ZVUGj4ktcn07QjnCQ7SqC0v57Q+npU1QKQ9VXHgu/rKkEljdW4mozhyEuXLuGxxx5z42+zKiT/ppq2XK5ntwXiuAHAcrVLMElGNa0Ff5TM8Fw+U5r2IvqiBsBG8hmmcKmW1TRLrFYrNM2UeVzbyOd2b28v+x/SsK3+TxUUFBQU5Liq8hSubQuD1wD45yHOPu8ws9tszJlyhnoQQsDJyUmmJvitNqhwaJhJVx1RiVEviZmlBJq8Zg4kBbodChUkTk77+/uzHioNLSYD8HhcN8fVMKKSHg3B6WTNdgGTujTnGVIySDWC48c+6zhq+6dl7JMy5k3FOt4kJkoGAGReNKqEOuaeCPM6kgYlnVT3ONmzHVRjNMxJ1HWd8kWhn+7BMAwYbHqWDg4OcPnyZZycbNM4h3qRrg+jpwgWFaWqnp5Hhgp1dadZ9DkFDGnj4cuXL08K0+hR037RC8Xw3jAMWC5jmoFFs8yekzhWUVFaVnUqY9fbhhSeq+sFbr31dgzDkOXQUiLLNqlnLgvtDhPB5z0tZKqgoKDg8XueTtvC4C4AH5Tz7huP7ZAnk60NbrvttjQJ6JYjubdkmoRVgeIHPVUH9SHpBz3zLJHYaChNJyDW583PnMin/D5ZX1LbWC+/vTOkpd4mDyUSSnJYLtMGeMXG+62U6Khi5UNcPmzI116R8wqc1sfzeIx1nuZHY/lKoK4UBvLKIMd8Lj+ULjTQcJS2t6qrRHwuXLiQyIDZemdsVMXhEJBIHh0dpWeB9amiBpuW+YcQw4Aaqlwu830UdQxJHuuqzssEAAtomqlP6kPSxLH5qj9kYUN/L3TvxZjEc3quzQxN3WTkiR6qgoKCgpsdH2vD+Nwn62xsJsjWBnfffXcgsQGQTfZyfubR8Uu2p81bm2wC0ZAOl2xPXpA6IyT8m6ZknYA1lALsepMA4Pj4OLVfSYpe58ka9yTTPdM0tLJcLtNv1nNycpIROPVWcdJVbwsneNahRMGTMR+qYT1KXgg1n/uy/LVKjlmOEiSGlzabTeqnhjk1PKpkSQkqJ/e0bc8wqYADLO5t19Q4PjrBdtPiwsHFRIzZjr29vUS+QggIiHvW1XUdlSUzDH3A0PcADEPos37H39xDbpk9D6rUxXEcoFyT49n1kml4/BfQ55hjrXm7VB3ivWTqAv49taXPnsOU9kCURvYXYSJc/B9788vfjte8+1UoKLhpMfMluLv/gZ1jzUMfnbl03q5QzeRSu+XBZ+4cO/mE3azluAHzsJ13PF7ydNoWBvcBeJ6cdzeAD52lQJ2055a2p1AKJpXJv/Zhrbn0B3qNV15YNydfTiS6SSxz7iyXSxwfH6dJCsi9ItovJRfey0Tio8ZyJVEkB8fHx5nhm+fr9izaF00AqiSFYSRVJ9RHxOu1nQq9Rwq2m9eQLKiZfo5sqcrDNmQT+DhxM/S5Wq12lCyOl27jE0JAMGCI8TSYxbQEhkiQUnLVqonG8DHdAD1jzLGkpDqM3wPabouhn8LKVZ2HD/f2puSgOq4A0G67tN+dfwY9/HPLewcgJUT1qpuqoD4Zqj5PXP0X0GO5WCMEQ9Pk+zRqOogY2ltkCmdBQUHBzYrHa2DgJwDfAwAAIABJREFUFgZAvoXBPQD+qkV8FoBHz+J3IvhB7RUGKjH0ivC4V4YILtc/zZzsjeWsW98nuVFfEHMobTYbHB4eom1bbLdbtG2bqSU+NOZDYJyAuq7LiJOOA0ESqFvQcAIchiEtpdf91ebG1f+m6ZzK1lwGcNY/V5YfJx8upZn8NLLF83SMdexU6WN5nsjpvVVvl5LQOXLCcVc10N8DEqc5FVNDWcMwoGv7tCqQXru6zrPPI1gq0/+cBRnhCdN2PKeF0fpuAILBkKdQqGvD/v5+aqchz6ml7eIzGu/FdM+qqsJbPvs3ztTugoKCghsRZ0lVcC1bGNyLmKbgfYipCr7hLI1Q06wSDz9RU/3RMA6/fevKJs32TfXJf0O/2jd+NS77SVQneW/CDSEkM7BXwnyd+q3eEw+C267wPE506q8iAfH7pnEs2Jf1ep2dr6E27//Sced4+FQRSkCpDKoyoa+Z4kBDeOrV4d9aJzCFlJTckWBr+NOTqOgdatA00lcMAGI79/f3cXQ0bbDJHEuJzI7dTB63Mfs3iR3QY3MyJVUNA2CosFg0CAHounba1iRMquMwhszaNuYlaJplFmbVPuq9IImZFDyqs1whJypTmO4HgJSUM5477b8HxO1XNHTJLwQ69nt7q9lnt6CgoOBmxVlW2515C4MQP2G/9fE0xH+712/VDD3pCiVCyQ3DQ/pNW9/ndT5k4icGJSpajxI3HyKicqHqma5mokrE0J62jyRCV9zp5KT5l1Ql8e1WP5KqJKyL4zCZoXMfkg836nh4c7f3cGl7MqO2rMRTouX9bdp+JVieyGrbfP813FtV4yZx0gerovrjSZtXW2IZeeqLgFwZrOsaVR0zjPNYs4ivT05O0vOx3W5hmPZatIrP1wJtu8nCtXpfvIdM7wGfFWA6ls4bgBDm1cKqmlYfxjrqnedNV0ly7LMVeGdUygoKCgpuZJyLDOOczDSJn4ZuSCp8igIAWbhMiYmfYHXymSMowPyeapy4VRli21RdoqGbBnD1+5D4mcXcSF3XZWE4hbZpu90m0sfQHZUp9oveFuZTorrkyReAZJRXBY/jyrr9SkI/aer46yqy08CxpFrmCR7HZLvd7qhMc6v7fDhUQ028D/q3GVBV+bOgoT3eq6EfEDDkpGoA9vb2dvrE8T04OEjPxtBPhvyULmEsg+M6hB6ho+q2uz+jhpnj1jjcXDoqTCEAIfTjPd1kY5D2xMMAKmSJxFdROTObQnHDEMeFyhrDw0dHR+m55rOx3U4bC+sWLgUFBYJhd/XwcHL2xLJz/1F26fLuec2du+etlmeu50nB3Jxwg31mnAvyBEzf/v3KtGlyyM9TwzQnJ4Y1eJ7itCX0flL2q+mUTHhVgBM3Q4iaL4fXaniN1zCE1XVdOl9DWp5Q6d9zq/b88nSdVHV1F/vIMaJKp+FAr8YpadX+n7Z6UMddCaqG/liGeqVIDPU6LYvXeEVGy2b4lyRG7+t0cgxfMpM5xy+EgCHkPqlhGNAPix2irc/o1L4ewzC1S8kpFSd9DoYhbgWj3itVv9SAz49VPdc/VzFU2CUiN6emxnMGRKujkOIwKWsantVnn5s4x9QLzU75BQUFBTcTzgV50smUEz6AbAm5TmhqtOYEw8nGT0R6nYYf1I+k4TI97okbj+nqLhIis7jc3puk9bWqJlQ0lKxwgiKBUlKkPij1/6hyoxMeiRDb49UqVenSHnBCPHUslLDMhUznSJP+piroFS71XnlVUO+VHo9KyDYju1T2WF5VVUll02cMIa6867po/ufiAzWLR/LSIQRLqys5xlTsFNonXZ3J8C4QvVAM103XRcJlFlMfaIhxCvmOqQtEDeMKT95XJVGx3DqaxTGRLaqRMVdUk1aUdl2XEnIeHR2lZ4h90LD0ZtOOz/MUsr7n09+Br/iNz0JBQUHBzYZzQZ6UkKgx/DSPi//tfT06watqo6oHJ7ekDIh6wTrVZ3RaaIrHuWLN+4Y0PMS2nqaqqBKmZfix0HP1fYY+59qvdRFsExWSuXN9CJDHvTLhx8P3NW2IizwFgYZJ9cd7zpQM+zq8h4u/vUrD333fY29vD4eHhynMqooT967zhHV39WCuZmqOMZZFAuWJvB8rmrzrZjdUqV47zQYf31ug67bJUwYEDH2eEy0pipanBOGXE5rQfe4t/a3eLP/8FhQUFNxsOBfkCYhZtJnHR71GCqpOOjnyw1yVC/WPKLzKo3ug6ZYsPMeTNq2DyokuqdewCzCZpHU14JVW3XHy8pOYqnLaHt00d7VaYblcZirKFCIadvpFcqJhSprafWhsjtT540qAtV+6LQgVHD/OIYSU2kAVJio4bH/TNMkbNXePqKAAE+HwocAuBFjToBvVtrquUTcVhrZHCFM9TI2gixQ0UjcMhhCaLL8Uw7FUx7Rd2+0W7XZ6dn0C0WEYUDeVI+C58lZVDS5cuAXARHyojh0eXhJSFu/7wcGBJPeMxwm9z7CQVgsijESxagALqKxG13aTKjqMhNDi4oySMLOgoOBmxLkgT5ywdCLhBMrJR0nTnE9kziczDENKqqhZozkxrtfrUxUlT5g8gdDQCc/jhM12UyVQIqir9JTE6I+uOlOlgMe3220Kq6iactoKOPUkqcLkQ5RKSjzp4vVzpn1ew1QJSkQZYtV7UlVTskdv0GfdfoUhnwGWrYoOABwdHaWxoxql/jOSBIMlNWYTAo6PjzM/UlVV6ZkBJgK83Z4kAsFyDw+PMm+SEi+2uaqiT9IsJudkklXdQoaJNqfniGrilJqAY35wcABgIk8PP/wwn0iEMCCEAXVtWK2Wscyxzxx7Tb7K54ehSQ2Tx0EzwJDtMcjnsu22yfReUFBwnTAzPw2LmTlrLsP43Nx2HRTj+vbbd6ueMbB3D35kvoAZo/3TAeeGPHHi1lQAqtYoqZhCFLsTuk72JElzoR2//H2uTRoC1BxHGurjhOJDc564KAlUj5V6btTrdFqozJMijpMSobmQ4Fzf/DG9hv2Y8/j4Y2wz74/m1poz6qtaRJWN46iJIOfaH0LI6vfjAuTbjfD8FEYzoO1DzLdUAVU9PT9qYJ/Uw21qF5+7w8NDVFWVtuNRnxnb75VDeqY4LvwykM61XFHUcqPBeypPN1BWX5YSYxI4Ej69D3wG0xeQYfqcZZ3+f0oJN1d2xvBmyTZeUFBw8+FckCeCk4eai6neqMGZ4ETOJH+7K6Dy8B5JC/dRu9oyew1tsS7WQXM4J0CqCeoNUbXJe69Ypvq1lDjphMVjNEqrUd1nFVelrG3bNIkCuyvPTlOY1P+i98QrWOpnUsM+SaK2xYc31Yysea5URfQhOW0nTe6a8kFDkErIkyI4jiVsUiI3m01KOaD+Ho5DCFP9k2+rwjC06R6yXpKetm1TSLhpuGE1UFmNuppCvym8Z1Ofh2FI6QJixvJ1UoU4dtvtFoeHhzseKI7xVHezmwcqhKS4VlXMQ8XtZWL9PRAm/19d16mOuqnQDxOxOy0rfUFBQcGNjnPz6ec9S7qB7NxWFDqR+hVgCk6Kc6vnlKDMqQUsWzMwX0nhUajyMmeyVdKknigNnelSd1+PEjO9Rjf/5RjqxKvlaFkkbuoj433QcJp6ckhoOGZKJpVEUmmhp0rvE4kVlRiew3HxoTstW8eBxIthN5IHJVgmK8n29/fxp3/6p7j9lluytAJz9zOWNW3yW9d1lvVdVUwNJ+tzZZiUSiWkVVVhGM9p2xZ938qz1yTSz2u4J9/JyUkKH2r9VJ1OU+d07DWUrc+kVbInok0m9rnxudKXj4KCgoIbFeeKPFVVlSY6XYLtFSWdlPieNxH7D3eeqxM8yYGqM1qWguTJtzeEgJOTk3RM2+6Xkfs+eO8TfSWbzSYtJ2eflEBynKjWcGLkBKyTJYmLrthjmWyjD/9piJPv6zY4qhopefIEkXmUWK4mv/RkWENf7JN6uPQ5YHv9fef7GpJifel8AO2Y4+mOW2/F3t5epnjxdw9Ew3Q9Pl9hCoWZRf/SdrtNYWYliFoWn+do5p8IerZqLrBPLQ4PD3H76CEwq9PzyrHr+7hJtJnh+Pg4Iz91XWO5WGG92puIZjegH7qMPHHbGA1F04u1Xu3lY418Sx22QZW9t37+7+IL3/aSnWe8oKCg4EbFuSBPOkn7Zdw6yTKMxg9zXUZPb4cqFAqdTDVPEOuf83d4v42SA1VrODH7UJdiTt3it3tP9JiFfM5PRRKjihDbo/3RutjWOf+SJyIkmN6IzntDVUpVIb+nHevU+6PXeGWPCg7L8vDqjpJmhjF5L/weeKe9HoYBg4TXUn+qCgHRYRRXp5GQ1Vl/4rEmU4XYljmy33UdmnqRZcQHkPa6A2IoOIXI6kUaH1VNqXjp/4mql33fo23bFLILYcxvJW2J2conVVTDosw3NSVsDSmsqKFn/QIy9+WgoKCg4EbGuSBPwHxogQSDE6oagQlOen3fJ9JBeCJGokM/DlUWls3XJCYsnxOHDxtq7qK+75Nx14dxdMJnWEXbxfLZd10ir+SKbez7PqUlIHS8NKWDN3jrJKihUV6rE7WGdXz2cRI6vSfaD817xX6sVqssvKYkV0mHeru0LSRpOm5Ue3SlnT4XcxP7oqqwXixwIt4z9oMjOgwdhiEmzAQqbELA0tWt91633KmqCjWEuIZYfj906PrJH5baM/arbeN+c5tNi4sX12ms+Hy3bYu9vb2svrZtsy1g+nrKvK9G8QA+Sz2Oj1sAm+z5WS1jIs39vYMs5Kv3W599vxDg5z/3t/Hn//1Ld8a6oKDgCUD+D4nmaHd1Wthb7Z733OecuZr+gQd3y5ypGzNhervlws6xzSc8a+fYcrOdrzutGH564VyQJ1U1gFwl0hw6qqR4RYjHs2/RmA+dceLXMJAPP/Ecb7jVMlSdUeLnz1VyoUks/TlzipWWqYSOygKN0wofsvIqlK+TxIFZuoHdzYKVtKpq5I3fLI/n6eo1qjxsh07SJIUsR5UlnquhSL2/2ieqj6qYzbXdk+ek4ADJWD6Ru7DzTKgZm2QmtafrgeVUrvUDekz7CPqFAkpaAeC+++7D8573PDzjGc/YIdZ8hlR5NMvVKa/kxnINVQ30PTKPWd8NKeeZrrRjv/RZyQhTsJ1zCgoKCm4WnAvyBEyrp1QJIFQtOW3y1W/KXvHhMZ18gSlrsk6wdV3Pho4ITjraJi1D1RRPmHzYRwmTrhBT34yWQ2WNKosSKyUBVHmo3HiVwIfMaCjXTXXp51HDvCpOwJRrSVdHKnitJygAcHJykoV91FwfQthR/3SctfzseMhX7y2Xy8x8rs/A/v4+PvzhD6dnpa41NJyTed4yJsHk77nwcGNV5kMDRqI9bply0uaqGseUCustt9yCw8NDPPTQQ8n7xJC0ksG9vb143RgK5D1crVYxIWc3fcsjuRqGWOd6vZfuwXYT1bK9veh1igkzc7LdtpOKyfvY9z227WZs324W+oKCgoIbGeeGPClUdeCEpyuivEcI2FV7CJah6oU/n8c0K7Vex/M5qWs6AT9pKJHyZIntuRLRUiXnNDVKiYr6npJ6Ij4i9tmHHHmtr5PkkL9JgPT8HbXGea+8oVjJJvtMY7v20ZNGVZi03V5FC0PM/UZid5pCyfMZttX7xzHq+370O5mMXdxMl+U1VmEwABjQYXeT4vR3MHT9lEqh73v0w66SqR4zIGbbf/DBBxMppZqmGeU5PiSwXGHX930KDfIZmMK3eQizrmscHIxpDRbxWWGdYZgy+ntinFZQ9qdvK1RQUFBwI+PckCddNacfxDqxe8LjyYsnEfy2rt/wTyNZGgbyYRIN2fiJWcvVEMZisUjJDDk5qpLkQ3xeJfOkj+D4KAHgJKrqgGYnJ7nRjV85tj4ExhVyfH+5XO5k8/bjrfmtlKypx4ztU18Sr9VJmm3SlXmeVKW6x8171Y/G54grFb06qK+7bou2rdF1k6dOxzmMBHC93kdjYwbufsDx8XHyH9V9j62JmdsMoTJUIYb/6nqREUY15/s+sf+33377lErh9tuzfE7qzzIzLFdxrNbrNUIIODy6DCDPwB7Pz3NrsQ3r9TqW2weEEElT3+VZ7nkP+j4mFjXk9zigRzU0+OmXvg1/6bc/HwUFBQU3Os4FeWJICsg3jfXgcf1g914W/42e16haonvOATFkQfOtmq3niJkuo9dwH8vT1VvMw6N1z3leNBym7acBnROVN4mzf96rwglWfV083ytJBNukyoaZ7awmA3Kfi6psfE/vk6pKVHZU9dHM8mry1rHV50FN+QzTxUzhU4gvC5c5LxrHmsv81+t1InexX9xfrsa6qWFNg3os9/DwEMMw4LGHH8Gjly/hmc98JtbrNWoY+rHdKU1CMNgwwKxCGwbUywWWlaEagNBPubiYwsHnZSL+8A//EC94wQuwXu3F+2f5asiqqrBcNBkx021UAODw8FIi8lTQ6rqGocJysUrETlMtEF3XpcSY0XtYy/2rEUKF7XZAF7qsDwUFBdcGm0s6++xd4/VHXrzeObZ63sftHKu63Tm03syLB7f8/OWdY/1jj82eu3virmVje8tuX1a33TJ/fTGMPzF4f4sPq+jE50M7nuj4MBKQL5XXFXa8Tk246hXyYSlvkFXyRuMtv+H7hJJeuSK4kozHdaUckCfUpL9Fy9DzlJD4dvoVaPpbw0PANAHzWg1vebXKt5HQYxpy9aFCNZ57ZYZeNq8c0vA9hB425GPtw52nEfGuG5KCFLcamd4jAR2GAcPYpscOD6O6c3Kceb+2fb7Cs7Jdj1fcEsawWDRAbcl0Tr8Tn0v+3fc99vf3U5m89xcuXIi+pJD7krhVDCxkX0T6vpekoXmiz7qaiLF6BvX+8h7o88x28xy/yrWgoKDgRse5IU9URRSeOOlxNSLzw14VEG+8VsVIExRq2TyHW1KoguLDdVw9pmoOjdWenGhdfvWeEgeShznTNFfW+ZQGJH06TtpnJT4aCgOQqUycADXcpuE1JS06ceqk6VMgqFl7s9kghJCUOY6bD1Hq8nxVznivaZT2qwy9edyvgOQ9MDOslmscH8XEpgcHF7Fer1P7qMAsFgs8+uijKWx5cnKCYaxvuVzi0qVL2WIFXYVH8pSZzjNVcIG9RVQlrcqfQ/qOqqrC/v4+Dg4O8MADD+BZz3oW1us1Tk5O0HZbrFd7GDCt8uNmxtyrT/t86623zz7HIYQsTLvZbNL/ABXCbbtJ/xPx/BZVtevRo6m9oKCg4GbAuSFP3n+jxMMrB6qu+LDdaWUrsdJzVWG6UrJLr0BpHiM/wfuwHhMbshxfv9bhFSBVADhhUZlSM7APc+m4+bCljoe+VoLpV+qpysW61FxOlUP75dvh74Oqghwngpvs8jWvV1Klma/n7pcnEYbYr8Hi/nGLZezvdrtN4UDWd3x8nMYBAHrExJlVVeHy0RHW63VGRpRwAEBTT0qiv9fZs4A8h5iGSodhwMd//Mfjve99b9qnsLVpjHx/GdrllwMlr2q257lhmMaI7VYlcRiGcVuZPAw79+WgoKCg4GbCuSFPGobzREjVmjnPjqoiquAo2dhut9nkqyEiVWzYFp2w1RDN91erVTLbsgyep+SnruuMPFGhmiNaTLSpISHfTyU2DDuqB4Y+K05+3HbD5zVSI7YSH20n3/feIYLleWWQ5MaHYDVMStK1WCyw2WzSuWoa1/H3RM4vLPDhQ09Q9fq2bbFarfCfPvB+PPbYY3jOc56T6uBS/6qqUI/h0WEcV44D7zF/qjAu38dEVEI9YBhC9mwpceQWKV07oFnUWFRxLLnVD0l013W4cOFCUuXSs4Ahf/7H1YZDPxHlzWaD1WqVNhpm+C756CqAWUGVtPFZH4Yhy4Du77H3aQ3DgDe//Ffxmnd/DgoKCgpuZJwL8qShG4WSFT3XH9tut5kKoddy4vK7z3vFh9BJ25MFTfI45x9SMzjP0wSKVVVNyQnHEA+ALPwzByVTShxYBwkTJ1iWpaqC90F5hUnDkaepTeyXKknqDeK5Wv5ciJD9V2+XbnVC4z1Dp7raa0499G3ViV3brOpi20VCSwKs45Oyu49j23UdwtiGtm2TSpVIO4Cae7pAUjo0hqHtgQBU9fiMw2BVxVNR1dNedylMOwwIAYlI3XHHHaltft8+/z8S+xjHlcrdycnJ1KZ62rtwjhBznIbQI2AuRQHALWs8KR17hIKCgmuHuf1TAWBz1607x7qD3Wvv+IN255jNGMZxSoBmLpu4LXbbUz/32TvHjj9l99ji8kwW9McuzVf+NMW5Ik/AbrjFh7s0maYu3/YGc796y8NPGsC0k7y+R8Otb6vfuV7b6IlZmpDEJ0QiRQWMIRZgVxVSwgZMy/B1QlRSyXKo6ugEp3msOG5st2YsJ4HguNAbo2Qm8/ScEgb0ZFfVOb1eSYHeZ95fYHfVYiQKeYJOs3HDWzMcXboUw2uIW7JoaGqxWKStTtbrNRqbFM/B8vxgdV2jG8nIyckJLl68GP1nABpeg0lxI4E1M6zX6+SPCyGgHdudNvoF0IcwpjcIOD46Sn1bNfGZWKwXMJtyZgFI/rdEUm18Bizg8PAwncv777fXCWHc0DoYhuC2qQkA+nxDYD4T5gzpHE+O0zD0ePPL347XvPtVKCgoKLhRcVXyZGY/BODLATwYQnjxeOy7AXwzgA+Pp31XCOHe8b3vBPCNiPPC3wghvOUMdWRbRniorwfI92Tj+8C0Yg7IvTlKSuZM3Hyt8Bm759rE+tX4TBWF7Zy7VvtE+HCTEgke82kE1MjrlRdOhlVV7eylp6SFZIZES1UzAGnS1f7xGu8p8uN8Wt/nxvi08VFVTNU39afFc3kfhol8NQ0uHx/j4sWLGMYyGEYdhgHPeMYzcPHiRSzrJhtL2IzaOSqFZoZONhT2zwfL0P5z/KuqQj32p3Pmbapsx8fHqb8X9w8AMK9TnZFOjh1J1Go5ksYw/U/wC4W21d93Ih4f0HXTMf3/YjlVNd03vh/vkSGmeSjJMgsKCm58nEV5egOA7wfwz93x7wshfK8eMLMXAvgaAC8C8FwAv2BmnxxCuOoGWOopItQHAwDHx8enmqM1Tw2Q5x/iN29VBLSOEEIWkmO5nBx0KTbLp0+H37j90n5VvnQfNIVmNFfyoysP1XjuFTq+x01ilTBRydnb20uT3XK5TAbpqqrSFixUwtq2TaumSBTok1GVj1Avz2kkVEkO3/eeLpbrs7trnUomdaz6PrbBE8SleMvSGIwE6PLly9hut1itVknFA2L4t2ka1FYh2LRVEL1jx8fHqAGsLl5M929RVdn90+dA+6urCPWLQAgBly9fTqrfMAyp7TGnEhC6HkM1oGmmZ3S5XKY+dF2Hk+MxlNjn+b94fxeLGtvtSeZhM1PFMt9yiLe5qeOekgw7VlUNM+6fN3mjvPJbUFBQcCPjquQphPA2M3v+Gct7DYA3hhA2AP6Tmb0PwCsAvP0qdWSTCTBNgrqiTI8rfHhnTr3i+6oIeM+Sh4bSNA+Ur4dES4mEGq6VZLAstpshN57DOjUXlSo6HAtv1mUbNCO0hpFU0cr9MX2mfDBzOceDvhmdHFm+38NN7w1VI5/KwHuW9F7xGiWVGmpTEqX1KtnkuFdVhdqZmjnWVVXh4kiASJ6SV8sAGFCP40TT9jAMyYN0YbVKYVveq5hR/HQ1LYSATvpKUkWlSb8UrFarzEcWyUssV0Nme3t7iZyHAYAFdG2f8kBVVdx3ruu6ZIT36QrifWkzs3h8L39eqir/H5v7MqD/xwUFBQU3Mp6I5+mvm9lfBfAuAN8WQngYwF0A3iHn3Dce24GZvRbAawHgtttuS5OsqkWcYNQXo2ElT6rUK6RKzVzSSE566hfihq8kJxoGpBrDunSFmrZBv9nrZOThFSW/GbFvVwiTAVgN6J6g6Vio0qG5q1gGx9L7l7QuzVodQkgTuyc9rJerxIBpw2D1Zqlq5MeB1zFNgIb/NFyopI/ESclp01Soqgbt4DLBj2186KGH0DQN7rzzzjh+vWx5AsMQpgUG6gHjfbjt4sWM2NUYV3hiup+elHdhSjZpZjg5OUHf9zg6Okr3ey3b+cR7FENpqCssbZnGg+1QtXaxbMb3mb18eh74bB0cHMDM8NGPflSIaNwwOF84UAPjykFYwHK1zAi+T0nB50TVtYKCgmvDcLLZObZ6YDfz9x3v3Z3P9n7//p1j2xfcuXOsefh4tu7Z7Oaf+Gd2Dh0+7+JuGx/abXf9Bx/cOdY/8shs3U9XPF7y9E8B/P/svWvMLVlaHva8q2577+92bt3T16GHMRA8eMJlDLaIBLKt2EGxkaVghUgIYiT8A0tB9g8If2wJIREpxuJHhDUWkbBkB5OAxEBIJGJBLGQYwwwDDDN2GGCmp093nz7d5/Jd9q1qrZUfa72rnlpVX/eZwfF8/aXeo6Nv79pVq9Zt7/XU8z7vu34EgI9//xGAv41pLf/kL6n3/sMAPgwAL7zwglfWhDUuQO+O02PKonC0GDBcjIGh4FeP60KcJ7LUa3XBZHF07spj4MbHGHjkdWGGShdGrpeWz+85h5QuluyWVHDD99JrmeHR6zjKj8ESAz1mxnKWjJNb5uJjZW8UaOR9xqBO65G7uXKxOLNrDICZVev73MKYAkVhUBRBewMEMbeIABG0bbsObWSPFMBo2UWcut4IQG1LbjhrgzicALJekwCed3A673SOZCBa239+fp7KTwC6rqE/i6F/hlm+i6LA+fn5YDuXKXYOcNqEVDcFxMwg9g8iBsZwMIAKyDsYUw/mPIC4EXPYFkeZLh03PfcXP/RR/PXf/ibMNttss11H+6LAk/f+nr4WkX8K4Jfi21cAvEinvgDg1Scpc8rNwT/0vCizm2ZKGM5P/nxM/yu4YK2KlsXMiZabu8iAIUBR4yfyqXxKeg9lYLjODB5ZJ8OgYiqVQXI30flcfq5RYubEJVCZAAAgAElEQVSGtSr5OLDbUNuRtzfvPwV5eVoIbR8D3nz/NQZaqs1iyxkNZnh6oFBC8TuDO5dlG9doOy7bRbeUofLzPgFC2oDkPpUITqC5tgA34ZorReAiuFCxuva7jpmIoKZ55pwDrAtuRALOOg+0v/JcZaHcYYRp/6BQRvYubIqs50omkDfGpDHg4zlDWEBd6jYBPHafzjbbbLNdV/uiwJOIPOu9V57wbwL4ZHz9EQD/QkR+HEEw/hUA/u0TlIeqqkYASkFALvTmhZbF2L0QdsgI8HWcYiDXLjELw+BGXXbsBuPy+b2+5s2HmVHj6/RJH8AA+DAgUl0M11fLAHoROL/nPlGwovVWYJOXo+XnUYbad3pv1txoXzMwYvZBASGDHnWH5syf9rcCE+5bdePpWCmDp5vdel+O6u+cg24cbKXP3L5br2G7ITDj+aF/wxbBvQ7rrbfewp07dwaJRlVMnzJvO4PK90JtEUG73WIfxeC7mKxVRLBarRKDZIxJjJO2oSxLtG3YXDj06bAPGQzqdf28NehhoIFzQyF7mGe9to77jRlenUdatrp9BX3eLe9DTigdf73eWouPfMNvAr+M2WabbbZrZ0+SquB/AfCtAO6IyCsA/gGAbxWRr0VwyX0WwN8BAO/9H4jIzwL4FIAOwPf7J4i0i/e59PjUZ7ro6uesA9LrGMywvokXZwZDHH6fMzBcn1x7xYAn9sOA+WFdDjAUok+5BfMow5xdAMbuLmabmMFSxkJBIEe9vV3/clv4c9aEKTjSFAdhwe/zcOUCex0Dvj4Hq2r6ubU2RQfmkWw9AOujwxgQS2ShCi9wXtBt9/AOWCwWk25TdfEF4NXXZ7vdplQOi8VimOmbGC4tj1kxHQMFwAWGOaGAkINqDKztqHxmNlOeKDvc2kWNwTqAgaawZwOLNJ+577hf9Br+bnjvhvf0w+2VZtZpttlmu+72JNF23zlx+Kfe5vwfBfCjX0glGDgoKNHQ+9ydwIt9vjADQ1DBC5wCGAZMurjsdru0UPfRRcN7qZhc66msB9BrfbhMXmCVUdK65QkxtQ+0rgwA9DzOgVXXNZbLZTpH752Lq4E+S7WCKF6AVfvFi/2UMZvDZTA7x+BMGQtloph9UwClY8JCZQZU+/0+5TDSOogIlsuwTUoeJdd1PUDUsnKAenp6Cu89bty4gboeJjlVrVJpsj0WRdBFUfcqCsW9CDrvIbGuCUQjACM95rsOu90u9b1G+RnTb/1iMrdyX+cSIu2ky5hZIHarclv5NY+rpTo3TZOi8XJ3aujbEHXXdb14vus6NPVi2HexPJ3X+v+y+TTbu8AmHqimMmBjKupyKkiGgPxs0yZm3Of2qBkdq84m+vx4nHa8XY2X9/Lx9Hey+8D7xseOqtGx1Wceju/9uVdGx2xcd66zXYkM4/yDyxmx05P5hEsvN9YwcUg6L8y8OPGTfJ4sMHcr5ffm0H9gmK9Jc0KxqFqBlrq8OHu33jNFZZHeSo2f+k2+uFM91RTE5Bonf8kPGAvE9d7sOmSNDZ+T65CmNEna/vwe3DZ2zeZ9ovdVF1dVNQiC6HFU1xQD07p++5iirrG9uAggq7UoCjsCJyrM1n4UF3I8HR8fpzYk8bf3ybWXykDY6sAYg4uLiwSetA9SdvhYT48x68qMZlEU2Gw2Axey9k/OVOq1epzdxto+ZQj187ox8L4Ke+yVJYqiGjCeeeJaDrzg+a2m91LR/1U2EXkRIX/dMwi498Pe+58QkVsA/iWAlxCY9b/lQzTxbLPNNhuAKwSe1K3Bomh2r7E7ShcEdkEx0GJjJikxAn682a2+1nKrqiJNzXCR0jJ5EVKQoYwHC8A5w7PWV1/r0z67E5Vx0WgwXrwUlPG9tCxtgzI3/F5BHbMVzEww88XAhO+vICTXlul5FYXaO+fQNM1IaJ4L1rn/k04oslUcWclJTrWeel4P7mTQJ9ZZAJLAZLfbYblcjjJu525Xdt2enZ3h4uICt2/fTvfTe3rvsePowTgfHzx4kMByWZaoqgqLxWLkOua5kAdAaH8DwOHh4YDx0z4C+mStVZbmQMvMtWXKDumQGCkAAZyxA5aPozK1rSokT8yh0fkw3LInd2VeYesQ0qx8XESOAHxMRH4FwPcA+Ffe+x8TkR8C8EMAfvBLWM/ZZpvtitmVAE/AcOFXY1AwpT3iv1xO7nJj43uwloOvUwDGbjy1/Clf9U+62LPuSBdKZR7yeuYgioEJa4F0sdLjzHwx0GF3mmYKZ6aAtwlh8MV6LO6b3O3CCzKDHW6vls/nsntvoEmiMczZrtzlmrcRGLoKwz17BpBtv99jvV7Dm5BxfQCcIEAR3GeW6qIA4vT0FJv9Prj1/DBK0UVWSuupgHW9XqOJiTQVQKU+8cEVaGUInHl+sStzqv91zrGejYFtXZfwfghY83LyqETeZ5HBm/YVM7k8h5nVzHOhiQgeH1zgqpoPQS+vxddnIvJphLx0346g8wSAnwbwa5jB02yzzUZ2JcATAwAGCvy5vk/7i8XFP2eqgHGkGLMTvEAzm5WHz+dgJ1/IeNHQctmlA/RiXnZlaJ30tf4tiiIJo1lDkrvllDUxlNAz3mzQfm4D9x3/5XYoCGEGTO+bpz7Qz6fcffnxxAIR45SPOQNGbmvbtmkjXmXO+i1b+vqG5nuIjMGXQQA62s97a2GsRV0aFN6gK8KGvA5AIb1eTAHXo7MzrNdr7Ha7tEG0tRY2gqWu69BGV7NqnAAkN18+lzsDwA4DAXI3mL7muaSfaTRl0zRp3BS06djs9w5V1Uy6pvleYVw82naH3a5NWjJlTZmJ4now66jMag7qpx5crrKJyEsAvg7ARwG8JwIreO9fE5FxtkEME/0usPqPU9HZZpvtStiVAE8KFHLWKddvcM4gFczyYs1Mki50utgq+8MAihfyPAkku9+mmBN2neQLBWfyVs2Kuld0/zh2ySlroEBQdTHqqmIQpZ+3zqGKoFCFvEDYBw0AWmdHYDHXhbVtm9rLgEn7YUpT4zsLQUgmOThO46T9ylo1ZSa4Pmqc1sEYk6LhHj16hOVyie12jbYtAJgBCAuLdRA1txH06DJf1gsAwHa7w6NHj7DZbPDss8+G+hiD1gu8ASSOaeccOgQt0m63S5m/b926hRdffHEAnByA05gtVxknYwzu3LyJ/X4/2C+PAQzPGQCj/uN+ZGM2ja9RN1pd1wn8BpdvB++3aJrl4HukZWn5IVJy06cgEJO0Suv1GtZarFarwYMIf+d4DPkBQc95twjGReQQwM8B+AHv/emTAj9PiX6P5daV91F+IWYOD0fH/Fd92fjYhMi5vH86OubefDC+djOd7frdIDiXaiyeNwfL0TG/b0fHpjKJA4Asx9dv7izG11fjPj9/4fb43hNfP1+MxxUAFm+Mx2Lxuy+P7/3WxDhOjdfUd+iKjeGf1q4MeNLFkxdhZkH4iVkXAF1Ive/3hFPLXQo506H3ZV2Hbj3CbiLWSbHx+/wzXchUY8KZnXWBUyZEgQy3XVk1BU7qHkyi8rhgF/Heu90OJlYh5bzyfb4prqf2i4IuzqXFwmLW4MCOc19NLfZ8nOsCgBijHrjmZRwcHAzcSAcHB4N0Byq0174Mc8LD+36cXCyvieAQAGznYaQcMCiVeFgE1knLtNaiigygcw7L5TKNQSrfuQGAExEcLpcJyLC7lFka7fOckdN25P3BY5YDeJ0zbAxwUtBDSHOefkT53v13oIAxQ0YQGCaizcEEM7psyvAC46CIq2oiUiEAp3/uvf/5ePiexFx2IvIsgDe+dDWcbbbZrqJdCfAEjLNVAxjpJ/S1/vjzj7uCIGWhzs/HewJxWQwkOIweGEa3aZ1ykXq+0HF0Udu2yX2jqQK22+2AMVFjBkj/69O+Mk7KWGkfnK3XKABcxISLDFKMjyDGjLdaSTqfCJh0sS/LEovFIrVH66lj0nVDl4+o/ofaros7u25UE8R1ZEGxvm+tR1MK7r/xJkwR3EBvvfkAN2/ehG5yy6zNkIlzKAqgbKoIQiIQEJ9yM4nxuHnrBIfLJZwPIKnzHhYezgVQs93sAotkQj81TYPFYpFYMB1fZc+Kokh7xa0iK8Xb1Nh9C+eGcyeNEYEODjrIQWk+z3VclPUZgHrr4KyF8UApJXzn0SG637oWKMzggUPngM5TrpdIyHcFDDOuM2vovU9sHI/l4eFh9j2+ugBKwkT9KQCf9t7/OH30EQDfDeDH4t9f+BJUb7bZZrvCdiXAE7uJeLHQz/RvrunRJ3b9C4zFsXpNHgrPZQO9UJdTDOT6ntytqJ91pHXRz3Rh0cg3ZTZ0UdT6MMujkUzs8lBQuCVX4G63Q4EghOZIPQCwCNqdQgycjIXZnDJB2TZlV3jfuaIo4NoO4j0QgYuCu+RCkuGefhydqOUzaOLxAIB914fbb7dbPHz4MPX13bt3A/uzWiQGT0RweHiI/X6fsnurOWJDtD/WmzXOzk/RNA2Ojo6A0sDAQMoSvm3R2rhRr2P2M4CzpmnQNM0AMLEGqCgKLCNYYnelMQbihrmOctdnDoaU9WNAxN+FHOwPGDvXBxIwOB7dhzYl1vM4EadIzF2lrvJLvidargrXmU1jN7u17ei7eAXtmwF8F4DfF5FPxGM/jACaflZEvhfAywC+40tUv9lmm+2K2pUAT7mrbspNkEfI5ayTskLsdshF57n+o3f9yACEqItFQQ7rVnJ3ngIj/kzvw2Hjeg9lmhRkKFjQKDCNpNLrztbrVC6nc0iuLOcGZSVBeVHAYLhnHmupuG+TOzCKj1OfdX06gal+l7i3GwvTc+DJYvDkbowATNCD3s9/9rNYr9e4f/8+RASnp6d4+eWXsVgE8HR0fIiDgwO8+OKL6FqLW7dvYnl4iM1mmyLtQv/GiDAvaK1F5xxOTo4ACeyRFAV8BLLbi6BrEgdUpC1rFj2DpDmWgLDR8HK1SqBmKoGl3fcMoTEGphqKqHVesOiaNVGcW4ldpZwiIT8/3buzKKVP8aAb+Prg14QvAKC/f9BqhXMtAhjO2yMUYacANs2xOPaBEXTw3qXtZ6xVkHx1hePe+1/H5RX8y/8x6zLbbLO9u+xKgCc21mXo+ylXRq4LmQqrZzcbMNYv6b1y/QhrVXRxyiPXFAAxI8Ggj/P5aIJEXnTruh4Iy3lR7YglULcfA7qeOehdbE1ZJTYA6N2gzBRVJjISBCxTviWHBJySTsr2/TzQQAGw8PDxGPceMyMMELj+XdehLCpYu08uyftvPUK7W+Ps7AxAyAa+XC6x3+9DtvFuj+1mh4PVIbbbLazrcLPrYKHC+n5cnQ/98+jRI+x2O9x+6mlYMSiUoXQO5xcb2M7BU7qAyhgcHB/j/OJsEL0GhC1dNBt4HmWYM5jee0g5BM78mlm4gesN48g77kt+3+nnpGlzzmEPB9PGIIqygO9s+n449Dq4Xvc03NcubxMzl6UYSFlk3xcH1p15H9IgFMXYDT/bbLPNdl3syoCnfG86NV1ImN3hhZ9ddgoeeDFjd54u3EC/fQpHmum9VFvDLJZel6ciYP0IMw7sttH7Af02LypIVvClmaiTy2m3Q1VV2G63KKoKBbWp1PsUBZqmQdd1iQ2oTARtptcdLap60Cdt2yaXn7UWUVuOro1ACpzNvIA4j6KuUp/sbc/KiQgsjQe7jLTNXdeF6MDIXBhjsNvusdvt8NabD/H48WO8/vrrKdR/vTmH9x7b7TYBqPPzcxhj8Prrr6MsS6yOjvDMM8/gqWeexs2bN7FvLcwusD7bLgDQh2fnwfUW59G2s7g4O4Nr+7EsRFBKEI6vdzus79+HmH4eLhaLntGj4AKeQww0LDwggGjai+xhgAElzyfO5D3FwLL7NoF+IAUKdJ7yhhXBZati+ABuHBCBWxvH2xhyHQPBtUffnyLWL+msxAF7F0B40W88rA8RxpSo6143OIOnd6/5iYiw4q2z0bH98zdHx9Zf+dToWPXc+DyzHUeiAUDxeD0++Naj0SF3Ps4hNh2pN5Hp/k85N83xOGqt/bPjaMSp+5SPprcuae+M013c/dZxyJwb75qC1atjAvXGZ8Z9sXx9om8BmIk+l4NxfczReBsYyAR5O9FuabvxeQDQTWw3002cO3FsKppxKopzsrw/pV0Z8ASMtwXhhUn1FcBYvKrXDrQgBGRypkpNy2Gww9fnO9Gre1AXQI5k4zQAHGmVRyxpJB0zURw91nVdYFZAkXPOJaDDbraiKFCZAnXTZ98WETgBCtLa6EK63+9DO02fEZ1ZLG07pF/ANYqRxfR6HwZ72j4W7fP4aB9pFOFuux+4AbvWorMd1us1ttuYHR1xAfYGRSFA6VJuJW8MHj58iGa1wOnpKd7z7HMoTPhVWa/X2HcdClPh4OAg5W1yzqHb7QfzxXmPznv42AdlWQIeaMoSTvooR+M9fDbfnAgMMADwPs4TwdAlmuuVeM4zeNc5onNegYvuv8jjZEQgEn9cfT+n0zgiMITiBZ23EFcAEFjbf4/qbFwrE34LO49BvYzvk3o6CSkemCFTNx3XMXe/zzbbbLNdF7sy4Cl3T3AUkhqHdKubi7eOYHcCM04KVDh8Ok99oFoTBgPK6ADDhVCvyRmnKaGugih1j2nUHOtI9Fptg/5dr9eBBYvaqoYAkmqk6nL4GGLhAU8Zy0VgoztOwRfrlwpvYNEDvtDOAkVpRn0hIgNWjsP2tU7K0jAQ9t6jLgp0EZwYY7BchSi2T3/q3+Ott95K+8Ct12vYlrJ27wJrVZYl6qbXJe0fPMajh6d488EDHB4e4uDoGAcHNwBj8ODxGbabCzz9nmfhvMH5xRYXZ2eAOBhv0JQVxPQCex1bzmnUVAUsKPN2FiyQQIoxQawe5xhr63LgznOFQZT2ofYXp+ZQZlRdpJpdhrV4lSlQ1MNcYMyyem+Trold0iIC0ZxmMZrQmPC+pHPLknVu4/0hnevgvbrs+jbl39/ZZptttutiVwY8AUOdE4ut+YldjzPIUsaAWR81ZlDUbTQQ2do+qzZHDikw4gUv/6t1ZpaL68ymbhe9Jo/cU9CUcvSQC7KISRB95vIZLGKIwIe23XAiAEX5cV8mVgsOxgNam9xtqufn+aLSWDmPsijgaLsRBqhdRpdqHZwXOG9SWgdlt1KeJDh0DoDv970DSngncBEcbrdb+NMSnRW89dYpmuYQdV3jYHWE87M1zs/PQxLJpsLp2QWOVgtYWPiihABYRFdnXdc9iC17Bsh4j8qYREHnzB8ICDGzpGyeghRD8zrXMnEEJh/n1wqinHPwRQGheVAUBYwYGNomiOdWHNXg3hPAZgAozTEEwXgPoj0CJpRs3vcsWz4XeI7PwGm22Wa7znZlwJOyQwya8gi6XHgL9Ll1NB8PQCJo79PeYjnwUW1T13X0hB6u54SbCsg0Uk7dY865tEVG7o4ZL149u8HshLIL7ObiNAVHR0cJVOh1mtxyfXaOoiiwNVvUdY1tFLA3TZOuadsWi8WiZy/8MLeV1t0YA3R9CgWREL7PyTv5fCcCKCit65TnCAAKSGC/gLTBsba3iuyHAlgxHs889xw653Dv9TfQOYeiqlBHsFSK7uUXclC5TrDeBn92WZboWgu7XmO72eNjH/9d/M4nfh/f8i3fEu7rDe6/GTKUO29xvFoAngAHMU2qPQsRgALAjzR46joFQuZe7z2cbdE5gfjhJrx8bSmCfUzzICLY7PeojEmRk2dnZwm8sbuXXcdVVcFFxq8sCpgI9BgEFRAYChbQenjvgTI8CHSkDdS5lwC9MahMvxXPrutQGRLAi8A5RP3UkHlS6K3TPs1vGQZizDbbbLNdF7sS4ElEUk4dgCKK4iLEi5H+18WoooUkL1O1RVxmcmdRNFXOcunrnKXi7Mkq/FZXYg6iWMyeMwicwTxfcLUPdG86dpVofaqqQoFeq7TebrGLoKqqKlhrsVwu09Ywy8iwaH/lLkrtk+2+Qxfdik2MoWO3kS6kJYG+vM8FkvI/6ZhYOHhaqPf7fXDHtTbkYDo8RvFciXv37oV922L4u3d9OZpGIY2zMUCsz6512J4G8ei//jcfxbPPPou2C4Di/GyL2zePsNk4HC5r1E2JgyiELMoGVV2Epd8YeBG0cRza3Q7RW4U9uWjrusR2u0/js93vYQBstnucHB+Gftxug9t1u0UVgS9rxRTkFgjpJx48eABjDA4PD0d7KupcYK2cpgjY7/dYLBZh6yETPuu8w2q1Svo2IOTAYsZMigKlMdhut2kzX2stfF2jING/RciLlbO92o5edwgEANWzls45iJkj7t6t5tv96Fj32fF2HcWrr4+OVaux0FgOx0Lj7tmxiBwA1l9xZ3z9+8fbj9SPx3U027EwWHZjUbFsprdImRQv78b3kXrie7oZ32f79HjLlYdfPT4GAA++eXyfP/7P/8no2N/4w782Ova5P/ny0THTjb97uzvT9zYnzeTx3IrtRP+UY4bZNuMHJ38JEe2LKcH5E1UH5UR96nvjBNn+c3cnr3cXX/zG5VcCPAHD7NWsEVKbcmsAw8gkXVhZ6M3CcwU37FrRe+vfxMRQvZL7JdMy5fXgOrJrjD/PIwKVHeDFNY8YzHVVwc3SRwYuFgvszgMTpQBjt9v1Gq+YFkGziKcouSzFgojAw6GQXtytbVaXFdDrtFLSSO0/D4gJzE3Q2LgAnHzI5K3XGGPQ1KHsmzdvomkafP7lV1CWZQCATQMvAthhtJcxJpYPeCewzsO5kAxbPLBFAecL7FvKSwXdNLgH4F3sowebDVarFRbLOiUB1f5r2xZGfBJrK2BhfVLXdbBdH3CwXq+Trs1Hd6Cl6Djtex3DzjmYqoKJCVaVfeJAA2NMqhO75RQc7Xa7wEButyjLMgnqrbUoIsjXtm3jvnvWWhja6kYBlHMhmUGIjCwAODgpktuR50qeykHnqdq7IEHmbLPNNtsXbVcCPA0EuBNPqpf9QCsQYbDDupQcNOm9dLFbxo0YcxYovxeXBSAlemRQM6WN4uvVJabv84UnsTSUxVrZIV1sWYgMG/UlhYFxwOFyCR81RovISuz3e5QiWK/XCQSw69Go2Dner/QtPPps513XYUcJOQd6H5BAXgROetBZmQJ7a1H6kvJhdfBeUJjIckjIBVTUFUwbogWffvrpkGuqMNitN/BOcHZ2hjZu8dJE91rbtoApsIupCaqqwbZTINxgs+ngrUW73WG73cM4g6OjBfa7Ft4BsqzgvEWzqLBvt+jsPvWPgqJFUaCDSykdAGDVNAM33n6/R7MogzvLlAmYHB4eYrvfYxHfA8GtzJowY4Le6+joKKRu2O2wiO5iZkdTuoo4H9Q9zQlTd7sdDhbLwEoumpAbrCjw5v37PdiOY3V+ft5rA62F7RwgPu3r6LsOF+drvP/PfHnU0CHNG3bhjV3pZZq/7GKebbbZZruOdiXAExv/MDPo4OidXIfEAl01ZrK03DwTOJefs1x5hnK9v27qy/vOTYm4ufwU7k1ujPyafHsafa1MFJ/Leqku0utFUcAbkxJWamJOBj66MPM+ecaYsKVLUYT8RlLEXEAOrbWQWJ+pOmiZnfcQ9ODQos8RFOpQwvsIYh2NM4CmrICDA9y6dQtlUydgum3WcBZYLpd48403cHR0hEenp4ApgO02ujR3sN5juTpC6UxkUAKLVBcLbLdnCWgcHNQ4ODjowZAUOI6uBGVkAADOJUG29x7r/RarqCNTxi7gpwJFIXFuehRRA6dtM2WJOtvDUPs73MYN5uZyuUSjzFsEUTp3dAz1uI6Hiuu996iKmHOqLFJk3nsWC2wp8WkS48excDCA7+DhUBmDdh+Slq7Xa6zXa8ALnLdp6x6OBGXT+cibP/Ocm2222Wa7bnZlwJP+yKqLQY3ZFgYc+qSs104JsnOtkP5n14Pek5kj1lbpIqZCbQU1+7jgMoDjOvDedaxjYQE1tzGJqulcXWgLSPoXCu01UsokJUAYF3AFhHVRpu1ctA1ddIu2kcVR8MD31szm6mbT9ty+fTstkiJhC5SqKNC2u9TurnPRddiiKCp0zgVXnI/bs0gF5yycdGh3vWh9uVym7ViapoHbh78vvPBCWsAXiwUuthu8fu8+lsslLi42MKbB6TpmYi9q2M7DFAUOVkeRsdni3r0H+Iav/09RiMPhcWCwygIQAyyWDbyLgCbb761uqkE6iTAfLMQJFlV0g9YFGvSAuPUWJbE0pUgCUpougPu0iMeURc21f+zGA5BSaAxyoRmDsgxzQeLYiwiqpkEVxf76kLG+2KCObVksFoGZKk1MWvoAt2/fxu98/BN45pln8Nzzzw62LsqBk9ZP3X88p3Md4myzzTbbdbErB57yp9acPcq1UfpjzhFznOlay1WNiD5BszHbw4CJr88BF+uU2IXHTBizZHotu/TYBTLFSjGY4evY5WcgcBi6DMuyhPFAWZSDflANVOsii7bfwrkArLbbbejPDHQq8NS+v7i46DcJrqrg6ipLXFxcYL3eJnajqirsuy7lfuI2dc5D9sO+EAMYhEi+BAybIjExbbdDXS2S/ujWrVsQ72Gtx37vcXBwEABfWaIsAdsC5XKBwnksqgMcHoaMwJw/yYhDUQZRf2E8rPfQLXGNiRv8Fj3rY5zA+7D9S26soROnpXg449EZg2WcF5aCH5I7Lc7Xy7Jya+ABzxvdrBjoM53zfO2Bdz8ndK6uDoASoV2LZZOE6GVZYr9rEzi+uLhIWq/8O8Csks7HXFA+g6drZlOSit1YeG0njuHROEO4vP7G5G1WE+JyuXE8OuaOxuJnt6rHxw7Hx1CMM4QDgK3GGb1lgjwVNz7oJoTP1elYRH7r8XRm9fpsMTr2wRvfOTq23Y7F6otxtVGdj3WHzefH4wAAeHg6PjYxjn4/FrVPWTkR+CLFRCUBoJyAIRMPaTJ1XjMe2/aZk9Ex/9RXTt66+oNxEIR960F28elG2WwAACAASURBVOSlVwc8SVw0dWHItT7AmBECeoYEQHJHsYtPFwIWR3MuGi2Hr9EUBCk6KYp/VZvCIlwtTxkoAIOoKL1Hyu5N/9Vy9yRrkkTCliucg0rrlL9mbQvfW12Q2zboiZrVKtyviRN812J1eAjvg/ZFXVvKVB0sFthFEfJ6vU7HjTHYd12KsdrTuGmSzxs3bkQWKnwRz87OUFUVdm2H1WoFeIPNxVkqc287rC82sDZE4hkPWBfYn/tv3kvJQQtvUC5KHMoK1lqsVjdRL4/wR3/0R1iv1/BSQbyHKYBdu8bTh7dhvcWqWuDx2TkOlgvUTXDfleLgCCw75+A7C1OVWEgT+tcCHkPdnE2g1cF2vcYnZcI3QetUxHkYxlnn4RDwMHOT6994I+g8WpRdfEDM8I7AcFVxDrg4DxrNiUbfKd1+Ru974+YJ2n2HD3zgA3j48CE+99mX8eXvf99AzM7fSY40lTgTnLc0JzHbbLPNdu3sSoGnJDimNABq/JpZId3MVsGXnqfHGRzlgnC+99Rrvq+CEGVvNI0A10nvn4vY+ZycGWD2RYGhHk9h+s6PwFznh5GCed0tPEqErVp0Tza9d5cixgJAEenTEhRFgeVyicoYuKpCW5Y4ODiAiWJqHifnHJZxbz0FrtoOBWAXFxdpbLquw2azwfn5OcoipFtQd2ISa+/2CXx579F6i3azR9mWSVNU1cGNVNY1jAlg+eaNY1SLQywWC2w2G+y2azRNBeeAkxtP44033sBTd05wXtdYLksYeBTlCs6Gbdo8J04FYIrAuCRXKY2hMUUQyEufZsJ2wz4ObsEitNH3AMlIiELU64wxEALSnLSV57m+1n7Jxz2ft/zcVorAUDqOpHPDMGHrxcVFfB0eIA4PD3H/zTdS3XPWNK+T7fr28zyZbbbZZrtu9o7gSUReBPDPADyDkMzlw977nxCRWwD+JYCXAHwWwN/y3j+U8Av7EwC+DcAawPd47z/+TvfRJ2r9IWZXGKcUULebtTYtuHqePt0DGOgv9FpeZNgtleuTOESfwY5qkhTkMNOlxq44zk/F7rNc85TrufRJXpNMMkOWgyutD9dN72Ph4Z1PWq20GGvyRB8E4ZUBmmY5isRjMKvARaPd6rrGxXYbhMZti5Zcn9qGtm2xi/deNk1wucU2brZ7HCyXKMsSt2/exHq7hYjg/Pwcjx6eBpava7Goy9QfTR1o+uWiCqkMAKxuHEJMHSMnHf7cV78f9+8/wr/7zJ/g/PRRYL7gcHBwgEePHkWweICzs7MIsvZYHSwhsAk4iggKUwTxPM0h5y2cdyilhECwo82iPTzEmLQZ72IZNF5OgKIsBvNCug6Ages6IM5p/YznEj9A6PhxHjB2PzPTqPMjufi8h/F+5Br08XvinMNut+sDIQpBs6jRLG5hsWzw8ssv4/j4GCcnJ4PgCgZ3zoWoPedsmgcMuGabbbbZrpM9CfPUAfj73vuPi8gRgI+JyK8A+B4A/8p7/2Mi8kMAfgjADwL4LwB8Rfz/TQB+Mv59+5tkLospNogF3gyalIHiiDtdOHJR+ZSWisETs0ZTeabYHacMGetRFMQpqGJAoW3JmQUFQQpy2HhB1HMHLpqi38olZ+py9oJ1YfyZAkZ2N3Jd1W0pIthuQ0bztm3D5rmxDi6661i/VZYlTg4PsY4uu7qucXJ4iP1+j6rcpi1zmpgCYBNdonVdwxRAWZnkvgvXV4C2WTOhG4+q7JlBU7Q4PjnEwaqG+CMAgO22qJYlfGTAttstqrLB2cUadVHi/PwcRgJQUSH26ihc6yRsXdLPK5s299bZoX1kpEiMTwEJSSJ1rDs78GG5dg+ISXOZ3XI6RimiknR6LCjX+ZiDGX3dal+Ri43nTxnBFM9dTUvALujdbjdgcqcAkaZS0Pr1ZczgabbZZrt+9o7gyXv/GoDX4uszEfk0gOcBfDuAb42n/TSAX0MAT98O4J/58Av9myJyQ0SejeVMGgtOmV0CpjOHD3QWBEb0c3UZMJMFjBkeFsrmLjitjy5oWqY+nes1zBpwFJo+5eeAROucb1zMgva8LTmbwCybAjStPy9gek3ejl7/ZVAUtIde1HDpwq1lKIvkfUjKyOBPQWRTliGFrOlZjTICQgVZVV2jKAosFgssDw8DyIo4oGmaAJxiCP5+u0WbRSYWJogGjREY8TBGUEaRprM7WGewWJRYLkt881/8elgnePTwMV5//fNYr9c4OTpC3VTYXFzA2R0Olk2IVISBdy1MWeLlV17B8fExHj5+jEUdGC0Fi6tFjb0NG+VOuaUEkkS1iTWyIUEos0Y6Z9T1ysA5B8p5Cg4eZwVOWrayTByFx1o+F9MwFBmw5rmi7tWmqWBMGIv3ve99uH//Pk5PH+Hk5CS22wBwkLBTD0R6/Z9mwc8fHGb7/7FNzIOpLOYAYB9OHJ8QnEMmxN0TQuPCTAR4TJwHANVE5vBJQfPUvG7Hec3clHj+kgSyJ78zFj8v3/jq0bHH7x+fJ3Zcn9P3js9brcaZ2gGgeXMsoK9eezg65t94c3TMbSfaSFrk/09t4kGuWj89Onb+579s+voPvHd8/e8MBf1yPi0/+II0TyLyEoCvA/BRAO9RQOS9f01EtMbPA/g8XfZKPDYATyLyfQC+DwBu3ryZnsDjZ+k8XdB1wVdwxYtqXddpgdMf8OCeGYIUjRpiZoTBFjMyWh8tUz/XhU6zPjNjpgsdJ0LUe0+BJhbd5qwBs1/MLijIUbZJ32s5nHZBARAzWoPwdgwjGDnqMA89V8E3uxGNFBAxCNsRSyAZhDfyHYx3el2WJUoEbZGz/Z56mgV9v98DdQ2/C3mcRAQCh9AlIVWA9lPXCUQspCggvoQzBgUEB4sSRVXjYNXg5Cj8iLz88svYrgu898texHLVYH12jrOzM5hCYIqg03rppZfgfcgWvtlssNVx3u9RVgFoL1arwUbTBWIgA6KuCYH1YdDufZ/jyqMHRLYwkOg66/sobHWigIjdcwqUtH91nuuc0cSmzjmUIiiMQSESNpUmhord4fo90weNnqG0MEYgUuLGjRt4/fVX4b3HjRs3AAxTggQgNUxOy+XPNttss10ne2LwJCKHAH4OwA9470/fRssw9cEIFnvvPwzgwwDwwgsv+NwN57Ifek7sqKZaIgYA+qOtkWvqhlGGRK/LXXpTLjrWR6mp+0J1P5rUkcPJp8phNisHMnyvXJfF7dK+YPCUgzIuU8Fc7jYcDBYxW/nCzH3C25LkjMuA4fM9wMvz/uTXQMPpaQyrqkq5h/S8zir4G7pyuUwDQMQBNiT4rCuLsurQlEB5fASH2G9FPw8ODg7C3LLbFJa/Xq+xXC5xdHSEo6OjlKndLUMUYhfBaFEUWJ9dBJejzjFoGD+lsvBBIK5A1hgDyHBO9X3uBlozZm74L4Nj1iBp+cb75KrLx1W/B5cxQjoGRQq7NvHBI4zvgwcPsNvtcHx8nMB7+FvA+yFYmvVOs80223W1JwJPIlIhAKd/7r3/+Xj4nrrjRORZAJq04xUAL9LlLwB49Z3uoWwPPxXz4pFHF+mCy+wLM0nsetKd6ZllAvpFS/+q9knL1WO8kS67wEaAxYdkg2kRowUzB0rMLrHWirVSDMZywMLtB3o9C9C77pjR4r7izWD1M61H7jbU+yoIZVDkbFiUi9LAeRLNuz47Oo+v/k2uJOcSU6VtKhCiw5wx8FEzZOFQYKh7K0JhCLvxaRs8xLQovYf3e9guAkvn4SUwTpuLM/w/f/jvsFwu8eXvfx9u3b4J57sEpLbbLc7OzrA+P8dyucStW7ewinsC7vbbFBm4Pj+HMQanp6dhM+OmwfHxcQDVpWa/D25J70OSA1NEbR0c2ni86Dp0BIz7frMQ6eczj633PiVo3VPeFe3b/EFEx111azweUw8kofyeuQ3foTptn3Pv3j2ISGSgDDRak12BOudnt91ss812He1Jou0EwE8B+LT3/sfpo48A+G4APxb//gId/7si8jMIQvHHb6d3AnrgpD/UuT5oyhjsZPWdfK8LSc6IMFgAxiCFy8m1SEls6yLrAQCogHLINmlbpqKUGOxpm1jvxffl/tK/LEpnsJMDJ/7PQG2qj3M2jF0xddQtWWvhCz9wK+bMG9+DPxuBKh+TOWKYj8tUFazrUKCA9wZwYRuReGV/nwwImEJgYOGcursMbLfFwarG8eF78OjsFGdnZ+j2W/gq1L2uaxQiqIqwyW4bE4Cen5/j5OQEXdfh+OgERRkShWqkp5EgqN7tdinUv1g2cIhuXo6Ck9jXXlAXYf8/wVQE5jAyFBiygPpe+57BNo+DAuzcclY3/yyPNO0fFHqmq+u6lI7C+yrNPc5NNdtss812Xe1JmKdvBvBdAH5fRD4Rj/0wAmj6WRH5XgAvA/iO+NkvI6Qp+AxCqoL/9kkrwy6qfAHXz/WYsk15+LUyRPxErj/yXC4wFMoqc6VPzBoBB/R6kK7rINGNwakSOJWCcw6wvXZqSrTOrFje5lzfpHXLn+I5LUPu5mM3DrdZP2e3EKdRUM0MwPvShXM5IlHrxGOiC6q+1rK1D3LXY+oP/dwA1naAoBcbd3uIDck30zgRUASQNjbWssQ5dCKQbg8jHs4LvBOUBdDZPcR4vOfpW1hfPMZms8EisjGNjnVp0CxqnJycYL/fw+73eHD/PrwPEZ0nN44T69O2LeoqMDSrw0O89tprsNbiYtNgtVjg8PAQZUw6WoikVMWD+esFne21emG8hq46NWXsGBTpXovqwtUxVkDFeikOAGBgqw8veo5qvpgJVb2f9yW+8iv/E1xcnOHi4gLWWjz/fEgT4b2DyDs/iMw22xdsUwymHwuvvZsWY4/Ou+yD9ZNX6T+0+Qkh+eKP74+OuWosiF5+fpwhfP3SONN2t5r+TtrVGAq0XzW+T/XczdGx8s3zcYEPxgJ/dzZxHi7JWv6kjPXEed29ceb6g9+Yfpjzz4/bKCdZNvvNdHDBk0Tb/Toujzf+yxPnewDf/07lTlwHYMx6MPDI97zjJ90+g3M4VwXOuiipq0pNz9cNVnlR0kVFgY/WS0TAso48dxMQN2AlNwb/ZfcLMFzEdGNaZp20fQpi8lQDudtNz2Ewl/cbmx7P925jVo/zPuWLLIvL2fKFmdm/3HiBTakOChciabr+nMDy9OyZ3pHLtEia9VTHnsEJ92nbFicnJ3j/+9+Pe/fuwXuPm7duJGCjiS8LCIq6Rn14CGstTk9PU5nn5+cBGJUlnHE4PjmCh8Hx8XFI5dBU2G37pKK73Q7L5TK4I2n8SxHsnYWBGQArnnepbRQwwa48nnf83WGAlYOYHBRpu/Q+uf4vB/POORwcHOH+/fuTDzk6lrPNNtts19WuTIZxoAcM+ROzmv5Q53ttMeOiUXL5YqKf5RsPM0uSuz/4Hnp/F11/RVGgbsJmtc76ARPkvB1pPhhIqLZoajsXfcLn9nIUH9C7GnNxuC6GLDTP3XODxTsybRqxpSBOy8jrqy4/ZfVyhisfJwaV+j7vUz0/dzEaY7BYLFI/aRbzJDLH0JVl4/VlLLtzgMACcS5ZOCBm+n78eIPNfof9dgvXdShEUn4mrpmIJLBVLRY4Pz/Hq3dfS9q8w5huwRiDzjncvnMr9dH6/Bx1XePuK6+ibipsdxusViuICJZ1HSIURYBOBeYa8j9kChlMKZDmvnTOoTIFvBnmL1ONn+Yi43mhVhRF+r4wqwVgcrsYfvhomgZf8zUfxHa7xquvvorbt2+n8YqjPelynm222Wa7DnZlwFPONOV6DF2UAIwWF7Z8kWDWI1/g+Ulaz8ndYwwgJLlehiJsJ36wUKkbRkEHG2tVWKc0BT7UcnDFQErre1lYOIOoPGmnsm75/XL3Ws5wsHuO3U3MNk0tmtzPud4rNxGB8R41MY95GxVQ5PUObxx84HQAxHGEgY9b3Vhr4csCj8/OcOep26ONKBmYi0jYF+7gAMYYnJ2d4f79+2FvvliP0sR7xTYdRsZqdRCyqD9+/BhAYL7saoXlIuzJBxF47X9rRxwvi781v1g41cYNiGNKChlHavL3JZ8nubsu/67xnnnMZCpbq2Vo+x8/fpwYtrYdJ4edbbbZZrtOdmXAU8628I+2LvAMNphxMcYk5oeBgG5uyyArvw7omRy9B//o63nq2ssj4EQEVV2gkaavX2uC1ymyX7z/HufTYfebnqMATC3P2q33YI2L1kXddgpouC/0GtZ+aYQZt1fzV7F2Rvtht9ths9nAR/aNr+W67ff7ASDkffmUHVM3JYNJPV8X7rqusbc2RN3FflLGaVBHIG3XIjAoPODQ31vb73zQrBVFgVIM3nPnKSybJjEvU2yniEC8Q130LF1RFPjUpz6FwpR47vlnE5hIjCgivLYWN27cGERcNhFI/dbHP45Fs8QHP/hB1HUdAJ3EK0mEz2J91qAZY2B8L8zmTYuLokhZ25mN5XQTOma5OzAXi+sczM/vAbTHjRu34JzDfr/FvXv3UFUNjo6ORlvIzDbbbLNdF7sS4ClnhfSHm4FKURSDzXh10dWFVM/Nn4o5e7g+jbOLiBcJfQrne+eanfyatOB4jBZ/U/cZyZmt0XP0CT8Hg5vNZrB4ajsGaQIIYGk5arzosu5JX+vCyuerW0yBjpbPfaJZ0Dm1QD5+OUPIyUn1c71WQZj2N9eVUxLoOGu6BFgLuCBO9gYQHzZBtrF8B4TjzoX923xw2cE6wMsgaaiN7EvXdahjHylQLSUArc5aGCkACfUxxuDOU7fx6mt3YQrBe9/7XjRFBdfGBKjeJoYutRdAXVVwdY2yafDnb93CwweP8ODBg4Heraoq1E0FH69NINTLADQWELhsHup89T5kgtdyObEpu/D4eB65yuA0gbsIMHULF50PasaUuH37qdR/6gKebbbZnsAmMqa7w9XoWHU+Fj/7z90dHVvdH2cI331wnFEbAOr7F6Nj5o2JDOMnR6Nj7dPjY/alCWH5xbRou7z3eHzwjbfGZZ6P64ipAIGJ3xz75rg8AJAJEXteop/IHA9cEfAEjBNSsuuNQ+uBYRg+b1PCri01flIHemDDLiYRGWxrkotmp8Swud5IRIJbyIeQdAjgbP+Er2UzyMhBE7vGmEnTOnFCRHZLcr/kn+lfZgEYzHgCDxwxxwCWs6LnwDGvQ+4CTIAHw+zmHAiglrNpQNAw+dhucQ7r3S6McT4+8RKn0V6+94CJ8/C6RYP4QfSY1kO1UjoODCC993DewcZ0FDeOjlBWBTabzWBuMEvH/abGLGbTNGiaBuuLDbquw8XFRWIdq7qE0/nvJabC6Mcr73+1vD8VJObMHl/P7tN8Lur80zFUhlbr2TTNYJ9JdgErcJttttlmu452ZcATMP7xV1aG9UG6GHCKAE4MmLMiDLrUrcULNwtsdXHIwVceAafHc/cevIN1vZuQBdzMyGj9uAw9V9kfPab10wzrGjWoLAUv8nm7gR546l/uj8uiqrz3g41gOX0Bt40FxvlrAIPIPz3OkY06HtwvCjqMMWidS+yKcw4WQKVg0hh0PmTStt7DS2Cg4H1y4fn43pVFOE5BA4u6RmPC1iWaa0kBeJpjAEyngNdByiK1yxiT2EO7a7FBv8Gv9lmuRUsusTgGTVlieeMGNvt90k9tNhs8ehiexFZNg6ZxqBYLXFycoWkarJrgHtYUDeJ90DuRWIrrweOic4XHmYG1fp5/d5QJ1YcGBd88F6y1yaXJ95htttlmu452JcDTzU1P++mPvoIWZjfUmCFhy7N+axZtXRSUublMh6EAg9mXXGfCdZly4xkpYP305r7cBgUMnMMpB4bM0OSAkVka/Z8DRb0/C6tZ4K0uOWYP8vuwzoUF3+zeykETt5VFxVovBpKsZ2PWkfuEy/Dew3QdOu9RwMBGcT6ov338awUAJG1VIl7QlDXafRfcdZfMhSlGp67rtJEvACzKGs8/9wLOz8P+eKvVasS6vR0DKs7Bi0CM4GCxCJoy3TC46wKYj/qzXddBTO++3O12vaaJqpq7RPPvjoJZnrM6vxls89gxCGLWk+d3rn/TOZ2742ebbbbZrotdCfAEjHUzUz+8QZS6T+Ap13kwiNDjAAaLsy5ODDLYdaEsFC8EujiERaGD90O3opYRFpfhNhs5EGTwoPdjl52+VmZH68qLUw4y2D3ErhOt1y66ujivFAvZgZ5VYhYPwICN035SxisHhuw2VBZHWRBepHl8GKwySPM+JLycAlWmLBMg8uIh3sNb3Wg5ROkV3gcuxgt81KPtow6pLsu0mXRZDgMRcsBREAgtYeAgcN6l7WiUpWMdmYigMCU0UVXOWHIiSQanixhNV1UVTGx313W42G5xcbaG8xbd4SHatsV2u4UxBkdHRwN2Vhkxnhc5E5S78vI2TwFf/i56qpu2SR9MVAel83vWPM0222zX0a4UeMpZCtbyMKjIw63VGICoa0WZEd63biqyip/U2YXB4ue+juONiKcWiXxh4mv0ff5kz+CG95/jp311m7CWaGqx0tec2FLbxq5LXVwZtOWsiYJBfc2gk9unlrsPc03NlAswd/Uoo8QslJZbx3HZKWMXCoYJu70M2ajoslMRt24x45xD5wxK028ho8e5Pxl4QjxMIbC2r+vZeo2u63Dnzp1RIlftg3C8B9fIogH1tSDohYQYRlNVaLs9jKmx3W5Tfqa6rtG27SBPl/bnFADO75ebjsdA6+XcgEni4/qe865xoMVss80223W1KwOemqZJr9mFNKUfYZcBa6FyETILdHOWhBcFXvRZF8RgashYTS8ivHAw2OEn9xywaDv0s6IoEiuin3FCTa1jvhiyPkqv0//sttOFVevNwIT7iIHnFDPBfZq7q6ZcNTlLpi4kvjePawJSzsF4j44+A4KQvPMepep0YEICTR8X8D4dVwBWvt8HsK5riInBLeITk6j3HbiuTA+ATNRItc4mBk6zim+jJm3QhzQevdhf0xbEuvl+U+kEzsQDNAerQnD79u0wbrQHpLUWFxcXOD8/T1GNd+7cSUJxZvu473meclZ5nWOqu9Mxq6oqla9MYT4H1NjNPNts19YmfuPkCdNyeDf9YFEcHoyO7Z4eH2teG2/FYjfbcYETx5rXb03eu70zjuor/+jzo2PujTfH572yGB2r74zv0z07jsADgM37b4+OFS+Mz52KCMSr461Y7ONx/0xG5QHwcSeSt7VLHgSvDHgCpp9WdXHmRTa/hkFCXg4DJjVd7HPheF6mnjsuz8H7oRstf2LPo+suAwla/lR2cD1f9U0MUnJ2KO+XKQCjC58yKe/kVmFmjF1a2nd6HwVn3P6c2WN2SxdyrYsCRHaf5eyHQR9CWlK9k0aOcmcVKCbb57xFXdUwxVCno2cwsM3bqyBq0F/iU3QxzwEWVBflEJiHuRrcv4NxkhClmcCIhN9nIwLj4xY+RQFHbdrv9yky0zmH7XaL09PTcC5FOeZicGttYq60Dsoa7ff7EXvErnLNFcZzgFNLTH2fZpttttmum10Z8PRtH/0Q/vdv/C0AmAQY+XGgz4vD2ZCZhWLwoloQZlVyMMAujXwh1cXd2rTUAhi6RNjyyCs1BRuXLTI5yMvBny7Qutjx07+eo+AkZ6sADLZfydkBrhNrvbgf1TTMX+8H9PsJMiOXt1PrxuxXzggyIwWEfeYAoDQmRbzBOlQA9t4DRZHyIgGAmAgGIrtlEVmXjFEEwmbCoL7lzxO7F8Lx0MEnd5oxBlUs76mnnsKDBw/w4PFj3DoJm3Gym9jDTc63HEznfZfOBWCy7PoAsFwusd1u4ZzDxcUFjDHY7XbJTds0fbJKBZMatVnHDZHzsVfWqu8HB/gibCeDIRPLAFqvSdF21k+lrZltttlmuxZ2ZcATMN6+Q8FMrp9RY62FLrw5O5ODixxE5WyJLlw5K5K7EhnMcE4m7/t8N6xJYgCY11OPc9u1Tvm9gKG4W/tFF7R8u5KcDcvvyeVzeXk/ch+xAJz7I2egck0Xl3OZbq1t28C0dX3STFP2+aks/Gjs8n6zMc9W74YKALeQfs+39B9jwMpmQyUhmpoBY5drr2m6hD2FgRgfIwT7+ub9nzOZOQOas5hcjuq49Ly2bbHf73F2doZbt25hu92mBw1OfJqDxfy+RVHA2ahtqnvGKR/DNO9iXirv/SB9wmyzzTbbdbIrBZ7++m9/E/7Xr/m/AfQLtQIC1t5w5BpbHjnHOYX0OrUckPACygCEmRJ2q6k2Rt007HLi+uh9pzKWq3ZEWZ7LXGi6SHF2ca0Lb4CcAxfdJkXrkDMaU8yDHs8X1BxkquvPOZc2W9a+uczNmgM7HjMguIeMB1zbDZgvBsm16XMtoTAw3qB0Lm5tAjgRVEDQSElgnRTsLJdLLBaLdO9Shot7DmKc9Mu/tseLpP3yjAn72ZVNBbl9E/defwNt2+Kpp56CmBipaS4HVW83DsyQ5uPAgns9rkxSWZY4ODhIfXRxcYG7d+9iv9/j8PAwMYZ1XaPrOjRNM4jorOs6ix51qKoCxoTEnpwORJOEDkC774Gpsz7pzmabbbbZrpNdKfAE9JFhrKvghZZNwUsugNbrgCH7wlnIc1Mgon9FJGk9gHFCSRabcwQa/83dc/y0nu/3loMOvl+e9ZtdiqqH0n7LtUYsEs4FxFw+a4jUxcP3ypkx3s5FjfuVF3YGdAq4VG/DbF7aqiamFkguunhfG/d90zorC8XnFD4kkPQAfAQTm80G3losqirohibckAx8w70wEAqWImiJbcpdkkVRwBSSROi6F15HrknWajF7xH2l9dC6sNuX53jOlvGc5Hl3cnKCw8NDGGPw5ptv4uLiAoeHh2lu37hxIwHVKdbQuT6Jqeqh+kg+B+/7CMqwhUyfDsPa8UbHs812HcwcHo6OyXufGx1zy2p0zLTT4mXbjJdjmXroen0s2r5MED2yNx5M3/vZcXvqGyfj21yMRduTKiw7FgAAIABJREFUx9br0TF59d7kvZcTQnncvjEu8+a4jvaDL42OVXcfja+d2L4GAHy7nzz+JHblwFO+qOliwJ/n+9cBfbQZJ4Pk1/o310axC03dD+yi4yd9fsJnkAQMkyCyW4cBDreBF2DNGJ5bDthylizXROkCqueri4brxHWecv/xfS9jSxi85ePFdWVAxueqK5SznmtEYVEU8N1w3ByiLMkP+6SAwDoHh94laUPF0jhba7Hb7XCwXI4E0jweU/qj3Aptu84jZYYiS3R4eIjNZgNYCxPniYmuvrzvpvozN9aG5QJ2bgfrp8LDRgg1zBNerlarxB4VRdij7o033sCdO3cGuc94DPUBRb9P4bvRjw9XPX+QEZGZeZptttmupV058MR5lRRU5FqPPJmic2EzXb2e3WK51kiv4yd8Teyn7I0yMawN0QWOy+Sn/JxhYrdKrjHR+yrTAvSMkXMh0aCexwAw3xZDjwMYJEbUtA8iknIAsXtNI920jsps6GLpvR+4ZFhTxe3JGT1daLV93E9TDBaP65QLVhkoZZi899h3LYwHdl076J+iKLCnvtL/+/0eruuwWCxg0W/smzM1PD7cx14DBYjJ5P8KpHR8ttvtIEAg1zhNuYuZbZwKMpjqm2AOgEFIfxCiQOPdCFiHMdWx5/l6cnKCx48f45Of/CRu3bqFmzdvDh4OwveAn2j1u6Q5q0IdfHTVWdfGpKQckYjZZptttmtnVw48AT1Q0IX77dgAjQ7iawEkJiN3Z+WuJc5nkzMybBr6reCOdT5sDO6mBLg9O9DnmuJ25vcuimLACuQuIwVNHAHFoePMSui5QO/y5JD+qbpzWXpvBZBarxw88ljkSRm5bd6H7OfcNmMMHO0dBwD7dp/OsdbCUj9r/qecpdOyrbU4Pj4OIfZZ3bR9bHqfEkE39XZrP4NDjb4rRXB6eorlcjlwEb8di5cDb2bscpcst9MYgLOV58xR+OsgYhIoVmCu8+Hw8DAmD93j/PwcJycnKfkm4AZ1YuIrsYLOwdoOxpT9OIiHs36wAfVss80223WyKweevuOT34Jf/NBH05PzlCuJAYYuKBqCz5vMMovAe9wNNBlACt9mF1euP1H2hRdBjcJjxoDrzOkC2EWnolwAg3O1nax/0Wtzl5LWiTcJVmPWS8tjETC7LBkY6fsc4DDrxLowPZcTnPICnm+7ov2sr/NkjGlMEdp7dnbW11UC4Ot8n5Vc+2DXtqM0FJvNBt1+j7IocHR0FPppwsU4VW+gzykFBBDlo5sxMGHos5cTW7dcLmGMwVtvvTVgKBk85yxbDpTZrcymfTSoo/Uoy6ELWK/lsS2K/kGkqqrBeB0fH+Ppp++kHFEvv/wyjo6OcHJyApHAamk7cxbXe0vs5T50ifg+oWYx720322yzXU+7cuAJGOqa9IeaXTTKoAwXiABS9DoGND5bcPPFOtcF5eBBy+O/LLBlcKaWL3Rab2YjcpYmB045C8EAirUumu+J68ht13YwoGLjc6bYCzYGlrygMkhkYXiu/2IGML8f5+uC8+m9grBtZGC0r6y18MQ0Akj79W02m7SFy1SAQG45c5bctBHsGIToO+f7zOH5uXqvXEuGeK2IDPbrY3A+xThpn3Hf6/l9AMBYp5X3u0JBBsKc1sC50MbVaoWzs5CxfLVaRfZ3uq/CXDSJGc37UNMiXGUTkQWAfw2gQfgt/N+89/9ARN4H4GcA3ALwcQDf5b3/4pWls10/IymGmlxsxseKCU1oPb3sygQ53Xz2rdGxbiqD9hOaO52+tlx3o2P2mXGWb7k3zujtu/G1mFg7LhNn24cTxx+NRd9muRwdq77s+dGx3XvH2c3rVTM6BgDyJ2MhuTs7mzw3tysJnv7L3/pG/J9/8eMjl1dKwEcARxcTXsyUJQLGQELfa7QRu0Xy+/B1U8CC78f14fp572Gkz42Uu4m0bHU/8nUc/aTAYyqiTZkWXRwBDPRbeUQes3Y5SzHVJgaGDOCU+Zpi0fR+U0Jx51xaXJXJYn2b9x6wfWRZXdeQso+SS8Cm67DZ71FVFTa7XWh/BMnLKIw+ODiYFFvnY5BbDsohIVqO5xk0kpHKKcsSB8fHuPfmmzg4OMDR0dGgXJPdSx8UtF0MKnke6XzMwU/oE4BdbAFY+vT7ZW2b+l61af147GFMiZCKoMAzzzwD7z3u3r0LkZAAVOdPD5o8NGFDSF0wrGPYcPlK/rTktgPwl7z35yJSAfh1Efk/APw9AP/Ye/8zIvJPAHwvgJ/8UlZ0ttlmu1p2pX/h9Olaf7RZ2Kx/c8Ygj0BTY5ZAQUS+DQWDAn3P95hym+lrBTvMvISszAqaxtmtuUwGMLyFSu7m4XYM2YWhyy/Pls6uvMtspD3KQGBuLM7XfmKdGS/yeeSYfs7Xcz0MiZu7rkNVVtjbDpUp0HlqJ4YbJXM04X6/HwQcWIxzO+XjoK+ZWayMAXy/jYuIhHxUWSgZpzLIN+dN5ce/HBjB80znPDOaPJfVJcasn7Y99JWDc2MNWs44KrD13kYAO3ww0HtcXFzgJGZNFxHAC0xMHS4QlGUNa3cDVuyyfr1q5kPlzuPbKv73AP4SgP8mHv9pAP8QM3iabbbZyK4seFImhrUjbOz2AHoww4sG61E4lYG6fPKoMb2GWSc9rn95YWG2RKOTtLyQIDGmVIBLT+f5ope7t5jt0fpwVmyu25RIerPZDJgWbvMUq6QARcEC67rytAZ8jMFFDiK1PrlGjBksdsflgDIxiRCgMKjKWEcU8CJp77q6rlO6AE7uqOUvFsMNKwsMwQTPIz4mEtIL6NimvnQh6aM4z/sOJ9G6Xr9arXB6eorHjx8nHZTOnTKCycoUab88ZeN4zLnPNVCB83TlUZ5tawdl8LzQflmtVoM284NEr2ELDymqEzs9PcXdu3dxdHSE5XIJ5xyOjo4gItjtet2b1ptzRmndr7JJCB38GIA/A+B/AvBHAB5579UX8QqAsW8gXPt9AL4PABYYb6w622yzXV97RzGIiLwoIr8qIp8WkT8Qkf8uHv+HInJXRD4R/38bXfPfi8hnROTfi8hf/WIqxoCGXW76f8oNM6Xl0R/3pJHJXvPiPqVh0UWBFwfdHHUqPxPrWCad2NE0UzOnDdC65i5JrROzVAye2H2nQJH7gBc3bmPeh3nI/pSrkQX33Fe8WHIaBDUVKmv/5YwI17+v0PQWNnldta8uPRd9yoDLmEo9NvU/78ucycvTEXC73s603awXm2Im2TXNx3ke5CzX1BzmYIWeUTUAer1f1+0HbtemaQAv2G52g+Nt26JrLTpK+MdtDxF8E1qIK2bee+u9/1oALwD4RgBfPXXaJdd+2Hv/Ie/9hypMaypmm22262lPwjx1AP6+9/7jInIE4GMi8ivxs3/svf8f+WQR+bMA/msAHwDwHID/S0S+0g8TxryjMWjK3Un5IgJgAKp4gdQFrHdT9G6TKdfGyH1EC40uPKyn0nsykEll+nG5zDTpIsOLLC+UrBvJF0mtA7M/IpJSKrA+LO9P1vNcVncGbXm6AW0LXycig2i6qfFkQXieYiLXRnF/5OOqxtGMqV+ov/K6TL3nNufzjQGZ8YCnoIJwb3I/Zu29efMmHj58iMePHycWR0TQeR+2kzH9Fj8MMhiMal2mggx4HnVdl1IQABiBMf2v+wayq1DH37mQvD3XLxljcHx8jN1uhzfvv4WiNKm+yqxyVF3+nXq3mPf+kYj8GoC/AOCGiJSRfXoBwKtf0srNduXMbbfjY5/7/PjEid2xxVzy3Zg4t+vGwnT4yx/K38n8flq0Xd4fi6R37x0LxpvVmGG1l4jQ/1Q20cbJrOV/+CejY4vzZ0bHtl/xnsnblKv3jY4VnxmKyOXhOIE18ATgyXv/GoDX4uszEfk0LqGxo307gJ/x3u8A/ImIfAbhie433ulebH/jY38Bv/ihj46exqeezIFxiL+CBF6YeHFWt07uVlLLo/eUgeGFSRkWvX/u/hNQgkkzzuOTgxR9rZmwFWwAvVslT90AYAQojekXON4/j0GBLqAqKM/BCQvV9Rq+v/Y1R9tdxrRMjV+eosEYg8ViMYjGywExj58CjwQ2EOmBCZA1BcryPuRz+b/3HibJlaKQWwCRIgmwAQSh+kQ5DFh1DCwAIW2TuuBY56RlMJjOtW/GGOx2u0E/ifR6t7TdTRapyX9zl7G2hyNajTE4ODjAvt0FxinOGes6lEUVE2PG+R1JmqZpJjVQV8lE5CkAbQROSwB/BcD/AOBXAfxXCBF33w3gF750tZxtttmuon1Bv2wi8hKArwPw0Xjo74rI74nI/ywiClOfB8AQfFIzICLfJyK/LSK//WA3DkuM56S/+l9/kPMncWZBmB3QY/n1DIL4HACjsvP3ucuHWQDWrehT/pQ7Rk1zNGnkmr7mzXBzUKYgLncd9iyCS24TXrwZaPL9uW+U5ZjKup27uDj6a4o942v5Gr1vAh5FkSK0+JwcMORzQd/nYGnq3BxcvtP5AAFzCf/fyXJgXBQF1us1zmLoK382xW7pe+4j7YOpuc8u6LzMPKAhB4R5fYEAmHQOcvZ7ZqBu3bqVNhzuug4eDoIemGs6DudC4s0rbs8C+FUR+T0AvwXgV7z3vwTgBwH8vfjgdxvAT30J6zjbbLNdQXtiwbiIHAL4OQA/4L0/FZGfBPAjCA/8PwLgHwH428BkUubR6ua9/zCADwPAn7v91ZOr32VicDXWyuSLqC4o7PrSMqa0QVMuj1jP9PStbg8FTHkkFC9yIhLcGQmfTi/wer2yLnmUG7MQvP0JgwfNU8VanJyxyRkNFeIz83EZIGEQwwuz9uNlYIRBGO+5x+3S5KZ6LLEz5I7UzxlUMABgYXsO+rhdDB75GmbzLmuT9322cWbhuH+536qqSq67qf5hQMP1yMX3DGyR3T8HrNqfyljmwJUfNJQ11Xosl8sRqMo1fYtl0PWsViucn5/j/OwCznocHy1gCgMxWm87yv10Fc17/3sID4P58T9GYMtnm2222SbticCThBwoPwfgn3vvfx4AvPf36PN/CuCX4ttXALxIl3/RmoEcyMT7jjQ6DHD0XHa38cLGT/95JJ66Ldg9lZfPwEY/40WOGadwQn9evphx/RnI7ff7gVsrz6U0xYRd5g7kek69v2xx4/srK6Z14TZwGTkY4dfMiuU6IwZ3OgbaHyw817bnUYbcv3kfs+XvGQRNacNyEwn77AlCFvTuHXa9VRDIeZXUWFPE/cbzgsdcwbr2jQI8Bpt1XU9+Z7h/gODKVc0ZA62pQAyuj4J35xyapkFVVXj44BFWyw7GGTQLjfTn8XjbLpptttlme1faO4InCb+mPwXg0977H6fjz0Y9FAD8TQCfjK8/AuBfiMiPIwjGvwLAv/1iKvdX/83X4Vf+s99N2hx2QQHDhV9B0mXuIv2bh+KrPkgXqPxaXuiZmegzPPcMgmqVlG3ycPAY7jGnIIQF46wf4m1k8oVMmQBmlZh5mXJhTbUlBxx5G/kYbzLMGiO+Pt9AWRfyHCwwSAWQmDw2drfyuOXsmZalgQA5w8jt5L7Q/tK5wEAt7++8jzgZphFBYaJof3QV0EaAU5YlNptNSlmgxiLwHBBqPzA40v/5djbaDwqctE8YQOfuOm37fr9PGdn5HL5WmcnQZ70mSufiwcEB7r7yKoqiwPNHz0WNXYGy1Pk50TmzzXYdbWqyT8RJ+Wlp6H94m/g9K06OJ0+1tw9Hx1w14VEopsXTXyqbym7evTLOGt5sxtnfAcB++XPj67/qxcF7/4l68tonYZ6+GcB3Afh9EflEPPbDAL5TRL4W4VHzswD+DgB47/9ARH4WwKcQIvW+33+BkXZsnJcpX/yn3Es5w5PrhfhcNY4C08U1Z6P0fGUAeGHKAUDQgYyTdTLw0boxy2GtTVFTCs5YQD3F6OTtzO3t3CZ5P3G92C3Hx6dcYXqPqSgvNc6BpYv+lMg/r/sUq6Z9pcaupVwPNAUec5YyBy/5PadYOmdkdJ33HjZzfTHA4fJzMMPv8/rpnOPITv7PLtvcDch9xv2i/Zbn3mLAGu7ZoaoK8AbEzKSpPsq6Dq+88jKeeuo9cd4Gfm622Wab7Trak0Tb/TqmdUy//DbX/CiAH/1T1CvZX/uNr8dHvuE3BwsJgxm2KYYCGLpIch0JL6B8LtCnM8jvxWwFf54WIi8IOZ58WmByLQtHauWMVi4A1tdt2w4E2rlrUes25dbUcriv8vM0Mi9f1Jl1Y6DC7hw9n4Gg1nlKo8MMENcpZ8P0PF308xQHCjBVYJ9HQObgNmcftVwGcnl99LwctFsg7K2XuflSmV0XhPAigLWojEEV66L3Ym2QjqkmRdWHBj1H+0HZUjUdN663Gs877k91J7JLeAiKLUQM2lYGwQthTg+j/l548Xk41+Hu3bt4+PAt3Lp1KzJTJfLvzmyzzTbbdbArm2F8ynThu+wzoGdg8txEHHqv2o1cH6LlK7Cqqiot1lPMiF6TAwZrAzASDPUrzBaw5UCB66NAi98rYMhZNy5Lj70dI8Vgk+up/cQaHAWGOTuRA4qcQcnHQe0yPRv/zdmtPPGmWs7A6DU5aGImjdt8Wf9dVqfUb3Se9rV4D+tc2EgYCKCpqgZutYEr0A43lFZQ4/14z8UcbGnb9T0HLOhnOUCNPTZoC4DBPoPAkLXqy0u9QnXqXYiLxQLn52tst3scHy8uufdss80227vf3hXgacpFNcWmAOP96vQcXnyV9eEki7lpnhveZ0zL4QXLez8QeLOORDVQxph0TM9hjZWWlS92OZuh7WMGiF2C7HZktiKPKmTQxGCOwdZlDB4v/pxbiOui5Wp9lDHjeudjOuW60/7Y7XajftAySmJytK75vXL7f9l78zDZrrLs+36qejo5GQ4JU3ISEoYYEwYDRAbBkI8xhCEoQSK+GHjRCOIrvgIKihpeQcDPT0BBuCJIwmSMICYivBATAoKQECAjIZKJnJORzOPp6q5a3x97PVX3fvaq7q5zuk9317l/19VXV63ae0171153Pc+z1ipZE1mMcN+UVv/uCwty27FQ7Gzb1i9jerfdsHuOd2Lx5uXEbW4mJib690d063J8HPebWzZd6ETrZBSO1YzRLtrtyf4sO48/qwRbD5OTg7XGOp1OTh9YvrwcdsPutddemJycxu233QEka2yPI4QQ48K6EE9AM4YEaAoHoC6sGDOrbRTLgdkxOLbX62F2drb/S59dYdHVxe+jVcCtVhxQ3W63awtX8oDv9YnCjgdtHsQ9zYmDreNulyg4fVCN/cBtK1kgONan1NeM18eD8v1/DGZmscDixQPC+dg4A7Ek4HgLmGGWvpKA8vuDZ7VFerm+nU4HG6am8AAJZrdsmlk1I63gmuTyOD6J75XS7M54vAuhkgWtZCmsvjtzfVcquwFZXHmskgvvwX3c6Zfrgm9+vtO/XlUfGB78kH1w/30P5M+3O9xRCLFEbLq5PVB73+aq2p0D9yme3wtbYQHAblfc0kjr3tNciXzNUXhmd2+9rXho6/5mIHlrzz1q7222sMo71ol4YuHklhIe+GMAt58TYbdJjDdySm4RHrR4RexYHk/ljvEyHMwbBzTOly0zURCwWIyWG4fFQ4z1ipv78n8WMCVXWsx/GFxHdjvyIM2DOrc/uun8WM/X09xtGcUkW8KGCSeuJwsMx/sritT+vYb6avLb5ub6ljE/xy2OU1NTQIiN47WVSpZFP24xi2qsN/dbdOX5tfcAcBZALtaiRYsttZyn92mvm2CtakNioH7PtFot7LbbbrUfDUIIMU6sC/H0kgueijOf/J3Gr3CgvMAhUB7keUD1wTrGmwCoxRjFYFxPZwET6+QBv8zs7Gx/ixU/P7pV+JzSDDKetl5yPXEd2Crhx8ZAe06LMVQxQJz7Kg6oLjhifzj1gOPyQF0SEtwH0RrH4oHjnUpxPyV4VXhuH98PbiX08nq9Hgzoi6Ver4c2gKnch25xmrAWukjo0n5z8X5lMRstqf7er1+MHfKgeI7P48VI/Rx2CQ7KnoA30e9vh0WXu/E6nU4Wv4NZfoYWtm3b1hfoCQNrqa//1OnNYcOGDWgXftEKIcR6Z12IJ6A+wC5kdVnMUhLjYXggLy3MyCuV+7Gl2UmOf+YxUwBqgonP4fry62jVWijw1n/dD7MasRWDrT3RchHrwfmV+pVFX5z1F4+P7fU+ZAtTrAvHG/HaQiXLoltR4jWJrsVh/VlaSiAKYnaptbzslDDF62AZiUvUz+fyvW5uiYxCMB4T7zle8oL7Jl5/DgD3/CrR1uvn6X0XBWur1a7Nbuz1kJffGLheBxfMat+dTqeDyanJRvlCCDEurBvxdOz3n44zn/wdAPUBiaelM9HV5a/dvcbuLLckeNwKW2tK+62xMIouDQCYmZnpD4x+DFuP+HgXZaXg5pJY9LpxbAy3za0RbP3i/xxMXnId+WDt9YkuUT4mBs6XxFDJBRb7mOvIrkavQ2kJhTizLsIDd8nS5URrmsP12kYB4J42PT3d3zC4b0m0etksZvgasjWThR+Xy/Xja+n9082z+NjNyKLKhY+fU6+/Ww47aLWaoqty8fUwP99DSgbA0Gr5vdbChg0b+oHk8/Pz6HQ6SAmwVn3ph2HXRggh1jvrRjwBzQfxQg9otoCUrE/s0uDYjpKYAOquJ3dnsLUg/nKP1guOsSqtLr2QNc0XznQ3CwdscxwTrw/ln7s440GVzym5JKPgjP+HBWDz++huWswixdcmllGamefpbCXjz7jvS1Ykh8uJdXX3GN9Hfu0mJyeR5rvoIgFmmE89IA1cmNGaVWo/l82xUF4Xv9e4znFl+1JeXNe4TlT1v9xPnk8l6Jr3wtTUFFrWxszMTK2+A5dqfb++Yfe0EEKsd9aVeIqDAICG6ClZOCJuaeJBMoqs6elpmFXTrX2wZJEVZ8p5fm7ZKa0xxDFO/Hlp2xVuG8doAegPiFEocR38/+zsbENYsTWILRrRreYDpPe3Bx2z9alyA3Vrs77iDMBh9Sy54LxcvuYce8Sz2TjonWdK8n0QBUyc0cefeVv8Pa8m79Ymv3a9Xg89Awzl/Ie5OdmVG8uLx8Z72Y/z2XLeL1Es8YxSvucG/dpCr+evu42ZifxjYGpqCtPT00ipCvzfMLNb7V6cnp6uPkcvz66r6rPbho1V35kElBDbTeEZ0N60qZHWO6i5zch9D9+tkTZzy/3FYiav2tpIm7/r7uaBY2ZJ7t3f7I+YllJzCxhgnYknoBxcXBJIceCZmJiouX/iwBUHWx+cfOAAKpE0NzdXnMIerSHsugAGrpoY8MyDZMmSwpYir+tCbWdBwmKndK4PtD4wmg32SHPRUwq89vPYpccxSlyX6BJiWMT4+S4MWRR5vV00cLvj2k58HUv3hefLZUdrWOw7F4dRYJSuAwvQeH2jK89hKyhb3jiIn93Twyx/Xle2Mvr9xMRYPK+X9w9/T/bcc8/+61arhW5vHr3UQ7cXXJM2WHdrWN8LIcS4sK7EU3Qt8IDlA25JNLkIcGsPz0Bi9wLvJTc9PV1trZHPmZ+fx+zsbO28CM9+4l/nbllKKdXipTyfOIAPm7XGswFLsTps2eDyY395G92aNj8/X7OssXWJl1jwslkAcoxSxC13TlyziQWsf87WNhYObGHkPvb2sPAo1SP2p7etLwrIPef1nJyc7LvIWOxG4RQD61l4eh9FC1O00rk1i/uD3cosJtkVy/dAf5FOcvNy3f2ax3uO48NY8E5NTfWPjfcs59Xr9ZB6Ce2JfB8k67u1JaKEEOPIuhJPx11yJD73+G8AGDzA4xR1xwePYStauxUpWn5cLPm+X768QLfb7bvAgPo2GqUBm+OaXJhEa060VsTlCXgaOQ/OMV7K84rigOHPuBx3Q/EUfx7go0iLMV3RBcbt8zgxYOElA+J1i33KlqJo/eG+KMUYxbbz5ywUua+9j7hfSvsZlsQBi0PuzxinVrKURVio8/3OVr7SNfD/7BputVr9HwO8ZMZCrkZvt1v8WKxOTExU2xd1qoBxFrt8fnFXTCGEWOesK/EEoDbITedp4i404qDrD3k/hmOHfEDzX/w+o4m3nNi2bRsA4IEHHqiJn+iG4QEWGAgIPpYHIreU8aAXZ7T56yi4YiyMu5f4vOgaYuuG94m3ky0ZLNCihSXWk+vnZbiVr9RHbs3h9bWiGPFrxMKX10CKq3+zi5TrxALL+yiWx9eJF7lst9t9i5On8Tn+OlpuovUt1oHPZxeg18v7oGQ9442X/X7jNL4X5ubm+t8L3h7I+6XX62Fqaqrfb/yDIE4mcBe1w27Edrvd/160WwORmTCYgDFMMAshxHpn3Ymn4y9/Nk479JyaVSDGmAADocADRzzOBRMPZAD6wskHfd+brd1uVzOOyDrDFiYWUnEQd/HA57l4iS6s6AriNrEbhvOKsSvcThcCPpi6a4pXU/dyXAiwEIvWKMddeP4XXVetVrWFSbfbxf05CM+FA4siFpvRIsOCievBQsvdobHv4gKQbGFhF6HXqbYyeM7L84jXxtvP7s2SCzMGoPM9yVZM74vSkhWlOC0n/mDg5Qs8T3/P9fX+YeudH+9l+mbBUaS6SOv3Q3euYfWbnFp3jxYh1hzthz6kkTb72AMaaa1u84fKxh/e1Ejr3tTccgUAurR/qFga6/IJFwVRyWXA7iC2EABlF0kp/sbPWUhAcH4s5qJrhQdLtkYMGwyj2GNrQwzW9jrwYB8tVFEQcVs4hirO+ouWsEi0lnA/umjkfi2dHwXAMMte7Ks4qy+eyxY0T+c1mPwaTU1N1cSTi6FhgfoeUM1WGq5HrCfDwokFHtebhWMsm5e8GEY5Dq3XuM/cHRdhK1VKXXhR3m/+3eL2+z3K4pbbJYQQ48S6FE8+ZTxab/hB7bPGgGow8TV7gLJbzY8D6mLLrQVu9YlujOga9PMHg88GUrhbAAAgAElEQVTAEuJuO/4VH2NNStYjXviScesAiyZfg8fP8/JYRMRFGUtxL+y+jP3krz0YnIWJ96MPsiwOohhga1NJcERLjIsCXqohXk8+lq+B9xHXZ+PGjX1RWppsEGPQ2HUbXYAc0M3ihfu6FOhdEtKx72MQOdeJxZYLmHbbYJYwEEyGublB3FS1H11z8VbvI6+D39vd7iBwv9er9rUDEjqdwb3cn5mK+qzMYSJSCCHWM+tSPMVgWbai+IDL1pA4qPL+X0A97oSFiH/mooUtGPzL3vNiKxEP3kB9jaTFiK4UdonF8rx9Xp9q8GzXLC/cFj93MUsaW49KAobFGNfDxYO7dTgmiq1Mw6wrJSsUX+NoEWKLHhOFCzBwM3r5UYxGIcv1cEsktzXeC9FSFa1hvBZWJApUbyuLb28DMIj343L8mna79T0TuR4cIM/3SHRFe96eb99amQxAM54pugmFEGKcWZfiyQcSn+VTGpR5IPIBN27zwQLB4fx8jScWWiV3CQ/wLJi8DHdlseBhseC/9FkUsWDhRQ8ZH7Cj5cXr4cHpfDwwiIuJ7WFBFGNcouuS+5pjgLyfeTkIzt9ssNhktNDFgTcKBxa43E7uf86LrY3RRRcFXLQ6+vViaxqLIG4PC2W/JnGtLBdqvO1N6d7xfuR7A0D/WnLsVxTJg1ivKp5tZmamdg/4sSzifdZotG4NLFGD+yH1Bm5eLtdn3sESXTNZnIQQ48u6FE8vOv/nceaTv9OwnLCLC6j/Yo6DMA/UcYVwADXLBOfBwdq+8zyLMo5j8bJi+Z4/D/z+umRxcqJ7jwdXFwelxRTZkhWtWMBgjSHvs2j9YWHC+XF/+rmxL6K1bmpqqmbxiWsMsZhYyDrmx5csLH685+dCaHJyslZ2DFKPwsnLiOImWoj8WJ5FF+EZkSUXZWyX58tisNerz4zkIHinsvpV4sd/XMT7qN02VKuMD+4LvsZRXEbrFVtYecKEt7P6DH13nxBiCQx5dkSmt97ZTLzpp42k+XvuaR4nN/qysS7FE9DcMR6oBz/zFilx8Ueecs3uFnbjcZ6lgFgeYP38uOI2D8heDsdisfvMj2erRbSmAIN1meLA12q1+vFNbLkABpaV6Gp04eCDMk+ZTyn1haHXlfvQ6+VbhHD9vZ5etscV+UxFJ4oET4vWOxaK3A/ezy7Yer1eYxsdFy0++5LL4HvJ4YVIWcTFc0rih4PBeSkFFt58LdnVCqC2ATALFr73WLxwfJWneX/3ej10OoO1yPjaVHWor+/F4pnbYmhhvjtXE+m9Xg+w1A+wr/ptHtu2DbY1qI5vFftJCCHWO+tWPP3yRc/E55/wn/33bOHwQYRXaGbXmR/DYgEYuDAYHujYAsHChweukigDUFtHKv6qd+sID/rRTcf1jBYgFlrRuhUD0+Ng6+3m86N7p2Qx83Pn5+f7q0lHy1m07nnfcp08loitI7HOUTDF6xNdjdH9FY9ll2i03kUrGwsctoLFa8giKLoA+VpEEcZ9VIqd4vJirJ+fz/XxsqtFXgfCiMVTSoZWq755L/9AqPWzDe6DXrAkVTFkhl7Pv3OT6Hbn+kHmEk5CiHFl3YonoD7l3gcCXhmcrTAsoAA0BjpO80GE0/wXPFuvoiUiCh62vvivfLZm+Hku8Ly8hVxVsQ1uqRq2HAC7muIstZKYjBaf2A9R9EUxFsWTuz891sj7bm5uru9WYsFgZti2bVuxPK4HlzMxMYFOp1ML1Hd80Uh2i5b6NQoeF3psvQMGyxREoRiJLreS2PLj2ILplp3ofmVh63mU8gaqYHKPa6uWGuj1Y59SMpgNNliO+XKbvU4ucKsPDbDmnowA8nYu1feu0+lgfl6z7YQQ48m6Fk/RtcEzvTzYm600HCPDA0aM2ajHhzQ3u3WxUpqFxttZsFXA6+h5RCtPdK3FGBk/j8UPlx37JR7DVibPK7oDuS+5TLZGcIyXuw+jkOJ+9RW7o3jxa8VtjBs3lyw8JcHgAo37orRGUxRkMbDf28fHxH0El7LOEt938Vpz3l4uW5RcOJWsV7HcKJq8/myFMmNLVQvAoG/ZCleqJ/dLPy0BCW5lRL9fPaas06nuB3fRtlpa50kIMX6sa/EUV0z2hzhvsspT2z0exC1B0VXFlqNS0LALBi8junHcouBWFhcIw/bAc4HkgoxFiq/u7PCv/OhqinXkc3wdKK+n/4/xNGzN8jZwPb3/zKrZct62uLp4FWvTqdWBB3nfCoVdRH6tvB4uHriPWy2g1Rps3FyK3QLQr1u0ZHH/cSxcSaDyfxbIJfevw8Hy0cLF7YoWLb+GfL/wdY8uRP8fy+D21dtg6HR8e6H69fT2xWvh57pbtXbPGZB6ANDD/Lxbe1v5PrBa+6v7QssWCLEkClba7i3NQHCU0mTh3eksKp7MbAbANwBM5+M/l1L6MzN7JIDTAOwN4PsAXp1S6pjZNIBPAngygNsAvDKldO0K1b8WUxMHVH7vgdr+BwwGLXZjsQWIg5FL57GIibEjXicvv3RedPv5fxclcbB0NyTP4Bs2iy8KNh4geZD0enFgNwsKbjeLSZ5yH4PkeZsTL8+3afH+8Xyj5YXzrurlYnK6ZhXk/zFOjd2ZfH94GbxmE1+/aMlhYcLWIBY7XhZbzaJr0OviG/OyoO92uzWXo5cbLaBsveP2xlg/LncwgaCHlOpubu/nkmWP7yVeVsInBlSfDb5jviBnt4uGMBVCiHFkKT8LZwE8O6X0cwAOB3C0mT0NwPsAvD+ldDCAOwC8Lh//OgB3pJQeA+D9+bgV4VVXPLfowuF1ndyd4NYmdlfxoMG/+v1ztiQAzUDmmA9bK+L09yiW2CrGsS5OycUTP/OBM07390ExikkWUGw5cWsTB0xH0VSK72FXaKzrwG00KNcHYs+Tj/V6+3IC/npiYgrt9mStLHY1lSxRbCnzla/5c77ew/rZ6+x/bGGLK5LHvokuN7cAej5x1iHfS1F4x75mtxz3HdfD28aTJThvvu95dXcW45x/FPtVWt21HWP1eDV3IYQYNxa1PKXqiXhvfjuZ/xKAZwN4VU4/FcBJAD4C4Nj8GgA+B+BDZmYpBm8sE6XZcf5Ln4VVHIwA1MQPD7gAigOV5w8MLC7RTTJstpSzbdu22mcsLmL8EFAWLm7JcXzg8nbGgZkHy5LLidvL1qeS0PR8eDAuLTYK1PcF9DInJyeLFhB2afHSA16P6J7l8lhwcP+ymOWtUbjeLiCi+5b7lPuZr5Oned053T/zWCzPr9PpNK6vU+oXfx0nGPjx0QoVN3yO/eBp09PTDctoqT6M18mvz+TkRH8JiG53sPnz4N7QUgVCiPFkSQEJZtY2swsB3ALgLABXAbgzpeQ/LbcC2JxfbwawBQDy53cB2KeQ54lmdoGZXXD7bGHRr+2ABxa35rBLji02PEj6oBBdcFE4MSya/Fgu34UKB7H77LI4AHKMTpzxxlavuPI0/9L3/3FbFLZoxP39/PMo/thywW2L5XE+nMbHer19OQO+DsAgjirGfMVrxXl7egz+j9Ybh/ucLVecZ3RdLTTo8/ElK1O0hgIDITk7O4tOp1O73+Kxw+47tpr5dfTr7ZbWuPo35wkMBJ0LwZJo5BinaG1lqyRvVM0zBkvWWCGEGCeWFDCeUuoCONzMNgH4AoBDS4fl/6WnZWMkSimdDOBkAHj8Podu98/TOOhxUC+LIwANa5TH5rBLxPPkfP09ryAd429cHPjKzu5O4yUN2BXo5ZasRCUhEN1/LAB4gcvJycnalhxxRpvXwUWSW058wPR2+azB2AcOx/3E+nF7vK+8X9jyFJd7cAHQFwfJLS65n1vNWXI8wHMat4WFUxS5frzHB3m/Rotm6bwoDErxbt6W2dnZmgAp9Wl0fbHg8XQX0HNzc30BFoPMoxvP+8HdofE6+fVmQcciya+Jx8Zx/q1WC7Ozs32LV7ebskCbQLutYHEhdghZbtcsI822SyndaWbnAngagE1mNpGtS/sDuCEfthXAAQC2mtkEgL0A3L58VS7Wq/86WlZ4sPIBlFdyjufzufw+xtbwL38zw+zsbD/YPK7CzQPxsIHTP4uWl5IVARi4otjdxSLIB3kXSlEQ+oDq/71vSssFlPop1onry0LF+6zqtvKSAQ5bDUvXIg74pRgxFk6xb1mQ+jFRJEVBG4kWIyeWx5MOuFxOjxMQRiFajVwEs4vP68hll35QcB+x0HYB7UIq3kfejrm5LlIytNuTALr9+gghxLiylNl2DwEwl4XTBgDPRRUE/jUAx6GacXcCgDPyKWfm99/On5+TFvKB7CAvv/gX8c+P+3ptdhUPkLycQYxH4sEmzkTjAZ4HG8/vgQceqIkQzq/UXBcqvn1IXCMKGCzEWS022Gvkw4LFFwP1wT+629wS4e3h+JnSf24blzVMzLE1hN17Xt6gD3v94O/qmPr14T7wMn15hZS1UavVgm86y8JoIfdYzrV2XEp5BuVcN28X067VoSTU+F5wl1/JOsTXncWD3z9sFfV7IcaDcblcJxcy9X6tu155qYnYjiqPhAceuC+3ewZm1t+b0e8PF8+et1seY5C+17HTGfR16gHt1gSmJqdhreb3RgghxomlWJ72BXCqmbVRxUidnlL6opn9EMBpZvYuAD8A8PF8/McBfMrMrkRlcTp+Bepdg90xQP0Bz26KaA3hX+IsMIDmYoR+TozdicHppcHY8+Zf7zyIet6xLK+DB+RGKxS/Ls3Wiusz8edsoYiDfsnSxVYJFksMB0EPO4b7Jwq8eHyc8s/9zm3gfqw+H6yfNTjXkNKgP1l4xbJLgd/8OVt74nUotYGvg1txSlvH8Ln83l2x/MMg/kgo4ZZIs1SbCNDtujt2cM9Gcc35D7vO8/Pz6M4PrvmgT+vHCSHEuLGU2XYXA3hiIf1qAE8ppG8D8Iplqd0SefnFv4jPHvIfAAYPfY+t4dlRpSn8wGDWEi8vEIWJ//kijzxTK7pKHI6hikHoPGjFAYoFgp8XLR4uYljwcTnukoorbXM5MR6K+4RX3ObP4oKY/prjrAYBxD1MTEzWYst6vUHgehScLAQGLrUs+noJCXVx6OdyIHz1v+566/WAVouWaZgYzL7r9uYRBQhbt9wyw+KT7wsWXyzQPb+4dx/HVLErMYo9fz01NVUTN26B4ns3WrrqMWxztTS+v9rtyX5cXvyx4e46r7O3k/up3ZqATfT6Qev9ODq0YK3mcgtCCDEurOsVxhkefHzwLgX/8kAVByVO51/NPmh4QDOA/owlYDDARcuO58uDSCmwN/6yZ7eU1yUuieDHeKwVW9iiABpYIOqWMR5wo8WMLU1RyPlA6m4+FlEcczU52UarVW0SW9W9ElTeL0wULy6K2q0JEgqD6+Xl+CDPAqwKMG/Bs+SVyicmJtCyNgmkumDpC6wsBHgleoctL/FaDnPdDkuLefp9y9fLg8P5uOjC5OPZ6lgq0+/XVqs+QcJssGaY7y9YldvL13EQH2dmQLJ+H/XFcAtI6AHJtM6TEGJsGRvxBNQtI8OCZoG61WLYr2MWUvwrn90agzgeqwka/yVfd2WU3YoltwiX4URB5WnRtVWa/eZ/vDXIsMF8mAXMz3VLCi9l4AOnW2m8D3q95ka6pZlx/D/2gQ/mHhvke6UNc1e5pWSYKy2lhB6qmXx9gYFBTBz/jxY5np3I/RhnyZWI6VEssjBdyGLDVkdguEuxyr9uEWse34OvxeTXs7T6erS09a2ZifYzRA+wwcxIAPDV4YUQYtwYG/FUWnmZiek+SPnCkNEl4S4x/3Xvyw+wi8Pz8cEqBgnHYGAWUlwOD7w8yLG7KLaltBimBw7HwdfLc/cKB5nHAZJfc3vcihBnM3LAvIsJFlAsPOOMNAC1ZRP8mFoAfwtoG1lI4AtkdjE/34WhBWulmpBxgVNyabolB2lwHVwEM1xvTmOXI1/fmkUG9Ri0ygo32XD9sVss9klNYPeAbo7XSmguzVCqd2V9AqrqVHXxQHzv216vLsZYaLOLr3o9EIxevp8zN9+jPRR7uU0KFhdCjC9jM5/4FZc+C0BTuMQBzmEBEgUNgMYvdbZKsAslWhxKViOHB7ZSvTx/F3Qu3FxYcB2HWV2cOOhHS5S73aKgKYlMPy+6D72d3I/erpL1hAUJiyX+i3B+rVYLvdTtn2dmaLWb1zuuH1US0gm94nUfBm+jE/sRQEPMxj7iaxgFcbw23N/cXzFvtkBy/Vik84KWw65t7KsogGO53G8+45PPq4s7rVMjhBg/xsbyBKC/d5q7FngQYGsGMLBUsXWHj2W3kRMFgVtworDxAYvTPJ/oUnKRxANQjDEC6us9xan6Xi8PsnbLAU9t9/Zx3VyccdwMWx2caJnrBwYHgent6M730Ot6PlWQuNe31xuU6eVHMeFp09PTVb7oAcgDdgK6vXm0J8qC2OsxNTXViLnhQX1ychKG5szCaNXxdpcsZ9xf/j/OBox15OvGYoMFSRRNZoa5+YG7lI/l8rksFugDt63f1wNh7nnEPvQJFFwW7/vILm//3sU4QQ/4F0KIcWOsxFNclgBo7vvmxAEtuuzYbVE63i0cvHZPyS3nefOsKg7ojUKFy+7PCOuWd6gvuXw8nYWOB/R6naNLKgqIKO782Hge15XL7U97p4Ux2c3HgiTGfpXKZTEbxV08r2SRq8+8G6ySbSTIfB2pkkssWomii9bvgVjPkmgqvea6xePjdj1cH7b2DbPaeT7VX33GXtwqh8s1s5oFlFfG92vs9+Zg0dlerWwtVSCEGFfGSjwdc94R+NJTLyhab3gfLqAeq8RB0OwKcfhXfSnGhS1XLmh48PRYIx90ePZbhK0VXG5JZEShNjExUbO2sGgYxKQ0cauXH8+WKV/XygO3WayVVqeuxIlbKrpotQYib3Z2sO8eB4LHtvNsSXZbxmn9LB6ju6vaUajpFu3/oS6ozAbbyADNvRC5P/3eiOLRj4tCruTuitfI+8RFi/elB+GX7keGRWcshy2DZoYHHnigdqy/7vV6aLf8e9KqWQh9goT3z9TUFLrzVYB5tzef+7CFbncOExNT6PXKruu1iFWq8gIA16eUXmxmj0S1+O/eAL4P4NUppc5CeQghdi3Wx9NtO3AxwAPJMDcKkC0KPQz9nIkrmcfg4FarBSRD6g0CpWOsTHRVNeoSLGExoN3bNyyP2O7ScbzEgQ90vAQDUN9vLtYttp3P4fPm5rqYna0EatycmP9Y8JZmEbLVali7eR+2KHp5ggD3T+wDpuTS4nsr9gmfw22LYpnPiXFTXC8XiOzWLdWdY65YzMfYqfn5eczNzfUFfUnQcZ97PXlGJQtxdofz7M9oWVzjvAnA5fT+fQDen1I6GMAdAF63KrUSQqxZxsryFEkp1WZS8QO+f0wP6HXpAZ8MVXzN4JzoSmq1qm0s3CrjuDtk2wPVQpq1eKmJpqXJ68N5M+wSjOfF1yWBVBrUo0XC3Vg86xBAwxrHC4hGEeBiyQdRFg9zc92ahWbYvnUxvoZn3kULTum6cl9XxzcD8lOvKqeKH8rtsPrim44vssoxWf6fg/2dGNTvlqMYF1aarRjFXGmWpQsw/4xFC1tBBzPpBmLX6+b3qx/L1q6UElo2sCR253tIqM7zRU49P3bj9dLA2lb1USXyfC2ptY6Z7Q/gRQDeDeD3rboIzwbwqnzIqQBOAvCRVamgEGJNMpbiiRdFjP/ZBcO/yJ0oDHiBTRYH/ku/EY+UFwfk/KuYkLrLLa4VVIpr4gEw1o2tFfE8H+BK1pDoKouDug/mLBzisQyLCxYGUbjE+CaeHefHRXeXn8filVdNj8I2roWVUoKhhe58rzZTL/YV3wc8K42FSKnMpfZ36brySuFxdiKfE93P7IIr5c+CjYUO48e7QI73REoJsMHMUC9rfr6D+fl5TExUYoqXbIhWvnjvrmE+AOAPAOyR3+8D4M5UbXgOVBudby6daGYnAjgRAGaw2wpXUwixlhg78XTMeUfgrGde1H/Pbodut9sfSN1awcHb/sCfmprqDx6+p5gPqiml/hYtjZlZ3ZRnhgGznU4/rqbb7WKi1dxfjoluL05niwdbqmIQeslCxVaIhYSQ5x1n1XW73f5sqomJCXQ6ncEMsLwlSxSfLDKj66jaZ83Qbg/WborCtmRNc2uG1ysKlRj83ncF9uou0pRSDmRHzWri+D3Boi9eI7ZEsfuM2+Gf8UKq7P50gc3XkV1jXBb3C8+c5H7ie8utQrxoq/cbC0EW8IP+m6wJu7hdS9W+Tj8/36ev/kOkh06nvlbVWsTMXgzglpTS98zsKE8uHFpsRErpZAAnA8CetvfabagQYtkZO/EUqeKOEjqzg4c/u9tiDE673a5+kVvdPROnabsrBGhahnzQmWhP1mZ3NeoWBhbPjwc3dtGUBvKYn/9Fyw/DLh/Oi/9PTU3VpuCzYGAXG1uuWAgA1QrT1SBeBXDzYNzrzcND7th6wlYTD+CO1gyHg85ZYHj9AcAmmhYtfs/Cma2CsS3RChf7zIWSt6Xk1vP28fWJVisWNHzv8dpiXH8XV3xPxsD/KPKYvsBJNtiLsQV05+prcrn1Kgpdj5tjV6AL63XAMwC81MyOATADYE9UlqhNZjaRrU/7A7hhFesohFiDjGXAuA8GSIZOp9MfZBl/0Ed3Eqz6Y8uJCyfPJ1poPD+2NkxOTvYXEJyYmKhWwi4Mvmw98PRoSQHq1qh4/LDz4iKg0VVWIsbT+P/SjDz+44DmUpmlta98ant0kzlcX66zC16/DqV1r6KLkOsVrwH332KWEj4uWoC8naV84/pPw8phy9L8/HzfQlVyafL7OCOP4X5hAerXzf/aE62+VY7dl1HUs2iNVr2F6rHWSCm9PaW0f0rpIADHAzgnpfRrAL4G4Lh82AkAzlilKgoh1ihjaXl6/rcOx+cf/00A5bVzfFDwqf1mRgHdPaRkDUsGD2jRnQTUrSc+KPkWIP3Ykh7Qag9mIw0bnKIoi7E4cbkFH7D8Nc9+ihsTxz6I7ic/P6VqCYe4H56v6RMD793F5xabwey9wR6AnuegnIlGALT3Q0kw8KzFGGhfirHiZQyiaIqWQw8Q52UauGx2FUYrS0pVbJy7eFmksHWLy+cyvO6xbTEWq9Pp9PvF6znsh4H/b7Va/WtWd70NNj3mNvP9Hq1M/JotbIYWkLfImZqa6LdhHW8M/IcATjOzdwH4AYCPr3J9hBBrjLEUT8DgIc9iJ8aS8MBjluChDTywxjgRH0SHucP8/Mr6Nfis717qVrOY2BUTZ4rFWBbPO1qpHBZRPCDz+QyLN/7PAozT2JpSqkN0fZWCwAez0epCzvuz7zKi470OpbWc2JrEn0WGWehY6LEFzc/hdpfyjuLX4784dmxYvaKQ4+vA6Xx8t9vFxo0bcdVVV2Hz5s2NOKl4bmnmI2/cHPuE+2ZQbkJKVrsOsbzqnF7DzR3F9VonpXQugHPz66sBPGU16yOEWNuMrXjyoO5W25BSFhioz65rTwwG8uo57w/+QbxGXEGcrQg8E88tES4G3EqQegNx42vseDA6WxY4/7j3XZzG7/Bg5/+j0IjHR2tX1fbBVi58ngsCt6Rw/JG3mS0rcQX36n3cZ21Qpv/nPp2dne0LW7dY8VY7LAzYRcfxQc02e1wUistLsCXS8/A6xCB2v76ldrNr18/xv4UslXx/+R9bt7xOs7Oz2G+//RquQm4Pf8Z1c0tQtN6V4pWqfh2sSN7p9GpxZf4jxC1tfD90uwntdt31K4QQ48bYiqdWu7kWEuABtRP99yxKBhaANlqt5vYh0d0WrVGlrVI83/5K2amLlg1+kccy3J1Sa0urGVjNeUdLmYsJtpJxGS6AopuIB3PejoPjddglVbKYAPWlIngA5TqW2uADPLsFua68AniMg4r1aLVamJ/v5NlgbsUaLCPh9WFBOLCgVcHsMc9h1kbe43DYsXwN4nt2W7LL0/NPKWHjxo2YnZ3t14lnifL9yxapqamp/mcuKhdbRmAgausiLn7uliwhhNgVGdun36uueC4+e8hX88Pe4zraaLXcRQekBKS8KGYlQDq1wYHFULTKeAxSjCmKQiUhYbbTqZYxSAkTk4OYkMVia9jiMizY2a0JvJCh1yPO3IoWmzh70I/l9rioiPlxOW4h8hl6Hivln3lwt5/LAsZddrz9i3/uViUXTsMGa47TqWLW6ms3VRa0+ka5fE2b1qAeEPbk47I87w0bNhSFhbclCqZh8DV211qc4ej9ND09XZtVx+2MViBvk68mziLbz+ENq+vnsWXSjx/Uly2Qfv9VPxDmkZLhpd/7BQDAx+7ffdH2CyHEemNsxRMwGMza7cFaOzz4+bjGAzT/smfiIMmDx0LT0P1/ZQmzopXC3/tg6HmXYmMYT+M1qLyu0brAFg2uf4z9ifnxcXELELcweZtKC0xyYDO7jGKfRpHAQi9a0jj/2L7owspXrBaDUxKtXI9qqZ+6a7U0E5DddVxmtNaUrlmpfO8ftjyxVcn7JW7sG/sgWuSWUg92QfL9w0HmJfcsl9Vut/HS7z2tWJ4QQowTYy2ejr/8ufj8E/6z6Hpz3BIC1NcI8gHQLQFxCnocqEsuO/98cnKy70Jxq4RbW0oxNCxguF4cG+ODm1ucYlxQ3RrTjLXhzYu5zWzNiJaTVqvVXzDTP2e3F++z5mLFN6H1wb4USMxWPd5bL07vZ2ERZ325hcX7cWClagEY7Dc42PIFSNZclNNfdzqdfjlmVnOBRbctt8PbydvHOPE6+v8YV8XtjFbN6Oblvoiiy0XnMMHp92N9dfMuUhq0n8th65TX9djvP73RTiGEGHfGWjwBzbV84mdxhpoTXSALzRwqzS7zgcsHX15kkdeJKgUks9XGiVYWzr/U3miBceuRWy9YxMRBnPOKFihuox8/OTnZsMKwkHDB0Ol0GmsNeTlzc3MNNym3vVQnfx9dj4fXwcAAACAASURBVIN86mIiuh1LMWF8TMkKWerXOINtmOWI61bqAxbHse/9v4sarjsLypLrzl9HCxW7b305g+rz+ZroGty3VXm/fNEzIYQQuzK7tHgqWUxKMSw8QPLAyMLH43uGTSH32X/RzcIDnv9FKxa751iMDLMQ8Xk8SHu+nU4HZtafLeUz3HzgjwO+t8MHWrfUuZWIrT4e79RqtbBt27Z+enRn8YDPg/liQdfcH/E6lIKogcEsupSTqhmYzen58T9b1qIVj9sU8XW+4r0Qg7X9M84jHuN97+3hle5nZmb69eD7J8L15YVFXfTyfV/lP9+v8+TkZD9+SQghRMXYiyce+HjGEdBcAqBkZYiDvR8HDMQDLyTpAzinubvK8+OtLty9w/FG7Ebk+kerDs/OKlmxAPSFjJ/n/3nw93pHKxP3nwde+/l8DLcvxuzweWwtiQIhxhTFvvZyvE9irA0HPrOQ7K9tlAy+ejx/zm7Quut0IHDjwpls+Svl5fn1Z1gW4qZKa2rxYqLc937vuvVuZmYGU1NTNddavA+itQ6ou+L4M74ucsMJIcTiLCqezGwGwDcATOfjP5dS+jMzOwXAswDclQ99TUrpQque2h8EcAyA+3P691ei8kvFBQtbLoD6UgNLcXX4sf6ZC5NS3BKX4wMpD7YxlojLZHcfgJrY4virXm+wSjSfV7JYsAhkoRDbV3Jhch4xONrhxUg93evNgorbHy1m8fqwkI0rikdxwNeAP+/XkRZB5fP4dfW+aUlilxqfF61kLIT8feyvKB7j5INhVkQve2pqCikl3HXXXdhrr71qwpSvU+yP0jWYm5vDzMwMAODF39WakEIIsVSWYnmaBfDslNK9ZjYJ4Jtm9uX82VtTSp8Lx78QwMH576kAPpL/rwrHXXIk/vlxX69NzQfqMSjsngPqi1YCzRlR7s5w4cTxPbwEAVu4eJYdu5dcIMQZbnwMD4K+35lbKbiOLLJicG9057BVo+T6icHFMcDcy/E2s2sqrpjOeXG7hwmdKBr5WvE6T1HU8DXjfmNRV33uQjEKlV5NXFbXpV3ru+imi7FjUazwoqVs+SvB1yoKuyi8pqam+u5WjkWLbl+2UrqbT0JJCCF2jEXFU6qe4vfmt5P5b6HFa44F8Ml83nfMbJOZ7ZtSunGHa7udlKwbQHmF8GHnsWBgl5zHAPEAF7c0YcuID848G4vFjQ/AcQAFytYvT+dYKBZPpfWR2LoUrSc++LL1igWK91sUaywaShajkjWF2xCPiUIoCsAoaEuw2GCxONh2hQO9mxsvs/CKrkZvKwvPGEDOom6hOvofXyfuc55sEPtn2EQGbq+/f9H5P188VgghxGgsKebJqn0avgfgMQA+nFI6z8zeAODdZvanAM4G8LaU0iyAzQC20Olbc9qNIc8TAZwIAPttfPiOtmNBfuWyo3DaoecAqMfYUF0aA3WkZMnhXebZBcbLDABNiwoPkr7UAA/SbFWKQdYuqjiWydvFwivWO05xj1YfL3dycrImDqLrj/OOSyu4646tYfy65B5lax9vtRKFXSmQndcginXkuvKilYw3hffmc0tk9XogcF2gxrrEvuUYKT/Wr5e3h+OdOL+SyzjGefnSAmwpZJec3zOtVgtHf/tJEEIIsfwsSTyl6mf54Wa2CcAXzOxxAN4O4CYAUwBORrUT+f9BtcJgI4tCnifn8/D4fQ5dfBnmHWShOBInipFh7iD/nAfNuBQBCwUOaPa84j5x7KaLs/xiWXFWFVu+SiLQB+e4qGKpX0qCJQaBsxuNyyy5EjkvtkrFclmQRDdqhEXgQpQsa/XXbZgN3JZV3Vowq/cx3wvRnenXM7o9+d5xaxef57FK3E4Wq7FtcVsaL8+FuN8/x5x3xIJ9IoQQYscZabZdSulOMzsXwNEppb/KybNm9gkAb8nvtwI4gE7bH8ANO1rRHSUOfmzpGSaMSsG8/LkLIhYlceq3n+fl+WDHefNrHjR9Ww1gMHjyDEG3TETLFlvXfGCPbkXHy+Qg9Gg9in3D7eKBPx7LfezuQHdpxv7h9acc79cYN8RWttL1i5aYGDzNfdXrJfh6UCkBnlUUPxzXVltKIlX5T0xOAlbVZ+PGjf26x+NdWPOmx26VYjestzfGYLHbV644IYRYHZYy2+4hAOaycNoA4LkA3mc5jsmqJ/7LAFyaTzkTwO+Y2WmoAsXvWs14J2fY7LGSe42tSbz0QLTYxEBeht+7AODlCqILiokxNWzpieXzjDbPl/9KVhoWNZ4vW81Y1MU6xfPZtVgqK65ZxQIxWrUW68dISTjFz0suSq5jMw6qLBY5CN7b1Rd6lpDQw4aZDY1z2R0Z68bxaFGsxbI47ZcufMbQNgshhFh5lmJ52hfAqVbFPbUAnJ5S+qKZnZOFlQG4EMDr8/FfQrVMwZWolip47fJXe3RK22W4NSGKDQ745k1xeXD3eJuSuGHLFRPFSPw8CqL4WbQGcSwPu7pKW3rweez2iSKOLTZc3jDx5Na0lFJxHaHSrDPuDzPrW1Gi0HGBEuvP/9lyFtvE+cQ8WPSxdYdjkUp4XTmwfmZmprA6en2pidISD3GPOK4D97/2ixNCiLXFUmbbXQzgiYX0Zw85PgF4445XbXn5pQufgS8c/i0A5a0/orWEZ6tFkRWDfdm15Gkly09cMNGDk6MwiUImzt5z9xaXEZc8KG1AzHkPs4aw8OC4HM/HXUzsbiwFo3u9OEbI2+r1i0H4/pm7ROO1KbndXLx5Hn5e7Ne43AALtSgO2RXJlqGUUk3ocf0H17bXyDOlhNQbLO2Q0KtZMvk+kVASQoi1z9ivMM6ULBgxTogtESVKQd2OD6zsouM4o8XcfjFQHKjHFbGFjInnxvaylWWYIIlijz/zdsclDPyYYcsRsCWP43qiS5DrW+qrEnytWCjFoHlmmBuyVGc/nuPR2LLl144FW69XF3xVewxIhpRowcxkmJ/L4rdVlfOSC1ZtKTQhhBAjskuJJ56SHmOgYmxOaaFHHnB9Sr+f65/5zDq2ngwTFx6A7HlEIcAWG2Aw+JesK6U4KhYspXWG2ELEIojz4HpzDA+vKB7bFvs39jWvk+Xwsg8xz1I7eSsTFnRTU1N9oVOaXcgCOgbaO9HtybPoPA93r9YFp+c36J++BS0NBOzLL9HGukIIsZ7ZpcRTjDvhmWvDxAJQ31OtZJ2KSxbwwA2UF+As1asUj8NutiiA2JLj55UCtD0fFlIxreQSi5Rm6Xm9uf3cvzHPlAabB7Mo5TWjuB+YaBXjtpf6jvt1mOuPxReXGQUbl+nt8/8pDYLsuf2ed0oJhpZEkxBCjAm7lHg6/vJn4/THnlsbKFkM+WveAJetDBzv41tjsNUpiiagvpBk/B/XSWJrFU9HByqLjAsFD1ZfSGiUgsGBgZDodDqNWW7RncmxPFF4xjb6Ao5cHq93xRY27892u41t27YVhWnJrcYxVFE0xeNLLtmSSAXqW8/EBU5ZAHG9XDxXdW7la9eDWdVWzYgTQojxZZcST0B5NfFhcUAlN40HKMeVu0uWjlJcDw/YcYYWizB2KzlREHCwNAdjlyxHnu4uRbb2cFv8v7slS66tUuyYH8trKkWBE89htxeLvYWEk18Xr4OLyoUsh8P6gsVlDM6PfRjFY1WmlzNYMPQlFyjgWwghxp1dTjyV1hliC4u7lTymhmdFsUvOZ2KxQGDx48d7OXFRTLZcuDCI6zpFNxlP+49B5CxAokuO2+ULb8ZyWCzEAGwvx9/HpRTYahVnJUZLm6fzdH2vd4wN4zrxLLdut1tbFsEXnVwscD1e+8E2OQPRaAZ0u3O1rVk8T2+3X4sXna8gbyGE2BXZ5cTTyy/+RXzu8d8A0LScsDWGY3Y4ANuPL7mW2AUXV5aO1gzPw4VLFFBct2hVipYz/z/M0uMWMxZOUdiwlc3rX2KxmXBxvalSnfnY0lpH3AauYykui5eU4Jijxeo4EHgDgVu576wv5FqtFnrdfB16gLWqMrUFihBC7NrscuJpGCWB5G4xYLC20tTUVF94cBA3D/ounHhqO69gXXJjRdEU6xXjkfwz3vOM683nuXiK++v5X1xvyWFhx24rds1xHWPMEG+Gy/UquUrdogegb1Vyy57HaLmrkzdW5vOHLS7KdWy1WmG2XwtueQJa6Hbna0L2mPMllIQQQtSReCJcgExMTDTWc3JhwIO1CyMO5k4p1QRNdNV1Op2acHCBwvFGMaDdX8eZdFwPjl9iq9fc3FzRisTCqRSbxQtgcjxWFD4LxZDFNpWsQV7/+fn5vvhxoeUxUW7BYmtgdDuyOCtZ7uLaUnXx1kJKQK83WM1c1iUhhBDD2GXFU8kF5P9ZDPGK4DyAx73u/Hy3MPnnvV4P09PT/cHb07vdbmMhzShG2FoSF3j0v7j1iIsdXmcIqLvhXNCV3GrcbhZFJeHmbXELUXRLsjUpnsPXIPaD15FXSeeAbiC70cyqfeVSeakEP8evF4s6dtECEktCCCGWzi4pno675Ej88+O+3ojDYTE0NzdXszqxmPCAcneHuejhrTxcSLXbbUxPT/cHbJ7Sv9BK5mbWn/HGC0K66IpiwokxS5x/KcYpvi9ZkrjuLEqiBSqKSX/Pq3JzmtePF8YsWcO4rX2LH9x12GvkwX0xPT3dmE34gv9q7DYkhBBCLJldUjwBzW04GHY3xcUg/VwOvo5WqhgEza65hVxYbP3h2J5oJWMRE2OH+HVpqQP/77MFvTwu28WQ193TonWJ28jls7UuWszia46rGtYvnmc/1qoHWGuQT2nzYLY2uWg7+ttPKuYthBBCjMIuK56Ou+RIfP4J/wmgKZ5KW3Gw1YTdPi4qeLsWFilsZeJ4JxY/0YLjeflinTyN3/OKbjS2yrDQcaE0bNabizpuM4sZngnodeRzuWwWTfyfy+C4plJdouDyvvJy2u02EnropYReN6GXuo08AOCXL9Jq3kIIIVaGXVY8AU3RFGedxbgYoLwGUXRjcWCzCwaOcfJj43v/Y8uX/4+CZqE6RbfbsBW7WVTF7VHYEuWfl1yMMa0UfO51LAkvPye6EReyzA3yalrBjrvkyGL5QgghxHKxS4unUhA0D+LD4pH8OLcQAahZeIAeut0egDbm53tIydDpdGqWKA/WjsLLy3XrEruhorUmBknzNHwXIL6iOJ/DwtDFU4xnYtHIIi9ap7gevDQBi8CYX+zHGBPFwokX8IzXRlugCCGEWA1sWIzJTq2E2U8B3Afg1lWsxoNVvspfxfLXQh1WovwDU0oPWeY81xz5GfYTrP41XG7GqT3j1BZgvNqzlttSfIatCfEEAGZ2QUpp1eaLq3yVv5rlr4U6rHb548C49eE4tWec2gKMV3vWY1vKASpCCCGEEKKIxJMQQgghxAisJfF0sspX+btw+cDq12G1yx8Hxq0Px6k949QWYLzas+7asmZinoQQQggh1gNryfIkhBBCCLHmkXgSQgghhBiBVRdPZna0mV1hZlea2dt2UpnXmtklZnahmV2Q0/Y2s7PM7Mf5/4OWucx/MLNbzOxSSiuWaRV/k/vkYjPb4U3ZhpR/kpldn/vhQjM7hj57ey7/CjN7wTKUf4CZfc3MLjezy8zsTTl9p/TBAuXvlD4wsxkzO9/MLsrlvzOnP9LMzsvt/yczm8rp0/n9lfnzg1ao/FPM7Bpq/+E5fdnvwXFnNZ5ly8Uoz6f1wKjPm7XMqM+O9YCZtc3sB2b2xfx+/bWFV3Xe2X8A2gCuAvAoAFMALgJw2E4o91oADw5pfwngbfn12wC8b5nLPBLAkwBculiZAI4B8GVU+488DcB5K1T+SQDeUjj2sHwtpgE8Ml+j9g6Wvy+AJ+XXewD471zOTumDBcrfKX2Q27F7fj0J4LzcrtMBHJ/TPwrgDfn1bwP4aH59PIB/2sH2Dyv/FADHFY5f9ntwnP9W61m2jPVf8vNpPfyN+rxZy3+jPjvWwx+A3wfwWQBfzO/XXVtW2/L0FABXppSuTil1AJwG4NhVqsuxAE7Nr08F8LLlzDyl9A0Aty+xzGMBfDJVfAfAJjPbdwXKH8axAE5LKc2mlK4BcCWqa7Uj5d+YUvp+fn0PgMsBbMZO6oMFyh/GsvZBbse9+e1k/ksAng3gczk9tt/75XMAnmNmzc38drz8YSz7PTjmrKVn2ciM+Hxa82zH82bNsh3PjjWNme0P4EUAPpbfG9ZhW1ZbPG0GsIXeb8XCA9pykQB81cy+Z2Yn5rSHpZRuBKovHoCH7oR6DCtzZ/bL72S3zD+QCXtFy88uqCei+gW10/sglA/spD7IpuoLAdwC4CxUloo7U0rzhTL65efP7wKwz3KWn1Ly9r87t//9ZjYdyy/UTTQZx/5ajWfisrPE582aZsRnx1rnAwD+AIBvfroP1mFbVls8lX5J74y1E56RUnoSgBcCeKOZHbkTyhyFndUvHwHwaACHA7gRwP+30uWb2e4APg/g91JKdy906ErUoVD+TuuDlFI3pXQ4gP1RWSoOXaCMFS/fzB4H4O0AfhbAzwPYG8AfrlT5Y476aw0ywvNmTTPis2PNYmYvBnBLSul7nFw4dM23ZbXF01YAB9D7/QHcsNKFppRuyP9vAfAFVDfjze6WyP9vWel6LFDmTumXlNLN+UvZA/D3GLilVqR8M5tE9SD7TErpX3LyTuuDUvk7uw9ymXcCOBdV3MImM5solNEvP3++F5budl1q+Udn90ZKKc0C+AR2QvvHlHHsr9V4Ji4bIz5v1gVLfHasZZ4B4KVmdi0q1/azUVmi1l1bVls8fRfAwTnSfgpVYOyZK1mgmW00sz38NYDnA7g0l3tCPuwEAGesZD0yw8o8E8Cv5xlPTwNwl5ual5MQw/JLqPrByz/eqhlfjwRwMIDzd7AsA/BxAJenlP6aPtopfTCs/J3VB2b2EDPblF9vAPBcVHEYXwNwXD4stt/75TgA56SUtvvX2JDyf0QDiaGKM+D2r/g9OEbs9GfZTmA1nonLwnY8b9Ys2/HsWLOklN6eUto/pXQQqu/IOSmlX8M6bMuqR6yjmtXz36h8uH+8E8p7FKqZMBcBuMzLROV3PRvAj/P/vZe53H9E5RaaQ/Ur9XXDykRlxvxw7pNLAByxQuV/Kud/MaqHyr50/B/n8q8A8MJlKP+ZqEyxFwO4MP8ds7P6YIHyd0ofAHgCgB/kci4F8Kd0P56PKiD9nwFM5/SZ/P7K/PmjVqj8c3L7LwXwaQxm9Sz7PTjufzv7WbbMdV/y82k9/I36vFnLf6M+O9bLH4CjMJhtt+7aou1ZhBBCCCFGYLXddkIIIYQQ6wqJJyGEEEKIEZB4EkIIIYQYAYknIYQQQogRkHgSQgghhBgBiSchhBBCiBGQeBJCCCGEGAGJJyGEEEKIEZB4EkIIIYQYAYknIYQQQogRkHgSQgghhBgBiSchhBBCiBGQeBJCCCGEGAGJJyGEEEKIEZB4EkIIIYQYAYknIYQQQogRkHgSQgghhBgBiSchhBBCiBGQeFolzOxaM3vuatfDMbM/MrOPrXY9thcz+yUz22Jm95rZE83sMjM7asixR5nZ1p1cRSFEgdX8PprZa8zsm0M+O8jMkplN7Ox6DcPMvmxmJ6x2PbYXM3uXmd1qZjeZ2SPy87o95NiTzOzTO7uOS2XN3BRidUkp/cVSjzWzkwA8JqX0P1auRiPzVwB+J6V0Rn7/2NWsjBDLhZmdAmBrSukdq10XsbqklF641GPN7FwAn04prYkfxWZ2AIA3AzgwpXRLTt59Fau0Q8jyJMaFAwFcttqVEGKtsdKWk7VkmRFrmgMB3EbCaV0j8bQGMLOfNbNrzOz4/H4/M/u8mf00p/9uTn+4md1vZvvQuU/Ox01mE/S3zOxvzewuM/uRmT2Hjt3PzM40s9vN7Eoz+036rG8iJXP1CWZ2XTaz/nH+7GgAfwTgldnkelFOf42ZXW1m9+Q6/9qQtrazi/CqfOz38i8SmNkvmNl3c92/a2a/QOeda2Z/ntt3j5l91cwebGbTZnYvgDaAi8zsqnx83y1qZhvM7BQzu8PMfgjg50Odiv1N/XK6mX0yl3uZmR1Bnx9gZv+Sz73NzD5En/1PM7s8l/sVMztwibeEWKfk++7tZvbDfN0/YWYz9Plv5u/e7fm7uF9ONzN7v5ndku//i83scWZ2IoBfA/AH+fv2b/n4ZGaPoXxPMbN35ddHmdlWM/tDM7sJwCdy+ovN7EIzu9PM/svMnrBAO55vZlfkuvydmX3dzH4jf+bPmfeb2e0ATjKzR5vZOfk7cKuZfcbMNi21X/Ixb87tv9HMXrtA3V6bv1f35GfOb9Fn3vZiXma2T+73u83sfACPXuSScrkvz+14XH7/tNyPd5rZRZbDBMzsFWb2vULb/jW/PsXMPmpmZ+U2fJ2fDbb4c5CvwzfN7K9yn15jZi/Mn70bwC8C+FC+bz407B4b0ta98zW6Ief9r/RZ8R7OnyUze72Z/Tif9+Fc7nMBnAVgv1yfUyy4Rc3skbkv7jGzswA8ONSp2N/UL43xgT5/Jp27xcxek9Onc/9dZ2Y35+uyYfG7AUBKSX+r8AfgWgDPBfAkANcBeHFObwH4HoA/BTAF4FEArgbwgvz5lwC8gfJ5P4C/za9fA2AewP8GMAnglQDuArB3/vzrAP4OwAyAwwH8FMBz8mcnoTLxAsBBABKAvwewAcDPAZgFcGg8Nr/fCOBuAIfk9/sCeOyQdr8VwCUADgFgOe99AOwN4A4Ar0blTv7V/H6ffN65AK4C8DO5TucCeC/lm1C5Emv9m1+/F8B/5jIOAHApKjfIUvr7JADbAByDSqC9B8B38mdtABfla7Ax9+sz82cvA3AlgENze94B4L9W+77T3075Xl+a77O9AXwLwLvyZ88GcCuq7/w0gL8F8I382Qvyfbgpfy8OBbBv/uwUz4PKiff7KVTOUaieA+/L5WzIZd4C4Kn5vj0h13W60IYH5+/zL+d7900A5gD8Rv78NTn//5U/3wDgMQCel8t7CIBvAPjAEvvF6/t/UD23jgFwP4AHDenjF6ESPQbgWfnYJy0lLwCnATg9f18fB+B6AN8cUs5BuZ8nALw2f58fkz/bDOC2nH8rt/223PZpALcjPy/z8T8A8HK6VvcAODIf+0GvA5b2HOTrMAfgN/M1fQOAGwBYPHaxe6zQ9n8H8E8AHpT78VmL3cN0X34xl/EIVGPM0XRttpb6N7//NoC/zvkemfvo04v1N7W1OD7ketyT+3IS1XhzeP7sAwDOzP2+B4B/A/CeJX3XV/ths6v+oXqYvBPAVgD/D6U/FcB14di3A/hEfv1KAN/Kr9sAbgLwlPz+NfzlyWnn5y/iAQC6APagz94D4JT8+iQ0xdP+IZ/j47H5/UYAdwJ4OYANi7T7CgDHFtJfDeD8kPZtAK/Jr88F8A767LcB/F96v5B4utq/wPn9iRiIp8X6+yQA/0GfHQbggfz66ageDhOF9nwZwOvofQvVQ/zA1b739Ldyf/m+ez29PwbAVfn1xwH8JX22O6rB7yBUg9J/A3gagFbI8xSMLp46AGbo848A+POQxxXIg2JI/3UA36b3BmAL6oP2daX20zkvA/CDJfbLUQAe4O8RKqH3tCX2+b8CeNNieaF6Xs4B+Fn67C+wuHh6C4Afov48/EMAnwrHfwXACdTf786vH4tKAE3TtTot3AddVM/opTwH+TpcScftluv78Hhsfj/0Hgvl7Qugh4J4xQL3MN2Xz6TPTwfwNro2RfGESuDMA9hIn38WgzFpsf4+F0PGB1TP8y8U2mIA7gPwaEp7OoBrlnLfyW23urwelTXia5R2ICrT5p3+h8pN9rD8+RkADjOzR6FS33ellM6n869P+S7I/ATAfvnv9pTSPeGzzQvU7yZ6fT+GBPellO5DJepeD+BGM/t3M/vZIXkegOoXQmS/XB8m1m9J9RmS95aQr7NYf5fKncmm5gMA/CSlNF8o80AAH6Q8b0f1ZV2ov8V4EO81d2vU7vGU0r2ofj1vTimdA+BDAD4M4GYzO9nM9tyBOvw0pbSN3h8I4M3hPj+A6sbUvi/5eRJnw3EbYWYPNbPTzOx6M7sbwKcR3C4Y3i9AFQvD36Oh328ze6GZfSe7je5EJcS4rGF5PQTVQD3sWTCMtwL4cEqJ++BAAK8I/flMVMIDAE4F8CozM1SC6PSU0iydz/17L6rngz+nF3sOMv1nU0rp/vxy2HN6qffYAajGijsKnw29h0t1wtKf0/sBuCOPJU58Ti/U3wuVO2zMeQgqwfk9yvP/5vRFkXhaXV4P4BFm9n5K24JK+W6ivz1SSscAQH4gno4qDuLVAD4V8tycv7DOI1BZo24AsLeZ7RE+u3476p0aCSl9JaX0PFQ3849QufxKbEE5zuAGVF8QZnvrF7kR1ReI8+X6DO3vRdiC6vqVAma3APitkO+GlNJ/bX8zxDoh3ms35Ne1e9zMNqJyIVwPACmlv0kpPRmVpeJnUA3aQOH7hmpw2I3ePzx8Hs/ZgsoSwvfjbimlfyzkfSOA/amexu+H5P+enPaElNKeAP4Hqh8LzLB+WTJmNg3g86hm1z4spbQJVShDLKvET1FZN4Y9C4bxfADvMLOXU9oWVJYQ7s+NKaX3AkBK6TuorH+/COBVaD6n+3Uws91RuY38Ob1cz8HSc3rYPcZsQTVWbCp8tuA9vAPcCOBBOT8nPqeH9vciDBtzbkVlpXws5blXSmlJP8olnlaXewAcDeBIM/Ob4HwAd1sV7LnBqgDrx5kZBzl/EpXJ9qWofuExDwXwu1YFkL8ClV/7SymlLQD+C8B7zGzGqmDR1wH4zHbU+2YAB5lZCwDM7GFm9tJ8488CuBeVGbrExwD8uZkdnAMJn2BVAPyXAPyMmb3KzCbM7JWoXGRf3I76RU4H8HYze5CZ7Y8qVsNZSn8P43xUX/r3mtnG3K/PyJ99NJf5WAAws73yGNOmggAAIABJREFU9RDjzxvNbH8z2xuVFfOfcvpnAbzWzA7PIuAvAJyXUrrWzH7ezJ5qZpOoXAnbMPgO3YwqFo+5EJVlo23VJI5nLVKnvwfw+lyG5fv1ReHHlPPvAB5vZi/LPwzeiKY4i+yB6nt/p5ltRnlQHtYvozCFKibmpwDmrQqQfv5STkwpdQH8C6oA993M7DBUsV+LcRmq5/SHzeylOe3TAF5iZi/I12DGqmB1FpmfRGXpmU8pxbWkjrEqiHkKwJ+jug+2YHmfg7X7ZpF7rE9K6UZUYQd/l5+Zk2Z2ZP546D28HfXjMn8C4AIA7zSzKTN7JoCX0CFL6e9hfAbAc83sV3Kf7mNmh6eUeqi+F+83s4cCgJltNrMXLKXOEk+rTErpTlTutxea2Z/nL/hLUAV0X4NKHX8MwF50zrdQ+aS/X7hpzwNwcD7v3QCOSyndlj/7VVR+5hsAfAHAn6WUztqOav9z/n+bmX0f1X305pzv7age5L895Ny/RiVmvooqKPXjqOKkbgPw4pzPbQD+AFUQ/a3bUb/IO1GZgK/J5fZ/BS6lv4dB5z4GVdD/VlTuS6SUvoAqYPc0q9wYlwJY8hotYl3zWVT32dX5710AkFI6G8CfoLKc3Ijq1/Dx+Zw9UT3I70B1r96GyroCVN+Rw7JrwWc9vQnVvXcnKit0fzZUiZTSBagCiz+Uy7gS1Q+w0rG3AngFgL/M9TgM1cA2Wzo+805UQcR3oRJf/1I4ptgvo5DDDn4X1TPkDlRWnTNHyOJ3ULlzbkIVe/SJJZZ7Earn09+b2Quz0DkWlQj8KSrrxltRH1M/hSooPVqdgKov/gzV8/LJqK4hlvk5+EEAx1k16+1vsPA9Fnk1qlimH6GKGfu9XL+F7uEd5VWoYlBvR9U3n/QPltjfRVJK16Fy7b45530hqolKQBVLdSWA7+Tn9H+gmsy0KB6VL9YZZnYOgM8mWgDNqumXv5FSeuaqVUyIXRgzuxbVd/A/Vrsuy0W2MG8F8GshPnOUPK7FmPXLYlg15f0WVDMBf0zpp0CLnq57ZHlah2SX0pOwfWZvIYRYkOwe2ZRdM3+EKqboO6tcrfXGGwB8l4WTGB+0Muw6w8xORTUN+E1h5pwQQiwXT0flWppCNU3/ZSmlB1a3SuuHbGkzVM9qMYbIbSeEEEIIMQIr5rYzs6OtWt7/SjN720qVI4QQy42eX0KIhVgRy5OZtVGtZPo8VIGG3wXwqymlH5aOn7LpNIONpY+EEOuYbbgPnTS7lDV41gyjPr8APcOEGFeGPcNWKubpKaiWjb8aAMzsNFTTDIsPnxlsxFMH+9cKIcaE89LZq12F7WGk5xegZ5gQ48qwZ9hKue02o74E/laE5eXN7EQzu8DMLphbcPkQIYTYqSz6/AL0DBNiV2alxFPJTF/zD6aUTk4pHZFSOmIS0ytUDSGEGJlFn1+AnmFC7MqslHjaivr+QftjO/YxEkKIVUDPLyHEgqyUePougIPN7JF5757jMdoS+kIIsVro+SWEWJAVCRhPKc2b2e8A+AqANoB/SCldthJlCSHEcqLnlxBiMVZshfGU0pdQ7RAthBDrCj2/hBALob3thBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBCSehBBCCCFGYIfEk5n9g5ndYmaXUtreZnaWmf04/3/QjldTCCGWFz2/hBDby45ank4BcHRIexuAs1NKBwM4O78XQoi1xinQ80sIsR3skHhKKX0DwO0h+VgAp+bXpwJ42Y6UIYQQK4GeX0KI7WUlYp4ellK6EQDy/4eWDjKzE83sAjO7YA6zK1ANIYQYmSU9vwA9w4TYlVm1gPGU0skppSNSSkdMYnq1qiGEENuFnmFC7LpMrECeN5vZvimlG81sXwC3rEAZYj1j1kia2H9zIy3tubGR1rviqmKWaX6+mdhqN8vZ92HNc2ebVoPurbcVyxFjj55fYnFKz7BH7N9I6z54z0Za68dbilmmTqeZODnZPH/vTc1z772vWfZt0SMtlpOVsDydCeCE/PoEAGesQBlCCLES6PklhFiUHV2q4B8BfBvAIWa21cxeB+C9AJ5nZj8G8Lz8Xggh1hR6fgkhtpcdctullH51yEfP2ZF8hRBipdHzSwixvWiFcSGEEEKIEViJgHEhFqS1YUMj7Yfv2LeR9qZnntVIO+vFP1fMc/6anzTSSsHhk5/tNtIuvvQxjbRD3vpAI613//3FsoUQuxat6ebsysvfsl8j7YQj/7OR9p1XP6GYp225uZHWO6iZ5+QHbm2kXXr+IY20g//kB838tm0rli1GR5YnIYQQQogRkHgSQgghhBgBiSchhBBCiBGQeBJCCCGEGAEFjIudTmkl3X2/1lwN/OQtxzTSDrrz8qWXU1g5/OJLmsHhu1/dLDt1m4HlQggBlHc02Py15nGf+8lRjbQDrv9RMc/uXXc30iZuaU6uueiHBzbSNv2kueJ5SqlYjlgeZHkSQgghhBgBiSchhBBCiBGQeBJCCCGEGAGJJyGEEEKIEbC1EFS2p+2dnmraTmqXptUM2rZ2IZB7rhlsPlIxu+3WzLMQHF4KNl8RCu1uTU020nrD6rMGvr8LcV46G3en25vRrGOGnmGi+AxrFQK5C8Hmw7DJqUZae/PDm3nefmcjrXt3MwB9RdhFn2GyPAkhhBBCjIDEkxBCCCHECEg8CSGEEEKMgMSTEEIIIcQIaIVxsTboFYK2C2k7XMz99y97nkvGCsGjT398I+1Hr24GiR76t3cVs+xedsWO10sIseMUn2ErUM62ZuB1adeGFWGJz7ArfmWmkfazH72tmGX38h/veL1WAVmehBBCCCFGQOJJCCGEEGIEJJ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkCz7YQoUZhVMvHIA4uHppnm7Ljef1/dPK6wDcxdj97QSPvcCz7YSHvLF367WPbUZcVkIcQ4UJiul7qFKXyFraxKW1HZ/vuWyyk877o/vmbx+gG461HNZ9hHX/SxRtp7vvya4vlTPyrs3rTGt2wBZHkSQgghhBgJiSchhBBCiBGQeBJCCCGEGAGJJyGEEEKIEVDAuBgLbKJ5K7f22bt54KY9G0ndvZoBj63Lr22kXfv/biyW/byDmluk/PilD22kzV9/QyNtn39tRny/4/u/3ki79ZhmUDoAPOKKRzTLufa64rFCiLVL6RnWfsT+jbR7D2s+W1CIud7tunsaade/s1z2gQ+6o5nlKx/cSJu/6eZG2j5fvaqR9if2G420e59YqCSAgy7b3Cxny9bisWsJWZ6EEEIIIUZA4kkIIYQQYgQknoQQQgghRkDiSQghhBBiBBQwLsYCe+zBjbTNJzcDp8+9ar9G2luf+NVG2hkvPKKRtvsZzWBzADjnwU9pln33JcVjI91772uk3foLD2qkXfJ7f1c8/6jLfrORNv2TLc0D18GKvULsythhj2mkHfyJKxtpb3nIpxtpZ9x7aCPtzNcc1Uib+PLuxbK3tJvPnIff13yGtWZmGmnWatpgZjc1g8M/eeIHimW/9btvaKRNKmBcCCGEEGK8kHgSQgghhBgBiSchhBBCiBGQeBJCCCGEGAFLayCQdE/bOz3VnrPa1RDrmPZjD2mk3f/+2UbatlMf3kjr7NEMbnzYZy5tpPXuu79YtrUKK+e2242k1Ok0jyt8/9oPa64g3Dm0udIwAExd2Fzdt3vnXcVjV4Pz0tm4O91eXlp4jNAzTOwo7UOaAeN3fKD5fLjp+mZw94MumGyk7fvVGxtp6Z7mBBUASPc3n222227NtImlPddsqrkjwtyjms9eAJi45OpGWvfuu4vHrgbDnmGyPAkhhBBCjIDEkxBCCCHECEg8CSGEEEKMgMSTEEIIIcQIbPcK42Z2AIBPAng4gB6Ak1NKHzSzvQH8E4CDAFwL4FdSSnfseFXXEa1mUF17942NtF4hSC/Nz69Ilcad7uXNlXh3e2VzRfCZ+5tBlGbNeOZbf/WJjbSJ2fLkit2vbwamX/OS6UbaIR9ulj1/zU8aad2bb2mktQtpANAtpoqloGfYAiz1GfbAtkZamitMjBCL0rvq2kba3m9o7oiwd/em5smFceOGX35UI23y3vIzbMPtzSfJ1uc0bSuHnHx7I637o+akFfSa+dmNhXpj/T7DdsTyNA/gzSmlQwE8DcAbzewwAG8DcHZK6WAAZ+f3Qgix1tAzTAixXWy3eEop3ZhS+n5+fQ+AywFsBnAsgFPzYacCeNmOVlIIIZYbPcOEENvLssQ8mdlBAJ4I4DwAD0sp3QhUDycAzUVrqnNONLMLzOyCOTTdHkIIsbPQM0wIMQo7LJ7MbHcAnwfweymlJa9slVI6OaV0RErpiEk040OEEGJnoGeYEGJUtjtgHADMbBLVQ+czKaV/yck3m9m+KaUbzWxfAOVI1zHGnnxYI+2mP2kGUW76m90baZNnf7+Z4RpYBX45ae/ZDOROj2gGRuKaLY2k3n3lFXJLAYrdO5YW49sqrOh9+OsvbqRdefeDi+f/9MzNjbR/O+6vGmm/e8Ybm2UXAsbFzkPPsDL2pEMbaVv+uNdI2/vjzWfYbl+7rJFWCixHauZXpa/9513xGXZQ8xlm197QSBu2enbqFdo9Wwi+bzVtHt399mmkPet/nt9I+9FdDyuWfd3ZBzbS3v3Cf2yk/cPpL22k2bDrOOZst+XJqilKHwdweUrpr+mjMwGckF+fAOCM7a+eEEKsDHqGCSG2lx2xPD0DwKsBXGJmF+a0PwLwXgCnm9nrAFwH4BU7VkUhhFgR9AwTQmwX2y2eUkrfBDBsw0/tkCmEWNPoGSaE2F60wrgQQgghxAhIPAkhhBBCjMAOzbYTZeb2mGqkvfbR32iknfagoxtpkytSowKFLUmK7OjMl0I5dx7TnI34qfc1Z6e99nd/v5G24czvLr3oqeZ1SHPNbQx6tzW3HNj6Wz/TSJuZL88q2e/GHzXSfv8br2ukTV53bSNt/hmHN9ImfnRdI61bqOMOU7g2S+0zAMUZjmI86G5oPome/4iLGmnf2vSURtrue+7RSLOZwlIO3fL9U7rf0uzS1tFKpTxX4Bl21wuasxH/8n0faaS99e2/3Ujb9JXLy+VMNr97cwc1Z8dZt/kcat0/10i7+A9/rlnEvc3jAOCRNzZnNp/ylRc1z7/9rkba7LOaW1lN/7i5FUvvjjuLZRevWWnm4RKxdtMm1Bt2/+zAvSHLkxBC/P/t3X+Q3HV9x/HX+/aSy2+SCwFiEk0wEZIKBJvBdKStQ3UK6CgzBarSigPiTKsVqpaKdmzp9Bctg45U0AhI7DiFGrQ4YG0ZfkhbSULkl4EIhDAhP8AkJJcQkhy3u+/+cctMcu/Plvvs3mZ3vzwfMzfcvtnd7+dzt/vOe7/3/n4+AJCB4gkAACADxRMAAEAGiicAAIAM5h2wFP406/d3W3GWVbG+2BxZOm5WiFV37oqxQ4ltDJrUM3lyiO0575QQm7o1NtX1/HfcpiSrUbinFEKprR+euTiO8aRvx+bE6hOxOVuSeue/NcQ2fG52iL31P2KzZd9P1sUnbEGT6f7zY3Ptg1+LTaZnfiE2mU67bU36OE2Ms7R4UYht+JMZIbboe4ktIiTZz2ID8cjxrPF7tc93j/LqhO5VuByWaF4uHRe3J0o1Aftr8fVivfHaJJs4MX3svnhsTZwQQjveG7dDmbI9NkRPXPNsYozpxmlVExeFJLZDee03Yg7bdH7MdW+/PTa/j9+a3jbqlVPjNlGnXBXfYw/8+7tCbP4PdoaY7UtsZVWvST/RhJ5qvN71/hND7I6//acQO+/qPwux43/8fPLYzeSwoQUnhNjGj8bXysLb0v+u2kOJf99GmcM48wQAAJCB4gkAACADxRMAAEAGiicAAIAMrDDeAqnVcMtbtrZhJMNsdmxE/KurvxNif/yzi0LspIdj83v1wIFRH7tnSWxKPvT3r4TY8bdMicdZHxs966nMOibEvnnuLSH2+S2Xhdice2Kjp5frrKo9WokmyGOeeDnETvnmZ0Js/uPxQoJKCy7sODRnWoj98JzrQ+yyh69IPr7/ocRnL2fV8SLwodj0Xd62vfHnS72f6qz6bL1xdfOeRfND7LIr7wyxf1gbd21Y/GTMLap3YU4p5oLywtiYXv1ifI/2r4r36/vl5hCrl1tKB2ND/g1zVofYgnmnxgcnmtpTx/H9iSZy1Wmg99hEPnNN/Fme889Xhti8hxI5bFfGLgk9id0PEhfhDB0TLxS64dxbQ+xLT12SPMzxjyT+fRvlRVuceQIAAMhA8QQAAJCB4gkAACADxRMAAEAGVhh/E+iZEFdcHTzz10Ksb2dsBE+u6J3xmulZuiTE3roirjT7yI1LQ6x/5dr4hHVWN0+t6t5zYmwm1I7YtJ1qlqy+EpvaU6uG15X6GaVWW080RnpqFeAWvE97Jk2K41kwL95xy4vJx1f27YuPH7GS9Oryf2pflRXG0ZxUDhtaHnPL+J2xIbr69HMh5tX0+yn1ftQpJ8XxXBdXCd99c8w3029/JB67nF7dvCex4nrltHjBTaqZurQ3Njn3HEg0Pg+mdwtIXeTkBw7GWCI3pRq5q6mLAY5SDtPC+HuwQ3VWlN8Tc5iPyP2rD/1Ye6svs8I4AABAMyieAAAAMlA8AQAAZKB4AgAAyEDDOFpqZAOxJPXM7A8x3xsb90a70ms9PZMnh9jGr8TVecv9cSXexVduDLHBd52YPM7g9DjHqXc/HmI7Lzo9xEqJPsYZqSbTOqsxt1Mp8Xt84ZMnH3H7+Vuv08EXt9Awju6VuNAj9dof2WgsNZ/DSsfODLGnvxSbyKuT4mrgi78+EGL7lsxIHmdoYjyPMnPNjhB76ay4W0Vv7CvXzB+sj2Pcvz957FY0ko9k48Yn46U5J4TYC+fPPeL2pu9ep4MvxRzGmScAAIAMFE8AAAAZKJ4AAAAyUDwBAABkiJ2uwBjycmzGrvwqNiK2RE/8bFCeGlfIHT8t0YydWMV34IrEquOSPnHimhD7yZp3htg7Lomrtb98KDa199wdY5UObBjXcbGZ9drLbj7i9uV37TpaowFaI7GrQWXnzqNyaBs3LsSqE2NzuMYnYomdEw5eHFdGl6T3zX0mxB7/ZNyF4rgLXwixwUosI+yh2FheejnORZL8YGyq99fiSuipf0tGy4fqrKzeFxvJf//j9x1x+1t3p/M+Z54AAAAyUDwBAABkoHgCAADIQPEEAACQgeIJAAAgA9uz4OizeCWb9cYrMbyc2LukyddrafoxiWDcfqGyZ2+837IlyecsT41XbIz7n7g9gS1aEGPVeJVM5ZfPxYMkrvjJ0TNpUgwuelsczwsvxfHsSV+hY319MXjKkVtHrH7yW9r36na2Z0GxpHLY+JgHfChxhVid9/Jot7JKXYHnrx6Ih9n/aohVlscr6CRpsD8+5+T7NsRjz5udfHwYz+Zt8bGJn48kaXziKrxqIs8nroD2E+IVv1k5LLFtiy15+xG3Vz99k/YeiDmMM08AAAAZKJ4AAAAyUDwBAABkoHgCAADIwPYsOOrs12PT4nMXTA2xRbfELRAqT29MPmeqEby8ZH6849Nb4nO+vDv5nMHaXyTDvYnm0dSFGL4+bs9ytLy2fHGI3fidr4fYR//uCyF27LfXJp/TU1vGrBvRKO9x6wWgq6Saw98VLx7ZdMG0EDvx+/tCrOe5renDHBMff+Dk40Ns4mNxi5R6DdEjldY+lYxPnTE9xKpD8YKdylNxG5dROxCb2iXJEhfspC5GOfje+DP/6+u/HWJ/es0fhdismx9OHju1bYs/fmSjvNfJYZx5AgAAyEDxBAAAkIHiCQAAIAPFEwAAQIaGG8bNbIKkByX11Z5nlbv/pZktkHSbpH5Jj0j6Q3ePXVl4c+iJzYC73xmbw//3Y9eG2IU/vSLE+p5JL1a9/7dPCrF7bvhGiP3mlz8bYjNWro5PmLOSeQes0v9G+rbEhtJz7vh8iL19/cH4YI+roBcBOQyNGjg55rAbL1gRYlevvjTEpmxO/7M7cMZbQuzr/3h9iH3mSzGHTbstXlyTykv+Wvpl7InmcJuQ2EEgdZHIaPNfnft5Oa7CnopNeublELvkjtgcPm9zfGzPlMnJY1f27Y/BUe7m0MyZp0FJZ7n7aZKWSjrbzJZLukbSV919kaQ9kuKrBwDajxwGoCENF08+7PWybVztyyWdJWlVLb5S0nlNjRAAWoAcBqBRTfU8mVnJzB6TtEPSPZKekzTg7q+fN9sqaU6dx37KzNaZ2bohJU4FAkCLkcMANKKp4sndK+6+VNJcSWdIiivxDX+SSz12hbsvc/dl45T42yoAtBg5DEAjxmSFcXcfMLMHJC2XNN3Memuf3OZK2j4Wx0CXSjTfHXtnXGn747/4VIhNfCber1qn6XDKU7tCbOmKy0Ns/iNxNfF6z9mMnkmTQswmTQyx5OrmLRhPZePzIbboqm3x0KmG0i5oiG8WOQx1JV7//XdvCLFr118YYpM3xftV9iealCUd8+iOEPvEDfGimXmPx1xXabZp+1A8c9pzbH+IlcaNj8feFcdztHLYwr+IOcx6E2VNIh9LUimxqnt1/6tHBobSFyk1fObJzGaZ2fTa9xMlvU/SBkn3Szq/dreLJd3Z6DEAoFXIYQAa1cyZp9mSVppZScNF2L+5+11m9pSk28zsbyQ9KunmMRgnAIw1chiAhjRcPLn7E5JOT8Q3abh3AAA6FjkMQKNYYRwAACCDeQc0g06zfn+3/U67h4GCSTUOeiWxemyT7wFLNFFu/+yyEJt1ztYQm3BZbEYsP7+5qfG01YgV5ddU/kv7fHe647JAyGFohbHOYclmakk9M2Nz+OZLFoZY6d1xp4J5l8cG+PLmLaMaz9GSytFSnZXHR/yMHtq9SnuHdoQcxpknAACADBRPAAAAGSieAAAAMlA8AQAAZBiTFcaBTuTl8hvfqUUs0dN5qBzfbhOUuGMX650/74jbtjXdqAngjY06h1m8JqNnYtzRILXLgZRuJB/3arzfwcFxMVht/0Vnb8SHEjsnSKrsjfm3tHD+kYG9pXAfiTNPAAAAWSieAAAAMlA8AQAAZKB4AgAAyEDxBAAAkIGr7YAmpa7keMuKx0LMVvaFWHlgoCVjapuRW0d0wPZPQJGkroxLbTNiEyaEmB86lHzOysDeEJt9U8xN9t14tV15777kc3aFarzazg6M+BlVq8mHcuYJAAAgA8UTAABABoonAACADBRPAAAAGWgYR2GVjp0ZYjZ1SohVtmwLsWa3dqkeOBCDqVjBlF/YesRtrw61aSRA9+udfUKIVd6SyGvbdoVYNdEEXh0cTB8ocWFHMgcWP4WpvG37Ebfr5TDOPAEAAGSgeAIAAMhA8QQAAJCB4gkAACADDeMoBOuLq3c/e+U7Quxjv/tgiD38e/F+lY3Pj83A3mxYURxoSCqHbfz0ghD7rfc/EWLb/uD4EKu+9KuxGdibzShzGGeeAAAAMlA8AQAAZKB4AgAAyEDxBAAAkIGGcRRDpRJCM56Md/uXCWeG2Mmv0BwOoM0SOWzm+ti8/NPSqSG2cGBjS4aE+jjzBAAAkIHiCQAAIAPFEwAAQAaKJwAAgAw0jKMQvFwOsf7vPRxiM2+PL/nKoUMtGRMAjFYqh01btS7GflgKscrgYEvGhPo48wQAAJCB4gkAACADxRMAAEAGiicAAIAMNIyjsFINmKkYAHSiZL4ih3UEzjwBAABkoHgCAADIQPEEAACQgeIJAAAgQ9PFk5mVzOxRM7urdnuBma0xs2fN7HYzG9/8MAGgNchhAHKNxZmnyyVtOOz2NZK+6u6LJO2RdOkYHAMAWoUcBiBLU8WTmc2V9AFJN9Vum6SzJK2q3WWlpPOaOQYAtAo5DEAjmj3z9DVJV0qq1m7PlDTg7q8vRLFV0pzUA83sU2a2zszWDYlNDQG0BTkMQLaGiycz+6CkHe7+88PDibt66vHuvsLdl7n7snHqa3QYANAQchiARjWzwvh7JH3IzM6VNEHSNA1/iptuZr21T25zJW1vfpgAMObIYQAa0vCZJ3e/yt3nuvt8SR+RdJ+7XyTpfknn1+52saQ7mx4lAIwxchiARrVinac/l/Q5M9uo4f6Bm1twDABoFXIYgP/XmGwM7O4PSHqg9v0mSWeMxfMCwNFADgOQgxXGAQAAMlA8AQAAZKB4AgAAyEDxBAAAkIHiCQAAIAPFEwAAQAaKJwAAgAwUTwAAABkongAAADJQPAEAAGSgeAIAAMhA8QQAAJCB4gkAACADxRMAAEAGiicAAIAMFE8AAAAZKJ4AAAAyUDwBAABkoHgCAADIQPEEAACQgeIJAAAgA8UTAABABoonAACADBRPAAAAGSieAAAAMlA8AQAAZKB4AgAAyEDxBAAAkIHiCQAAIAPFEwAAQAaKJwAAgAwUTwAAABkongAAADKYu7d7DDKznZI2124eK2lXG4czloo0F6lY8ynSXKTOnc/b3H1WuwfRaoflsE79PTSqSPMp0lykYs3ZSuoeAAAD1UlEQVSnk+eSzGEdUTwdzszWufuydo9jLBRpLlKx5lOkuUjFm0+3KtrvoUjzKdJcpGLNpxvnwp/tAAAAMlA8AQAAZOjE4mlFuwcwhoo0F6lY8ynSXKTizadbFe33UKT5FGkuUrHm03Vz6bieJwAAgE7WiWeeAAAAOhbFEwAAQIaOKZ7M7Gwze9rMNprZF9s9nlxmdouZ7TCz9YfF+s3sHjN7tvbfGe0c42iZ2Twzu9/MNpjZk2Z2eS3erfOZYGZrzezx2nyursUXmNma2nxuN7Px7R7raJlZycweNbO7are7di5F0c05rEj5SypWDiN/daaOKJ7MrCTpG5LOkbRE0kfNbEl7R5XtVklnj4h9UdK97r5I0r21292gLOnz7r5Y0nJJn679Prp1PoOSznL30yQtlXS2mS2XdI2kr9bms0fSpW0cY67LJW047HY3z6XrFSCH3ari5C+pWDmM/NWBOqJ4knSGpI3uvsndX5N0m6QPt3lMWdz9QUm7R4Q/LGll7fuVks47qoNqkLu/6O6P1L5/RcMv8jnq3vm4u++v3RxX+3JJZ0laVYt3zXzMbK6kD0i6qXbb1KVzKZCuzmFFyl9SsXIY+aszdUrxNEfSlsNub63Fut3x7v6iNPxmlnRcm8eTzczmSzpd0hp18Xxqp4kfk7RD0j2SnpM04O7l2l266TX3NUlXSqrWbs9U986lKIqYw7r2/X64IuQw8lfn6ZTiyRIx1lBoMzObIukOSVe4+752j6cZ7l5x96WS5mr4LMHi1N2O7qjymdkHJe1w958fHk7ctePnUjD8DjpQUXIY+avz9LZ7ADVbJc077PZcSdvbNJax9Cszm+3uL5rZbA1/augKZjZOw0nne+7+g1q4a+fzOncfMLMHNNwHMd3MemufeLrlNfceSR8ys3MlTZA0TcOf5LpxLkVSxBzW1e/3IuYw8lfn6JQzTw9LWlTruB8v6SOSftTmMY2FH0m6uPb9xZLubONYRq32N+ibJW1w9+sO+1/dOp9ZZja99v1ESe/TcA/E/ZLOr92tK+bj7le5+1x3n6/h98l97n6RunAuBVPEHNaV73epWDmM/NWh3L0jviSdK+kZDf8t98vtHk8D4/9XSS9KGtLwp9BLNfy33HslPVv7b3+7xznKuZyp4dOmT0h6rPZ1bhfP51RJj9bms17SV2rxEyWtlbRR0vcl9bV7rJnzeq+ku4owlyJ8dXMOK1L+qs2nMDmM/NWZX2zPAgAAkKFT/mwHAADQFSieAAAAMlA8AQAAZKB4AgAAyEDxBAAAkIHiCQAAIAPFEwAAQIb/AzF7lwia+a02AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_keypoints = data_generator.keypoints_shape[0]\n",
    "batch = train_generator(batch_size=1, validation=False)[0]\n",
    "inputs = batch[0]\n",
    "outputs = batch[1]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\n",
    "ax1.set_title('image')\n",
    "ax1.imshow(inputs[0,...,:], cmap=None, vmin=0, vmax=255)\n",
    "\n",
    "ax2.set_title('posture graph')\n",
    "ax2.imshow(outputs[0,...,n_keypoints:-1].max(-1))\n",
    "\n",
    "ax3.set_title('keypoints confidence')\n",
    "ax3.imshow(outputs[0,...,:n_keypoints].max(-1))\n",
    "\n",
    "ax4.set_title('posture graph and keypoints confidence')\n",
    "ax4.imshow(outputs[0,...,-1], vmin=0)\n",
    "plt.show()\n",
    "\n",
    "train_generator.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model\n",
    "Here you can define a model to train with your data. You can use our `StackedDenseNet` model, `StackedHourglass` model, `DeepLabCut` model, or the `LEAP` model. The default settings for each model should work well for most datasets, but you can customize the model architecture. The `DeepLabCut` model has multiple pretrained (on ImageNet) backbones available for using transfer learning, including the original ResNet50 (He et al. 2015)  as well as the faster MobileNetV2 (Sandler et al. 2018; see  also Mathis et al. 2019) and DenseNet121 (Huang et al. 2017). We'll select `StackedDenseNet` and set `n_stacks=2` for 2 hourglasses, with `growth_rate=32` (32 filters per convolution). Adjust the `growth_rate` and/or `n_stacks` to change model performance (and speed). You can also set `pretrained=True` to use transfer learning with `StackedDenseNet`, which uses a DenseNet121 pretrained on ImageNet to encode the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepposekit.models import DeepLabCut, StackedDenseNet, StackedHourglass, LEAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also look at the doc strings for any of the models to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackedDenseNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLabCut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'StackedDenseNet',\n",
       " 'n_stacks': 2,\n",
       " 'n_transitions': 7,\n",
       " 'growth_rate': 32,\n",
       " 'bottleneck_factor': 1,\n",
       " 'compression_factor': 0.5,\n",
       " 'pretrained': True,\n",
       " 'subpixel': True,\n",
       " 'n_train': 9,\n",
       " 'n_validation': 2,\n",
       " 'validation_split': 0.2,\n",
       " 'downsample_factor': 3,\n",
       " 'output_shape': (48, 48),\n",
       " 'n_output_channels': 54,\n",
       " 'shuffle': True,\n",
       " 'sigma': 5,\n",
       " 'output_sigma': 0.625,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 1,\n",
       " 'random_seed': 1,\n",
       " 'augmenter': True,\n",
       " 'datapath': '/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set.h5',\n",
       " 'dataset': 'images',\n",
       " 'generator': 'DataGenerator',\n",
       " 'n_samples': 11,\n",
       " 'image_shape': (384, 384, 3),\n",
       " 'keypoints_shape': (26, 2)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StackedDenseNet(train_generator, n_stacks=2, growth_rate=32, pretrained=True)\n",
    "\n",
    "#model = DeepLabCut(train_generator, backbone=\"resnet50\")\n",
    "#model = DeepLabCut(train_generator, backbone=\"mobilenetv2\", alpha=0.35) # Increase alpha to improve accuracy\n",
    "#model = DeepLabCut(train_generator, backbone=\"densenet121\")\n",
    "\n",
    "#model = LEAP(train_generator)\n",
    "#model = StackedHourglass(train_generator)\n",
    "\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the prediction speed\n",
    "This generates a random set of input images for the model to test how fast the model can predict keypoint locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 40s 4ms/sample\n",
      "236.02465066719344\n"
     ]
    }
   ],
   "source": [
    "data_size = (10000,) + data_generator.image_shape\n",
    "x = np.random.randint(0, 255, data_size, dtype=\"uint8\")\n",
    "y = model.predict(x[:100], batch_size=100) # make sure the model is in GPU memory\n",
    "t0 = time.time()\n",
    "y = model.predict(x, batch_size=100, verbose=1)\n",
    "t1 = time.time()\n",
    "print(x.shape[0] / (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks to enhance model training\n",
    "Here you can define callbacks to pass to the model for use during training. You can use any callbacks available in `deepposekit.callbacks` or `tensorflow.keras.callbacks`\n",
    "\n",
    "Remember, if you set `validation_split=0` for your `TrainingGenerator`, which will just use the training set for model fitting, make sure to set `monitor=\"loss\"` instead of `monitor=\"val_loss\"`.\n",
    "\n",
    "\n",
    "`Logger` evaluates the validation set (or training set if `validation_split=0` in the `TrainingGenerator`) at the end of each epoch and saves the evaluation data to a HDF5 log file (if `filepath` is set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(validation_batch_size=7,\n",
    "    # filepath saves the logger data to a .h5 file\n",
    "    # filepath=HOME + \"/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet_merged_3.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReduceLROnPlateau` automatically reduces the learning rate of the optimizer when the validation loss stops improving. This helps the model to reach a better optimum at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelCheckpoint` automatically saves the model when the validation loss improves at the end of each epoch. This allows you to automatically save the best performing model during training, without having to evaluate the performance manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    HOME + \"/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet_merged_3.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    # monitor=\"loss\" # use if validation_split=0\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EarlyStopping` automatically stops the training session when the validation loss stops improving for a set number of epochs, which is set with the `patience` argument. This allows you to save time when training your model if there's not more improvment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    # monitor=\"loss\" # use if validation_split=0\n",
    "    min_delta=0.001,\n",
    "    patience=100,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of callbacks to pass to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stop, reduce_lr, model_checkpoint, logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "\n",
    "This fits the model for a set number of epochs with small batches of data. If you have a small dataset initially you can set `batch_size` to a small value and manually set `steps_per_epoch` to some large value, e.g. 500, to increase the number of batches per epoch, otherwise this is automatically determined by the size of the dataset.\n",
    "\n",
    "The number of `epochs` is set to `epochs=200` for demonstration purposes. **Increase the number of epochs to train the model longer, for example `epochs=1000`**. The `EarlyStopping` callback will then automatically end training if there is no improvement. See the doc string for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 1 steps\n",
      "Epoch 1/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 50.7318 - output_0_loss: 17.7764 - output_1_loss: 16.7550 - output_2_loss: 16.2004\n",
      "Epoch 00001: val_loss improved from inf to 106.49466, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 58.93 (0%:  0.68, 5%:  0.80, 25%:  1.84, 50%: 54.03, 75%: 87.86, 95%: 168.31, 100%: 185.48) \n",
      "confidence - mean:  0.02 (0%:  0.00, 5%:  0.00, 25%:  0.01, 50%:  0.02, 75%:  0.03, 95%:  0.04, 100%:  0.07) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 50.6099 - output_0_loss: 17.7446 - output_1_loss: 16.7134 - output_2_loss: 16.1518 - val_loss: 106.4947 - val_output_0_loss: 34.7157 - val_output_1_loss: 35.9898 - val_output_2_loss: 35.7892\n",
      "Epoch 2/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 29.9155 - output_0_loss: 12.6300 - output_1_loss: 9.4053 - output_2_loss: 7.8802\n",
      "Epoch 00002: val_loss improved from 106.49466 to 74.16586, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 39.04 (0%:  0.29, 5%:  0.70, 25%:  1.39, 50%:  2.61, 75%: 41.66, 95%: 170.73, 100%: 291.53) \n",
      "confidence - mean:  0.14 (0%:  0.01, 5%:  0.02, 25%:  0.05, 50%:  0.13, 75%:  0.21, 95%:  0.27, 100%:  0.31) \n",
      "\n",
      "100/100 [==============================] - 231s 2s/step - loss: 29.8082 - output_0_loss: 12.6031 - output_1_loss: 9.3643 - output_2_loss: 7.8408 - val_loss: 74.1659 - val_output_0_loss: 25.0107 - val_output_1_loss: 24.7148 - val_output_2_loss: 24.4404\n",
      "Epoch 3/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 17.1818 - output_0_loss: 8.4683 - output_1_loss: 4.6685 - output_2_loss: 4.0449\n",
      "Epoch 00003: val_loss improved from 74.16586 to 45.76312, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  8.04 (0%:  0.15, 5%:  0.25, 25%:  0.80, 50%:  1.13, 75%:  2.28, 95%: 69.30, 100%: 101.95) \n",
      "confidence - mean:  0.32 (0%:  0.01, 5%:  0.04, 25%:  0.21, 50%:  0.33, 75%:  0.45, 95%:  0.54, 100%:  0.57) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 17.1821 - output_0_loss: 8.4618 - output_1_loss: 4.6710 - output_2_loss: 4.0493 - val_loss: 45.7631 - val_output_0_loss: 17.2342 - val_output_1_loss: 14.7972 - val_output_2_loss: 13.7318\n",
      "Epoch 4/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 12.3817 - output_0_loss: 5.4278 - output_1_loss: 3.6386 - output_2_loss: 3.3154\n",
      "Epoch 00004: val_loss improved from 45.76312 to 15.06671, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.10 (0%:  0.07, 5%:  0.17, 25%:  0.59, 50%:  0.91, 75%:  1.31, 95%:  2.67, 100%:  3.80) \n",
      "confidence - mean:  0.61 (0%:  0.35, 5%:  0.43, 25%:  0.54, 50%:  0.61, 75%:  0.68, 95%:  0.77, 100%:  0.90) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 12.3488 - output_0_loss: 5.4117 - output_1_loss: 3.6296 - output_2_loss: 3.3075 - val_loss: 15.0667 - val_output_0_loss: 6.6009 - val_output_1_loss: 4.5596 - val_output_2_loss: 3.9062\n",
      "Epoch 5/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 9.4785 - output_0_loss: 3.7573 - output_1_loss: 2.9901 - output_2_loss: 2.7312\n",
      "Epoch 00005: val_loss improved from 15.06671 to 10.13481, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.30, 5%:  0.40, 25%:  0.68, 50%:  0.93, 75%:  1.69, 95%:  3.18, 100%:  4.12) \n",
      "confidence - mean:  0.68 (0%:  0.33, 5%:  0.48, 25%:  0.59, 50%:  0.68, 75%:  0.77, 95%:  0.85, 100%:  0.89) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 9.4578 - output_0_loss: 3.7484 - output_1_loss: 2.9840 - output_2_loss: 2.7255 - val_loss: 10.1348 - val_output_0_loss: 4.1400 - val_output_1_loss: 3.1484 - val_output_2_loss: 2.8463\n",
      "Epoch 6/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 8.3766 - output_0_loss: 3.1662 - output_1_loss: 2.7000 - output_2_loss: 2.5104\n",
      "Epoch 00006: val_loss did not improve from 10.13481\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.38 (0%:  0.20, 5%:  0.40, 25%:  0.81, 50%:  1.11, 75%:  1.70, 95%:  3.36, 100%:  4.52) \n",
      "confidence - mean:  0.66 (0%:  0.14, 5%:  0.41, 25%:  0.59, 50%:  0.69, 75%:  0.76, 95%:  0.86, 100%:  0.95) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 8.3674 - output_0_loss: 3.1618 - output_1_loss: 2.6966 - output_2_loss: 2.5090 - val_loss: 11.6471 - val_output_0_loss: 4.1897 - val_output_1_loss: 3.6752 - val_output_2_loss: 3.7822\n",
      "Epoch 7/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 7.9640 - output_0_loss: 2.9849 - output_1_loss: 2.5762 - output_2_loss: 2.4028\n",
      "Epoch 00007: val_loss improved from 10.13481 to 8.85279, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.36, 5%:  0.39, 25%:  0.59, 50%:  0.85, 75%:  1.33, 95%:  3.37, 100%:  4.48) \n",
      "confidence - mean:  0.70 (0%:  0.44, 5%:  0.53, 25%:  0.62, 50%:  0.70, 75%:  0.81, 95%:  0.87, 100%:  0.90) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 7.9723 - output_0_loss: 2.9872 - output_1_loss: 2.5788 - output_2_loss: 2.4062 - val_loss: 8.8528 - val_output_0_loss: 3.3977 - val_output_1_loss: 2.8611 - val_output_2_loss: 2.5941\n",
      "Epoch 8/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 7.3006 - output_0_loss: 2.7357 - output_1_loss: 2.3597 - output_2_loss: 2.2053\n",
      "Epoch 00008: val_loss did not improve from 8.85279\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.14 (0%:  0.29, 5%:  0.38, 25%:  0.69, 50%:  1.11, 75%:  1.53, 95%:  2.66, 100%: 49.45) \n",
      "confidence - mean:  0.67 (0%:  0.03, 5%:  0.41, 25%:  0.60, 50%:  0.68, 75%:  0.80, 95%:  0.90, 100%:  0.94) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 7.3019 - output_0_loss: 2.7361 - output_1_loss: 2.3599 - output_2_loss: 2.2059 - val_loss: 12.0920 - val_output_0_loss: 4.7547 - val_output_1_loss: 3.7886 - val_output_2_loss: 3.5488\n",
      "Epoch 9/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 6.9137 - output_0_loss: 2.6048 - output_1_loss: 2.2318 - output_2_loss: 2.0772\n",
      "Epoch 00009: val_loss did not improve from 8.85279\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.16, 5%:  0.35, 25%:  0.62, 50%:  1.14, 75%:  1.86, 95%:  3.27, 100%: 34.57) \n",
      "confidence - mean:  0.64 (0%:  0.05, 5%:  0.10, 25%:  0.60, 50%:  0.69, 75%:  0.78, 95%:  0.90, 100%:  0.98) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 6.8949 - output_0_loss: 2.5974 - output_1_loss: 2.2258 - output_2_loss: 2.0716 - val_loss: 15.1161 - val_output_0_loss: 5.3554 - val_output_1_loss: 5.0136 - val_output_2_loss: 4.7471\n",
      "Epoch 10/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 6.4213 - output_0_loss: 2.3649 - output_1_loss: 2.0865 - output_2_loss: 1.9699\n",
      "Epoch 00010: val_loss did not improve from 8.85279\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.99 (0%:  0.11, 5%:  0.33, 25%:  0.60, 50%:  0.95, 75%:  1.48, 95%:  3.86, 100%: 142.92) \n",
      "confidence - mean:  0.72 (0%:  0.02, 5%:  0.47, 25%:  0.65, 50%:  0.75, 75%:  0.85, 95%:  0.91, 100%:  0.93) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 6.4270 - output_0_loss: 2.3677 - output_1_loss: 2.0882 - output_2_loss: 1.9712 - val_loss: 9.8911 - val_output_0_loss: 3.6587 - val_output_1_loss: 3.1447 - val_output_2_loss: 3.0877\n",
      "Epoch 11/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 6.1874 - output_0_loss: 2.2657 - output_1_loss: 2.0133 - output_2_loss: 1.9084\n",
      "Epoch 00011: val_loss did not improve from 8.85279\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  8.89 (0%:  0.06, 5%:  0.35, 25%:  0.68, 50%:  1.13, 75%:  1.84, 95%: 50.05, 100%: 150.03) \n",
      "confidence - mean:  0.71 (0%:  0.02, 5%:  0.25, 25%:  0.64, 50%:  0.74, 75%:  0.82, 95%:  0.98, 100%:  1.07) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 6.1699 - output_0_loss: 2.2598 - output_1_loss: 2.0074 - output_2_loss: 1.9027 - val_loss: 14.4651 - val_output_0_loss: 4.9626 - val_output_1_loss: 4.8174 - val_output_2_loss: 4.6851\n",
      "Epoch 12/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 6.0541 - output_0_loss: 2.2297 - output_1_loss: 1.9617 - output_2_loss: 1.8626\n",
      "Epoch 00012: val_loss did not improve from 8.85279\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.55 (0%:  0.09, 5%:  0.46, 25%:  0.70, 50%:  1.18, 75%:  1.70, 95%:  3.66, 100%: 63.20) \n",
      "confidence - mean:  0.68 (0%:  0.01, 5%:  0.10, 25%:  0.61, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  0.96) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 6.0619 - output_0_loss: 2.2320 - output_1_loss: 1.9641 - output_2_loss: 1.8659 - val_loss: 14.2437 - val_output_0_loss: 5.1781 - val_output_1_loss: 4.6247 - val_output_2_loss: 4.4409\n",
      "Epoch 13/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 5.4417 - output_0_loss: 2.0035 - output_1_loss: 1.7648 - output_2_loss: 1.6734\n",
      "Epoch 00013: val_loss improved from 8.85279 to 6.61540, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.12 (0%:  0.09, 5%:  0.23, 25%:  0.57, 50%:  0.94, 75%:  1.62, 95%:  2.62, 100%:  3.24) \n",
      "confidence - mean:  0.76 (0%:  0.09, 5%:  0.56, 25%:  0.67, 50%:  0.78, 75%:  0.86, 95%:  0.96, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 5.4265 - output_0_loss: 1.9979 - output_1_loss: 1.7598 - output_2_loss: 1.6688 - val_loss: 6.6154 - val_output_0_loss: 2.3893 - val_output_1_loss: 2.1494 - val_output_2_loss: 2.0767\n",
      "Epoch 14/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 5.4615 - output_0_loss: 2.0169 - output_1_loss: 1.7647 - output_2_loss: 1.6799\n",
      "Epoch 00014: val_loss improved from 6.61540 to 5.57939, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.14, 5%:  0.22, 25%:  0.55, 50%:  0.86, 75%:  1.51, 95%:  3.61, 100%:  4.32) \n",
      "confidence - mean:  0.78 (0%:  0.55, 5%:  0.59, 25%:  0.70, 50%:  0.78, 75%:  0.86, 95%:  0.96, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 5.4387 - output_0_loss: 2.0085 - output_1_loss: 1.7573 - output_2_loss: 1.6730 - val_loss: 5.5794 - val_output_0_loss: 2.0164 - val_output_1_loss: 1.8097 - val_output_2_loss: 1.7533\n",
      "Epoch 15/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.5989 - output_0_loss: 1.6946 - output_1_loss: 1.4863 - output_2_loss: 1.4180\n",
      "Epoch 00015: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.86 (0%:  0.07, 5%:  0.40, 25%:  0.69, 50%:  1.04, 75%:  1.73, 95%:  4.42, 100%: 27.15) \n",
      "confidence - mean:  0.77 (0%:  0.38, 5%:  0.60, 25%:  0.70, 50%:  0.76, 75%:  0.88, 95%:  0.94, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 4.5911 - output_0_loss: 1.6919 - output_1_loss: 1.4837 - output_2_loss: 1.4155 - val_loss: 10.2946 - val_output_0_loss: 4.0849 - val_output_1_loss: 3.2188 - val_output_2_loss: 2.9909\n",
      "Epoch 16/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.6393 - output_0_loss: 1.7426 - output_1_loss: 1.4899 - output_2_loss: 1.4068\n",
      "Epoch 00016: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  4.93 (0%:  0.20, 5%:  0.24, 25%:  0.59, 50%:  0.93, 75%:  1.56, 95%:  3.57, 100%: 103.72) \n",
      "confidence - mean:  0.73 (0%:  0.02, 5%:  0.48, 25%:  0.67, 50%:  0.74, 75%:  0.86, 95%:  0.93, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 4.6814 - output_0_loss: 1.7580 - output_1_loss: 1.5034 - output_2_loss: 1.4200 - val_loss: 10.0586 - val_output_0_loss: 3.7533 - val_output_1_loss: 3.2658 - val_output_2_loss: 3.0394\n",
      "Epoch 17/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 5.0364 - output_0_loss: 1.8704 - output_1_loss: 1.6242 - output_2_loss: 1.5419\n",
      "Epoch 00017: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.04, 5%:  0.25, 25%:  0.53, 50%:  1.00, 75%:  1.54, 95%:  3.70, 100%:  4.76) \n",
      "confidence - mean:  0.78 (0%:  0.52, 5%:  0.58, 25%:  0.68, 50%:  0.78, 75%:  0.86, 95%:  0.95, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 5.0360 - output_0_loss: 1.8700 - output_1_loss: 1.6244 - output_2_loss: 1.5416 - val_loss: 6.7841 - val_output_0_loss: 2.5662 - val_output_1_loss: 2.1938 - val_output_2_loss: 2.0241\n",
      "Epoch 18/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.4779 - output_0_loss: 1.6669 - output_1_loss: 1.4423 - output_2_loss: 1.3687\n",
      "Epoch 00018: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.33 (0%:  0.21, 5%:  0.31, 25%:  0.76, 50%:  1.02, 75%:  1.50, 95%:  3.77, 100%:  5.52) \n",
      "confidence - mean:  0.76 (0%:  0.31, 5%:  0.60, 25%:  0.67, 50%:  0.78, 75%:  0.85, 95%:  0.96, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 4.4676 - output_0_loss: 1.6634 - output_1_loss: 1.4389 - output_2_loss: 1.3654 - val_loss: 7.0211 - val_output_0_loss: 2.6374 - val_output_1_loss: 2.2275 - val_output_2_loss: 2.1562\n",
      "Epoch 19/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.7772 - output_0_loss: 1.7876 - output_1_loss: 1.5338 - output_2_loss: 1.4559\n",
      "Epoch 00019: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  5.71 (0%:  0.30, 5%:  0.47, 25%:  0.81, 50%:  1.11, 75%:  1.83, 95%:  2.98, 100%: 174.58) \n",
      "confidence - mean:  0.71 (0%:  0.01, 5%:  0.26, 25%:  0.63, 50%:  0.75, 75%:  0.86, 95%:  0.96, 100%:  0.98) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 4.7679 - output_0_loss: 1.7840 - output_1_loss: 1.5308 - output_2_loss: 1.4531 - val_loss: 11.0051 - val_output_0_loss: 3.9266 - val_output_1_loss: 3.6122 - val_output_2_loss: 3.4663\n",
      "Epoch 20/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.4561 - output_0_loss: 1.6534 - output_1_loss: 1.4356 - output_2_loss: 1.3670\n",
      "Epoch 00020: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.08, 5%:  0.36, 25%:  0.78, 50%:  0.99, 75%:  1.46, 95%:  3.06, 100%:  4.04) \n",
      "confidence - mean:  0.76 (0%:  0.51, 5%:  0.62, 25%:  0.69, 50%:  0.77, 75%:  0.84, 95%:  0.94, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 4.4468 - output_0_loss: 1.6500 - output_1_loss: 1.4326 - output_2_loss: 1.3642 - val_loss: 5.9682 - val_output_0_loss: 2.2471 - val_output_1_loss: 1.8996 - val_output_2_loss: 1.8215\n",
      "Epoch 21/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.3361 - output_0_loss: 1.6238 - output_1_loss: 1.3932 - output_2_loss: 1.3190\n",
      "Epoch 00021: val_loss did not improve from 5.57939\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.10, 5%:  0.23, 25%:  0.69, 50%:  1.03, 75%:  1.64, 95%:  3.25, 100%:  5.45) \n",
      "confidence - mean:  0.77 (0%:  0.44, 5%:  0.50, 25%:  0.66, 50%:  0.79, 75%:  0.85, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 4.3217 - output_0_loss: 1.6188 - output_1_loss: 1.3886 - output_2_loss: 1.3143 - val_loss: 7.2750 - val_output_0_loss: 2.8273 - val_output_1_loss: 2.3384 - val_output_2_loss: 2.1093\n",
      "Epoch 22/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.0074 - output_0_loss: 1.4998 - output_1_loss: 1.2803 - output_2_loss: 1.2273\n",
      "Epoch 00022: val_loss improved from 5.57939 to 5.48522, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.05, 5%:  0.12, 25%:  0.66, 50%:  0.99, 75%:  1.51, 95%:  3.33, 100%:  3.72) \n",
      "confidence - mean:  0.77 (0%:  0.54, 5%:  0.55, 25%:  0.69, 50%:  0.78, 75%:  0.86, 95%:  0.95, 100%:  0.95) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.9941 - output_0_loss: 1.4948 - output_1_loss: 1.2760 - output_2_loss: 1.2232 - val_loss: 5.4852 - val_output_0_loss: 2.0049 - val_output_1_loss: 1.7643 - val_output_2_loss: 1.7160\n",
      "Epoch 23/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.2227 - output_0_loss: 1.5826 - output_1_loss: 1.3508 - output_2_loss: 1.2893\n",
      "Epoch 00023: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.10, 5%:  0.22, 25%:  0.73, 50%:  1.01, 75%:  1.59, 95%:  3.16, 100%:  4.05) \n",
      "confidence - mean:  0.79 (0%:  0.54, 5%:  0.59, 25%:  0.72, 50%:  0.81, 75%:  0.88, 95%:  0.95, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 4.2181 - output_0_loss: 1.5805 - output_1_loss: 1.3495 - output_2_loss: 1.2880 - val_loss: 6.2067 - val_output_0_loss: 2.1986 - val_output_1_loss: 2.0235 - val_output_2_loss: 1.9846\n",
      "Epoch 24/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.0596 - output_0_loss: 1.4956 - output_1_loss: 1.3066 - output_2_loss: 1.2574\n",
      "Epoch 00024: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.21, 5%:  0.36, 25%:  0.73, 50%:  1.01, 75%:  1.72, 95%:  2.72, 100%:  4.80) \n",
      "confidence - mean:  0.71 (0%:  0.27, 5%:  0.45, 25%:  0.61, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  0.96) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 4.0520 - output_0_loss: 1.4933 - output_1_loss: 1.3040 - output_2_loss: 1.2547 - val_loss: 8.7799 - val_output_0_loss: 3.4451 - val_output_1_loss: 2.7849 - val_output_2_loss: 2.5499\n",
      "Epoch 25/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 4.0937 - output_0_loss: 1.5219 - output_1_loss: 1.3148 - output_2_loss: 1.2570\n",
      "Epoch 00025: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.10, 5%:  0.32, 25%:  0.71, 50%:  1.14, 75%:  1.69, 95%:  2.48, 100%:  4.38) \n",
      "confidence - mean:  0.77 (0%:  0.54, 5%:  0.61, 25%:  0.70, 50%:  0.76, 75%:  0.86, 95%:  0.93, 100%:  0.96) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 4.0841 - output_0_loss: 1.5183 - output_1_loss: 1.3117 - output_2_loss: 1.2541 - val_loss: 5.5989 - val_output_0_loss: 2.1231 - val_output_1_loss: 1.7762 - val_output_2_loss: 1.6997\n",
      "Epoch 26/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.8316 - output_0_loss: 1.4284 - output_1_loss: 1.2277 - output_2_loss: 1.1755\n",
      "Epoch 00026: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.30, 5%:  0.38, 25%:  0.60, 50%:  0.87, 75%:  1.43, 95%:  3.37, 100%:  3.98) \n",
      "confidence - mean:  0.76 (0%:  0.08, 5%:  0.56, 25%:  0.66, 50%:  0.77, 75%:  0.89, 95%:  0.97, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 3.8578 - output_0_loss: 1.4381 - output_1_loss: 1.2365 - output_2_loss: 1.1833 - val_loss: 6.7614 - val_output_0_loss: 2.4595 - val_output_1_loss: 2.1853 - val_output_2_loss: 2.1166\n",
      "Epoch 27/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.4708 - output_0_loss: 1.2815 - output_1_loss: 1.1143 - output_2_loss: 1.0749\n",
      "Epoch 00027: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.05, 5%:  0.23, 25%:  0.57, 50%:  0.92, 75%:  1.53, 95%:  3.08, 100%:  7.21) \n",
      "confidence - mean:  0.77 (0%:  0.25, 5%:  0.56, 25%:  0.71, 50%:  0.77, 75%:  0.86, 95%:  0.97, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 3.4613 - output_0_loss: 1.2782 - output_1_loss: 1.1112 - output_2_loss: 1.0719 - val_loss: 6.5028 - val_output_0_loss: 2.3573 - val_output_1_loss: 2.1047 - val_output_2_loss: 2.0407\n",
      "Epoch 28/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.4390 - output_0_loss: 1.2765 - output_1_loss: 1.1017 - output_2_loss: 1.0608\n",
      "Epoch 00028: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.19, 5%:  0.26, 25%:  0.56, 50%:  1.03, 75%:  1.51, 95%:  3.25, 100%:  4.38) \n",
      "confidence - mean:  0.77 (0%:  0.01, 5%:  0.54, 25%:  0.70, 50%:  0.79, 75%:  0.86, 95%:  0.98, 100%:  1.24) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.4642 - output_0_loss: 1.2854 - output_1_loss: 1.1101 - output_2_loss: 1.0688 - val_loss: 8.2760 - val_output_0_loss: 3.0464 - val_output_1_loss: 2.6556 - val_output_2_loss: 2.5740\n",
      "Epoch 29/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.6765 - output_0_loss: 1.3602 - output_1_loss: 1.1817 - output_2_loss: 1.1346\n",
      "Epoch 00029: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.25, 5%:  0.35, 25%:  0.52, 50%:  0.95, 75%:  1.56, 95%:  2.75, 100%:  5.80) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.60, 25%:  0.71, 50%:  0.80, 75%:  0.89, 95%:  0.97, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 3.6711 - output_0_loss: 1.3580 - output_1_loss: 1.1801 - output_2_loss: 1.1330 - val_loss: 5.6599 - val_output_0_loss: 2.0597 - val_output_1_loss: 1.8321 - val_output_2_loss: 1.7681\n",
      "Epoch 30/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.3152 - output_0_loss: 1.2271 - output_1_loss: 1.0638 - output_2_loss: 1.0243\n",
      "Epoch 00030: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.02, 5%:  0.32, 25%:  0.69, 50%:  1.09, 75%:  1.45, 95%:  3.18, 100%:  4.03) \n",
      "confidence - mean:  0.78 (0%:  0.47, 5%:  0.57, 25%:  0.69, 50%:  0.79, 75%:  0.88, 95%:  0.96, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.3083 - output_0_loss: 1.2248 - output_1_loss: 1.0615 - output_2_loss: 1.0221 - val_loss: 5.8912 - val_output_0_loss: 2.1640 - val_output_1_loss: 1.9049 - val_output_2_loss: 1.8222\n",
      "Epoch 31/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.6135 - output_0_loss: 1.3573 - output_1_loss: 1.1535 - output_2_loss: 1.1027\n",
      "Epoch 00031: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.03, 5%:  0.24, 25%:  0.63, 50%:  1.04, 75%:  1.39, 95%:  3.00, 100%:  7.16) \n",
      "confidence - mean:  0.78 (0%:  0.43, 5%:  0.55, 25%:  0.72, 50%:  0.78, 75%:  0.88, 95%:  0.98, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.6234 - output_0_loss: 1.3608 - output_1_loss: 1.1567 - output_2_loss: 1.1059 - val_loss: 6.5474 - val_output_0_loss: 2.4170 - val_output_1_loss: 2.1249 - val_output_2_loss: 2.0054\n",
      "Epoch 32/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.3816 - output_0_loss: 1.2579 - output_1_loss: 1.0793 - output_2_loss: 1.0444\n",
      "Epoch 00032: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.19, 5%:  0.36, 25%:  0.71, 50%:  1.05, 75%:  1.44, 95%:  3.01, 100%:  4.82) \n",
      "confidence - mean:  0.75 (0%:  0.21, 5%:  0.49, 25%:  0.66, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.3717 - output_0_loss: 1.2548 - output_1_loss: 1.0758 - output_2_loss: 1.0410 - val_loss: 7.6231 - val_output_0_loss: 2.8202 - val_output_1_loss: 2.4404 - val_output_2_loss: 2.3625\n",
      "Epoch 33/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.2078 - output_0_loss: 1.2010 - output_1_loss: 1.0239 - output_2_loss: 0.9828\n",
      "Epoch 00033: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.30 (0%:  0.13, 5%:  0.27, 25%:  0.62, 50%:  1.09, 75%:  1.65, 95%:  3.24, 100%:  4.77) \n",
      "confidence - mean:  0.79 (0%:  0.53, 5%:  0.60, 25%:  0.70, 50%:  0.80, 75%:  0.90, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.2174 - output_0_loss: 1.2039 - output_1_loss: 1.0272 - output_2_loss: 0.9863 - val_loss: 5.7825 - val_output_0_loss: 2.0900 - val_output_1_loss: 1.8568 - val_output_2_loss: 1.8357\n",
      "Epoch 34/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.1220 - output_0_loss: 1.1647 - output_1_loss: 0.9956 - output_2_loss: 0.9617\n",
      "Epoch 00034: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.12, 5%:  0.21, 25%:  0.68, 50%:  0.96, 75%:  1.67, 95%:  3.37, 100%:  4.20) \n",
      "confidence - mean:  0.77 (0%:  0.19, 5%:  0.54, 25%:  0.71, 50%:  0.78, 75%:  0.90, 95%:  0.97, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.1136 - output_0_loss: 1.1617 - output_1_loss: 0.9929 - output_2_loss: 0.9590 - val_loss: 7.4544 - val_output_0_loss: 2.8267 - val_output_1_loss: 2.3911 - val_output_2_loss: 2.2365\n",
      "Epoch 35/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.1005 - output_0_loss: 1.1620 - output_1_loss: 0.9861 - output_2_loss: 0.9524\n",
      "Epoch 00035: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.22, 5%:  0.34, 25%:  0.67, 50%:  1.02, 75%:  1.44, 95%:  3.15, 100%:  5.56) \n",
      "confidence - mean:  0.82 (0%:  0.52, 5%:  0.64, 25%:  0.72, 50%:  0.81, 75%:  0.92, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.0885 - output_0_loss: 1.1577 - output_1_loss: 0.9822 - output_2_loss: 0.9486 - val_loss: 5.7504 - val_output_0_loss: 2.1220 - val_output_1_loss: 1.8434 - val_output_2_loss: 1.7850\n",
      "Epoch 36/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.9178 - output_0_loss: 1.0826 - output_1_loss: 0.9326 - output_2_loss: 0.9025\n",
      "Epoch 00036: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.30, 5%:  0.34, 25%:  0.69, 50%:  1.08, 75%:  1.42, 95%:  3.03, 100%:  4.12) \n",
      "confidence - mean:  0.79 (0%:  0.34, 5%:  0.58, 25%:  0.69, 50%:  0.80, 75%:  0.88, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.9049 - output_0_loss: 1.0782 - output_1_loss: 0.9284 - output_2_loss: 0.8983 - val_loss: 6.0307 - val_output_0_loss: 2.2230 - val_output_1_loss: 1.9539 - val_output_2_loss: 1.8538\n",
      "Epoch 37/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.3764 - output_0_loss: 1.2483 - output_1_loss: 1.0829 - output_2_loss: 1.0452\n",
      "Epoch 00037: val_loss did not improve from 5.48522\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.30 (0%:  0.30, 5%:  0.41, 25%:  0.61, 50%:  1.00, 75%:  1.61, 95%:  3.30, 100%:  4.44) \n",
      "confidence - mean:  0.77 (0%:  0.11, 5%:  0.55, 25%:  0.69, 50%:  0.79, 75%:  0.89, 95%:  0.98, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.3741 - output_0_loss: 1.2475 - output_1_loss: 1.0821 - output_2_loss: 1.0445 - val_loss: 8.8645 - val_output_0_loss: 3.2505 - val_output_1_loss: 2.8757 - val_output_2_loss: 2.7383\n",
      "Epoch 38/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.9709 - output_0_loss: 1.1071 - output_1_loss: 0.9477 - output_2_loss: 0.9160\n",
      "Epoch 00038: val_loss improved from 5.48522 to 5.05866, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.22, 5%:  0.39, 25%:  0.73, 50%:  0.96, 75%:  1.62, 95%:  2.99, 100%:  4.11) \n",
      "confidence - mean:  0.79 (0%:  0.53, 5%:  0.57, 25%:  0.70, 50%:  0.78, 75%:  0.88, 95%:  0.96, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.9712 - output_0_loss: 1.1068 - output_1_loss: 0.9482 - output_2_loss: 0.9162 - val_loss: 5.0587 - val_output_0_loss: 1.8472 - val_output_1_loss: 1.6227 - val_output_2_loss: 1.5887\n",
      "Epoch 39/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.8821 - output_0_loss: 1.0794 - output_1_loss: 0.9205 - output_2_loss: 0.8821\n",
      "Epoch 00039: val_loss did not improve from 5.05866\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.51 (0%:  0.12, 5%:  0.37, 25%:  0.73, 50%:  1.25, 75%:  1.69, 95%:  3.80, 100%:  6.01) \n",
      "confidence - mean:  0.72 (0%:  0.04, 5%:  0.40, 25%:  0.66, 50%:  0.73, 75%:  0.85, 95%:  0.90, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 2.8694 - output_0_loss: 1.0749 - output_1_loss: 0.9163 - output_2_loss: 0.8782 - val_loss: 10.2388 - val_output_0_loss: 3.8661 - val_output_1_loss: 3.2347 - val_output_2_loss: 3.1380\n",
      "Epoch 40/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.7927 - output_0_loss: 1.0559 - output_1_loss: 0.8858 - output_2_loss: 0.8510\n",
      "Epoch 00040: val_loss did not improve from 5.05866\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.33 (0%:  0.13, 5%:  0.37, 25%:  0.66, 50%:  1.07, 75%:  1.55, 95%:  3.48, 100%:  6.14) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.60, 25%:  0.72, 50%:  0.79, 75%:  0.90, 95%:  0.96, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.7847 - output_0_loss: 1.0527 - output_1_loss: 0.8833 - output_2_loss: 0.8487 - val_loss: 6.0545 - val_output_0_loss: 2.1424 - val_output_1_loss: 1.9897 - val_output_2_loss: 1.9225\n",
      "Epoch 41/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.2111 - output_0_loss: 1.1869 - output_1_loss: 1.0275 - output_2_loss: 0.9967\n",
      "Epoch 00041: val_loss did not improve from 5.05866\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 12.47 (0%:  0.17, 5%:  0.31, 25%:  0.55, 50%:  0.98, 75%:  1.72, 95%: 90.11, 100%: 188.90) \n",
      "confidence - mean:  0.69 (0%:  0.02, 5%:  0.03, 25%:  0.63, 50%:  0.72, 75%:  0.86, 95%:  0.97, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.2077 - output_0_loss: 1.1853 - output_1_loss: 1.0265 - output_2_loss: 0.9960 - val_loss: 17.3041 - val_output_0_loss: 5.9063 - val_output_1_loss: 5.7673 - val_output_2_loss: 5.6305\n",
      "Epoch 42/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.9901 - output_0_loss: 1.1107 - output_1_loss: 0.9563 - output_2_loss: 0.9231\n",
      "Epoch 00042: val_loss did not improve from 5.05866\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.20, 5%:  0.42, 25%:  0.70, 50%:  0.90, 75%:  1.33, 95%:  3.50, 100%:  4.75) \n",
      "confidence - mean:  0.78 (0%:  0.28, 5%:  0.62, 25%:  0.70, 50%:  0.79, 75%:  0.89, 95%:  0.95, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 2.9928 - output_0_loss: 1.1119 - output_1_loss: 0.9572 - output_2_loss: 0.9237 - val_loss: 6.0488 - val_output_0_loss: 2.2145 - val_output_1_loss: 1.9559 - val_output_2_loss: 1.8784\n",
      "Epoch 43/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.3761 - output_0_loss: 0.8832 - output_1_loss: 0.7587 - output_2_loss: 0.7341\n",
      "Epoch 00043: val_loss did not improve from 5.05866\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.18, 5%:  0.30, 25%:  0.65, 50%:  0.94, 75%:  1.57, 95%:  2.95, 100%:  5.16) \n",
      "confidence - mean:  0.82 (0%:  0.58, 5%:  0.62, 25%:  0.75, 50%:  0.80, 75%:  0.93, 95%:  0.99, 100%:  1.04) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.3641 - output_0_loss: 0.8791 - output_1_loss: 0.7548 - output_2_loss: 0.7303 - val_loss: 5.0645 - val_output_0_loss: 1.7689 - val_output_1_loss: 1.6528 - val_output_2_loss: 1.6427\n",
      "Epoch 44/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.1600 - output_0_loss: 0.8111 - output_1_loss: 0.6849 - output_2_loss: 0.6640\n",
      "Epoch 00044: val_loss did not improve from 5.05866\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.21, 5%:  0.44, 25%:  0.77, 50%:  0.94, 75%:  1.51, 95%:  3.12, 100%:  5.52) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.64, 25%:  0.73, 50%:  0.82, 75%:  0.92, 95%:  0.96, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.1816 - output_0_loss: 0.8187 - output_1_loss: 0.6920 - output_2_loss: 0.6708 - val_loss: 5.1382 - val_output_0_loss: 1.8268 - val_output_1_loss: 1.6724 - val_output_2_loss: 1.6391\n",
      "Epoch 45/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4562 - output_0_loss: 0.9183 - output_1_loss: 0.7810 - output_2_loss: 0.7569- ETA: 4s - loss: 2.4570 - output_0_loss: 0.9185 - output_1_loss: 0.7814 - output_2_loss: 0.757\n",
      "Epoch 00045: val_loss improved from 5.05866 to 4.92840, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.10, 5%:  0.34, 25%:  0.64, 50%:  0.95, 75%:  1.52, 95%:  2.50, 100%:  6.24) \n",
      "confidence - mean:  0.82 (0%:  0.52, 5%:  0.63, 25%:  0.74, 50%:  0.81, 75%:  0.93, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.4553 - output_0_loss: 0.9177 - output_1_loss: 0.7808 - output_2_loss: 0.7568 - val_loss: 4.9284 - val_output_0_loss: 1.7275 - val_output_1_loss: 1.6236 - val_output_2_loss: 1.5773\n",
      "Epoch 46/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.5663 - output_0_loss: 0.9617 - output_1_loss: 0.8182 - output_2_loss: 0.7864\n",
      "Epoch 00046: val_loss did not improve from 4.92840\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.43 (0%:  0.30, 5%:  0.34, 25%:  0.63, 50%:  1.18, 75%:  1.84, 95%:  3.36, 100%:  5.75) \n",
      "confidence - mean:  0.76 (0%:  0.10, 5%:  0.56, 25%:  0.70, 50%:  0.77, 75%:  0.86, 95%:  0.91, 100%:  0.94) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.5808 - output_0_loss: 0.9669 - output_1_loss: 0.8230 - output_2_loss: 0.7909 - val_loss: 7.6738 - val_output_0_loss: 2.6909 - val_output_1_loss: 2.4977 - val_output_2_loss: 2.4852\n",
      "Epoch 47/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4545 - output_0_loss: 0.9043 - output_1_loss: 0.7856 - output_2_loss: 0.7646\n",
      "Epoch 00047: val_loss did not improve from 4.92840\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.07, 5%:  0.21, 25%:  0.73, 50%:  1.14, 75%:  1.48, 95%:  2.52, 100%:  5.62) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.63, 25%:  0.74, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.4513 - output_0_loss: 0.9034 - output_1_loss: 0.7845 - output_2_loss: 0.7634 - val_loss: 4.9656 - val_output_0_loss: 1.7270 - val_output_1_loss: 1.6251 - val_output_2_loss: 1.6135\n",
      "Epoch 48/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4280 - output_0_loss: 0.9202 - output_1_loss: 0.7691 - output_2_loss: 0.7387\n",
      "Epoch 00048: val_loss did not improve from 4.92840\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.32 (0%:  0.22, 5%:  0.31, 25%:  0.71, 50%:  1.03, 75%:  1.62, 95%:  3.47, 100%:  4.56) \n",
      "confidence - mean:  0.79 (0%:  0.56, 5%:  0.61, 25%:  0.71, 50%:  0.77, 75%:  0.90, 95%:  0.97, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.4236 - output_0_loss: 0.9189 - output_1_loss: 0.7676 - output_2_loss: 0.7371 - val_loss: 5.5954 - val_output_0_loss: 1.9721 - val_output_1_loss: 1.8397 - val_output_2_loss: 1.7836\n",
      "Epoch 49/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.2183 - output_0_loss: 0.8287 - output_1_loss: 0.7068 - output_2_loss: 0.6828\n",
      "Epoch 00049: val_loss improved from 4.92840 to 4.82372, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.11, 5%:  0.30, 25%:  0.60, 50%:  1.08, 75%:  1.41, 95%:  3.02, 100%:  4.47) \n",
      "confidence - mean:  0.80 (0%:  0.52, 5%:  0.62, 25%:  0.72, 50%:  0.80, 75%:  0.88, 95%:  0.98, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.2179 - output_0_loss: 0.8287 - output_1_loss: 0.7067 - output_2_loss: 0.6826 - val_loss: 4.8237 - val_output_0_loss: 1.7017 - val_output_1_loss: 1.5717 - val_output_2_loss: 1.5503\n",
      "Epoch 50/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.3698 - output_0_loss: 0.9007 - output_1_loss: 0.7523 - output_2_loss: 0.7169\n",
      "Epoch 00050: val_loss did not improve from 4.82372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.09, 5%:  0.19, 25%:  0.56, 50%:  1.07, 75%:  1.46, 95%:  3.26, 100%:  5.58) \n",
      "confidence - mean:  0.80 (0%:  0.51, 5%:  0.62, 25%:  0.74, 50%:  0.79, 75%:  0.88, 95%:  0.97, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 224s 2s/step - loss: 2.3797 - output_0_loss: 0.9042 - output_1_loss: 0.7554 - output_2_loss: 0.7201 - val_loss: 5.9681 - val_output_0_loss: 2.1045 - val_output_1_loss: 1.9539 - val_output_2_loss: 1.9097\n",
      "Epoch 51/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.0043 - output_0_loss: 1.1150 - output_1_loss: 0.9652 - output_2_loss: 0.9241\n",
      "Epoch 00051: val_loss did not improve from 4.82372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.32 (0%:  0.27, 5%:  0.43, 25%:  0.75, 50%:  1.11, 75%:  1.55, 95%:  3.19, 100%:  4.55) \n",
      "confidence - mean:  0.80 (0%:  0.50, 5%:  0.60, 25%:  0.72, 50%:  0.78, 75%:  0.89, 95%:  0.97, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.0003 - output_0_loss: 1.1115 - output_1_loss: 0.9641 - output_2_loss: 0.9247 - val_loss: 5.3782 - val_output_0_loss: 1.9039 - val_output_1_loss: 1.7585 - val_output_2_loss: 1.7159\n",
      "Epoch 52/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.8843 - output_0_loss: 1.0727 - output_1_loss: 0.9197 - output_2_loss: 0.8919\n",
      "Epoch 00052: val_loss did not improve from 4.82372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.03, 5%:  0.26, 25%:  0.63, 50%:  1.07, 75%:  1.53, 95%:  3.34, 100%:  4.20) \n",
      "confidence - mean:  0.78 (0%:  0.50, 5%:  0.60, 25%:  0.71, 50%:  0.77, 75%:  0.87, 95%:  0.93, 100%:  0.98) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.8903 - output_0_loss: 1.0752 - output_1_loss: 0.9216 - output_2_loss: 0.8935 - val_loss: 5.3671 - val_output_0_loss: 1.9183 - val_output_1_loss: 1.7431 - val_output_2_loss: 1.7056\n",
      "Epoch 53/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4545 - output_0_loss: 0.9087 - output_1_loss: 0.7848 - output_2_loss: 0.7609\n",
      "Epoch 00053: val_loss did not improve from 4.82372\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 10.86 (0%:  0.25, 5%:  0.38, 25%:  0.73, 50%:  1.16, 75%:  1.87, 95%: 59.90, 100%: 192.89) \n",
      "confidence - mean:  0.76 (0%:  0.01, 5%:  0.50, 25%:  0.68, 50%:  0.79, 75%:  0.86, 95%:  0.98, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.4551 - output_0_loss: 0.9092 - output_1_loss: 0.7849 - output_2_loss: 0.7611 - val_loss: 12.6527 - val_output_0_loss: 5.6653 - val_output_1_loss: 3.6740 - val_output_2_loss: 3.3133\n",
      "Epoch 54/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.3759 - output_0_loss: 0.8786 - output_1_loss: 0.7591 - output_2_loss: 0.7382\n",
      "Epoch 00054: val_loss did not improve from 4.82372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.12, 5%:  0.27, 25%:  0.57, 50%:  1.18, 75%:  1.57, 95%:  3.16, 100%:  4.15) \n",
      "confidence - mean:  0.80 (0%:  0.22, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.89, 95%:  0.98, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.3691 - output_0_loss: 0.8763 - output_1_loss: 0.7568 - output_2_loss: 0.7360 - val_loss: 6.1424 - val_output_0_loss: 2.1836 - val_output_1_loss: 1.9883 - val_output_2_loss: 1.9705\n",
      "Epoch 55/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.3556 - output_0_loss: 0.8881 - output_1_loss: 0.7466 - output_2_loss: 0.7209\n",
      "Epoch 00055: val_loss did not improve from 4.82372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.17, 5%:  0.45, 25%:  0.71, 50%:  1.04, 75%:  1.50, 95%:  2.80, 100%:  5.95) \n",
      "confidence - mean:  0.82 (0%:  0.55, 5%:  0.63, 25%:  0.73, 50%:  0.83, 75%:  0.90, 95%:  1.01, 100%:  1.05) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.3505 - output_0_loss: 0.8862 - output_1_loss: 0.7449 - output_2_loss: 0.7194 - val_loss: 6.2948 - val_output_0_loss: 2.4181 - val_output_1_loss: 1.9676 - val_output_2_loss: 1.9092\n",
      "Epoch 56/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.0530 - output_0_loss: 0.7657 - output_1_loss: 0.6539 - output_2_loss: 0.6334\n",
      "Epoch 00056: val_loss improved from 4.82372 to 4.66014, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.19, 5%:  0.35, 25%:  0.57, 50%:  1.02, 75%:  1.43, 95%:  3.04, 100%:  4.43) \n",
      "confidence - mean:  0.81 (0%:  0.52, 5%:  0.61, 25%:  0.72, 50%:  0.80, 75%:  0.90, 95%:  0.98, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.0452 - output_0_loss: 0.7629 - output_1_loss: 0.6513 - output_2_loss: 0.6309 - val_loss: 4.6601 - val_output_0_loss: 1.6341 - val_output_1_loss: 1.5170 - val_output_2_loss: 1.5091\n",
      "Epoch 57/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9021 - output_0_loss: 0.7140 - output_1_loss: 0.6046 - output_2_loss: 0.5836\n",
      "Epoch 00057: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.33 (0%:  0.19, 5%:  0.35, 25%:  0.67, 50%:  1.07, 75%:  1.41, 95%:  3.82, 100%:  6.12) \n",
      "confidence - mean:  0.80 (0%:  0.56, 5%:  0.62, 25%:  0.74, 50%:  0.80, 75%:  0.88, 95%:  0.97, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.8992 - output_0_loss: 0.7128 - output_1_loss: 0.6037 - output_2_loss: 0.5828 - val_loss: 6.8282 - val_output_0_loss: 2.8177 - val_output_1_loss: 2.0709 - val_output_2_loss: 1.9396\n",
      "Epoch 58/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.7316 - output_0_loss: 0.6566 - output_1_loss: 0.5471 - output_2_loss: 0.5279\n",
      "Epoch 00058: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.16, 5%:  0.28, 25%:  0.49, 50%:  0.91, 75%:  1.40, 95%:  3.77, 100%:  5.16) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.62, 25%:  0.74, 50%:  0.79, 75%:  0.90, 95%:  0.99, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.7329 - output_0_loss: 0.6567 - output_1_loss: 0.5476 - output_2_loss: 0.5285 - val_loss: 5.0729 - val_output_0_loss: 1.8355 - val_output_1_loss: 1.6466 - val_output_2_loss: 1.5909\n",
      "Epoch 59/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4805 - output_0_loss: 0.9170 - output_1_loss: 0.7939 - output_2_loss: 0.7696\n",
      "Epoch 00059: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.39 (0%:  0.21, 5%:  0.37, 25%:  0.77, 50%:  1.22, 75%:  1.73, 95%:  2.88, 100%:  5.62) \n",
      "confidence - mean:  0.76 (0%:  0.26, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.97, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.4721 - output_0_loss: 0.9146 - output_1_loss: 0.7911 - output_2_loss: 0.7664 - val_loss: 6.9445 - val_output_0_loss: 2.5007 - val_output_1_loss: 2.2717 - val_output_2_loss: 2.1721\n",
      "Epoch 60/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.7350 - output_0_loss: 1.0095 - output_1_loss: 0.8773 - output_2_loss: 0.8482\n",
      "Epoch 00060: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.52 (0%:  0.08, 5%:  0.23, 25%:  0.65, 50%:  1.31, 75%:  2.02, 95%:  3.81, 100%:  6.30) \n",
      "confidence - mean:  0.77 (0%:  0.10, 5%:  0.48, 25%:  0.69, 50%:  0.81, 75%:  0.87, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.7635 - output_0_loss: 1.0258 - output_1_loss: 0.8846 - output_2_loss: 0.8531 - val_loss: 9.6086 - val_output_0_loss: 3.2889 - val_output_1_loss: 3.1741 - val_output_2_loss: 3.1456\n",
      "Epoch 61/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 3.2562 - output_0_loss: 1.1886 - output_1_loss: 1.0556 - output_2_loss: 1.0120\n",
      "Epoch 00061: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.45 (0%:  0.29, 5%:  0.43, 25%:  0.74, 50%:  1.24, 75%:  1.86, 95%:  3.21, 100%:  5.79) \n",
      "confidence - mean:  0.75 (0%:  0.02, 5%:  0.48, 25%:  0.68, 50%:  0.80, 75%:  0.86, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 3.2414 - output_0_loss: 1.1837 - output_1_loss: 1.0506 - output_2_loss: 1.0071 - val_loss: 9.2698 - val_output_0_loss: 3.1455 - val_output_1_loss: 3.0368 - val_output_2_loss: 3.0875\n",
      "Epoch 62/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.5413 - output_0_loss: 0.9260 - output_1_loss: 0.8189 - output_2_loss: 0.7964\n",
      "Epoch 00062: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.07, 5%:  0.29, 25%:  0.71, 50%:  1.10, 75%:  1.52, 95%:  2.95, 100%:  4.62) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.59, 25%:  0.75, 50%:  0.79, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.5320 - output_0_loss: 0.9227 - output_1_loss: 0.8159 - output_2_loss: 0.7934 - val_loss: 5.2294 - val_output_0_loss: 1.8082 - val_output_1_loss: 1.7228 - val_output_2_loss: 1.6983\n",
      "Epoch 63/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.2284 - output_0_loss: 0.8302 - output_1_loss: 0.7092 - output_2_loss: 0.6891\n",
      "Epoch 00063: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.46 (0%:  0.17, 5%:  0.47, 25%:  0.73, 50%:  1.07, 75%:  1.85, 95%:  3.31, 100%:  7.01) \n",
      "confidence - mean:  0.78 (0%:  0.05, 5%:  0.58, 25%:  0.72, 50%:  0.79, 75%:  0.90, 95%:  0.96, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.2616 - output_0_loss: 0.8415 - output_1_loss: 0.7205 - output_2_loss: 0.6996 - val_loss: 10.7484 - val_output_0_loss: 4.0672 - val_output_1_loss: 3.4158 - val_output_2_loss: 3.2655\n",
      "Epoch 64/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4269 - output_0_loss: 0.8999 - output_1_loss: 0.7759 - output_2_loss: 0.7511\n",
      "Epoch 00064: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.08, 5%:  0.28, 25%:  0.70, 50%:  1.05, 75%:  1.64, 95%:  2.95, 100%:  5.85) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.62, 25%:  0.72, 50%:  0.82, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.4183 - output_0_loss: 0.8968 - output_1_loss: 0.7730 - output_2_loss: 0.7484 - val_loss: 5.6109 - val_output_0_loss: 1.9888 - val_output_1_loss: 1.8344 - val_output_2_loss: 1.7876\n",
      "Epoch 65/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9030 - output_0_loss: 0.7141 - output_1_loss: 0.6067 - output_2_loss: 0.5822\n",
      "Epoch 00065: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.32 (0%:  0.08, 5%:  0.29, 25%:  0.71, 50%:  1.17, 75%:  1.57, 95%:  3.41, 100%:  4.84) \n",
      "confidence - mean:  0.82 (0%:  0.52, 5%:  0.64, 25%:  0.73, 50%:  0.82, 75%:  0.92, 95%:  1.00, 100%:  1.08) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.8986 - output_0_loss: 0.7126 - output_1_loss: 0.6052 - output_2_loss: 0.5808 - val_loss: 5.5705 - val_output_0_loss: 1.9450 - val_output_1_loss: 1.8211 - val_output_2_loss: 1.8044\n",
      "Epoch 66/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.8463 - output_0_loss: 0.6915 - output_1_loss: 0.5867 - output_2_loss: 0.5681\n",
      "Epoch 00066: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.22, 5%:  0.27, 25%:  0.68, 50%:  1.08, 75%:  1.39, 95%:  3.07, 100%:  5.41) \n",
      "confidence - mean:  0.78 (0%:  0.54, 5%:  0.61, 25%:  0.71, 50%:  0.78, 75%:  0.86, 95%:  0.96, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.8480 - output_0_loss: 0.6920 - output_1_loss: 0.5872 - output_2_loss: 0.5687 - val_loss: 5.8002 - val_output_0_loss: 2.0131 - val_output_1_loss: 1.9101 - val_output_2_loss: 1.8769\n",
      "Epoch 67/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.8190 - output_0_loss: 0.6851 - output_1_loss: 0.5770 - output_2_loss: 0.5569\n",
      "Epoch 00067: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.37 (0%:  0.16, 5%:  0.37, 25%:  0.74, 50%:  1.07, 75%:  1.49, 95%:  3.80, 100%:  5.45) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.60, 25%:  0.76, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.8367 - output_0_loss: 0.6905 - output_1_loss: 0.5830 - output_2_loss: 0.5632 - val_loss: 5.7753 - val_output_0_loss: 1.9726 - val_output_1_loss: 1.8991 - val_output_2_loss: 1.9036\n",
      "Epoch 68/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9301 - output_0_loss: 0.7209 - output_1_loss: 0.6149 - output_2_loss: 0.5943\n",
      "Epoch 00068: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.16, 5%:  0.28, 25%:  0.53, 50%:  0.92, 75%:  1.45, 95%:  3.63, 100%:  5.96) \n",
      "confidence - mean:  0.81 (0%:  0.16, 5%:  0.62, 25%:  0.74, 50%:  0.79, 75%:  0.92, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.9486 - output_0_loss: 0.7301 - output_1_loss: 0.6208 - output_2_loss: 0.5978 - val_loss: 6.1026 - val_output_0_loss: 2.0630 - val_output_1_loss: 1.9935 - val_output_2_loss: 2.0461\n",
      "Epoch 69/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.7686 - output_0_loss: 0.6593 - output_1_loss: 0.5645 - output_2_loss: 0.5449\n",
      "Epoch 00069: val_loss did not improve from 4.66014\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.10, 5%:  0.33, 25%:  0.67, 50%:  1.13, 75%:  1.53, 95%:  3.32, 100%:  3.80) \n",
      "confidence - mean:  0.82 (0%:  0.58, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.93, 95%:  1.00, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.7607 - output_0_loss: 0.6565 - output_1_loss: 0.5619 - output_2_loss: 0.5423 - val_loss: 5.2990 - val_output_0_loss: 1.9169 - val_output_1_loss: 1.7017 - val_output_2_loss: 1.6804\n",
      "Epoch 70/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.6367 - output_0_loss: 0.6120 - output_1_loss: 0.5225 - output_2_loss: 0.5022\n",
      "Epoch 00070: val_loss improved from 4.66014 to 4.57874, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.27, 5%:  0.42, 25%:  0.70, 50%:  1.16, 75%:  1.51, 95%:  2.53, 100%:  3.56) \n",
      "confidence - mean:  0.80 (0%:  0.56, 5%:  0.62, 25%:  0.71, 50%:  0.79, 75%:  0.91, 95%:  0.98, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 1.6362 - output_0_loss: 0.6116 - output_1_loss: 0.5224 - output_2_loss: 0.5022 - val_loss: 4.5787 - val_output_0_loss: 1.6059 - val_output_1_loss: 1.5033 - val_output_2_loss: 1.4696\n",
      "Epoch 71/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.5932 - output_0_loss: 0.5931 - output_1_loss: 0.5087 - output_2_loss: 0.4914\n",
      "Epoch 00071: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.15, 5%:  0.22, 25%:  0.63, 50%:  1.01, 75%:  1.55, 95%:  2.85, 100%:  5.50) \n",
      "confidence - mean:  0.80 (0%:  0.16, 5%:  0.58, 25%:  0.72, 50%:  0.81, 75%:  0.92, 95%:  1.02, 100%:  1.05) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.5884 - output_0_loss: 0.5915 - output_1_loss: 0.5070 - output_2_loss: 0.4898 - val_loss: 6.2680 - val_output_0_loss: 2.0719 - val_output_1_loss: 2.0887 - val_output_2_loss: 2.1074\n",
      "Epoch 72/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.6841 - output_0_loss: 0.6240 - output_1_loss: 0.5405 - output_2_loss: 0.5196\n",
      "Epoch 00072: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.32 (0%:  0.11, 5%:  0.32, 25%:  0.65, 50%:  1.16, 75%:  1.69, 95%:  3.20, 100%:  5.11) \n",
      "confidence - mean:  0.79 (0%:  0.58, 5%:  0.63, 25%:  0.72, 50%:  0.79, 75%:  0.88, 95%:  0.96, 100%:  0.98) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.6800 - output_0_loss: 0.6226 - output_1_loss: 0.5391 - output_2_loss: 0.5183 - val_loss: 7.1247 - val_output_0_loss: 2.4423 - val_output_1_loss: 2.3449 - val_output_2_loss: 2.3375\n",
      "Epoch 73/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.8965 - output_0_loss: 0.6994 - output_1_loss: 0.6068 - output_2_loss: 0.5903\n",
      "Epoch 00073: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.04, 5%:  0.24, 25%:  0.75, 50%:  1.10, 75%:  1.62, 95%:  3.02, 100%:  5.95) \n",
      "confidence - mean:  0.83 (0%:  0.56, 5%:  0.62, 25%:  0.75, 50%:  0.82, 75%:  0.92, 95%:  0.99, 100%:  1.06) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.8893 - output_0_loss: 0.6968 - output_1_loss: 0.6045 - output_2_loss: 0.5880 - val_loss: 5.4507 - val_output_0_loss: 1.9053 - val_output_1_loss: 1.7892 - val_output_2_loss: 1.7561\n",
      "Epoch 74/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.6737 - output_0_loss: 0.6213 - output_1_loss: 0.5354 - output_2_loss: 0.5169\n",
      "Epoch 00074: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.21 (0%:  0.14, 5%:  0.32, 25%:  0.69, 50%:  1.05, 75%:  1.57, 95%:  3.57, 100%: 49.80) \n",
      "confidence - mean:  0.78 (0%:  0.02, 5%:  0.60, 25%:  0.71, 50%:  0.82, 75%:  0.88, 95%:  0.97, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.6680 - output_0_loss: 0.6192 - output_1_loss: 0.5336 - output_2_loss: 0.5151 - val_loss: 7.4786 - val_output_0_loss: 2.6054 - val_output_1_loss: 2.4616 - val_output_2_loss: 2.4116\n",
      "Epoch 75/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.3985 - output_0_loss: 0.9015 - output_1_loss: 0.7656 - output_2_loss: 0.7314\n",
      "Epoch 00075: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.10 (0%:  0.12, 5%:  0.30, 25%:  0.68, 50%:  1.18, 75%:  1.80, 95%:  3.46, 100%: 42.19) \n",
      "confidence - mean:  0.77 (0%:  0.07, 5%:  0.51, 25%:  0.73, 50%:  0.79, 75%:  0.88, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.3915 - output_0_loss: 0.8991 - output_1_loss: 0.7632 - output_2_loss: 0.7292 - val_loss: 8.4674 - val_output_0_loss: 3.0555 - val_output_1_loss: 2.7503 - val_output_2_loss: 2.6615\n",
      "Epoch 76/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4879 - output_0_loss: 0.9077 - output_1_loss: 0.8026 - output_2_loss: 0.7776\n",
      "Epoch 00076: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.05, 5%:  0.40, 25%:  0.63, 50%:  1.03, 75%:  1.43, 95%:  2.64, 100%:  5.33) \n",
      "confidence - mean:  0.77 (0%:  0.15, 5%:  0.40, 25%:  0.71, 50%:  0.78, 75%:  0.89, 95%:  0.98, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.4763 - output_0_loss: 0.9044 - output_1_loss: 0.7985 - output_2_loss: 0.7735 - val_loss: 7.4947 - val_output_0_loss: 2.5845 - val_output_1_loss: 2.4762 - val_output_2_loss: 2.4340\n",
      "Epoch 77/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9214 - output_0_loss: 0.7208 - output_1_loss: 0.6136 - output_2_loss: 0.5870\n",
      "Epoch 00077: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.15, 5%:  0.26, 25%:  0.59, 50%:  0.95, 75%:  1.59, 95%:  2.76, 100%:  3.56) \n",
      "confidence - mean:  0.80 (0%:  0.36, 5%:  0.55, 25%:  0.73, 50%:  0.80, 75%:  0.93, 95%:  1.01, 100%:  1.04) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.9436 - output_0_loss: 0.7281 - output_1_loss: 0.6211 - output_2_loss: 0.5944 - val_loss: 5.5197 - val_output_0_loss: 2.0161 - val_output_1_loss: 1.7991 - val_output_2_loss: 1.7046\n",
      "Epoch 78/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.0637 - output_0_loss: 0.7618 - output_1_loss: 0.6636 - output_2_loss: 0.6384\n",
      "Epoch 00078: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.16 (0%:  0.07, 5%:  0.17, 25%:  0.53, 50%:  1.04, 75%:  1.47, 95%:  2.94, 100%:  4.77) \n",
      "confidence - mean:  0.80 (0%:  0.51, 5%:  0.62, 25%:  0.73, 50%:  0.79, 75%:  0.89, 95%:  0.97, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.0733 - output_0_loss: 0.7657 - output_1_loss: 0.6665 - output_2_loss: 0.6411 - val_loss: 4.6979 - val_output_0_loss: 1.6677 - val_output_1_loss: 1.5382 - val_output_2_loss: 1.4919\n",
      "Epoch 79/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.6011 - output_0_loss: 0.6075 - output_1_loss: 0.5084 - output_2_loss: 0.4853\n",
      "Epoch 00079: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.11, 5%:  0.21, 25%:  0.67, 50%:  1.07, 75%:  1.43, 95%:  3.39, 100%:  3.70) \n",
      "confidence - mean:  0.82 (0%:  0.56, 5%:  0.63, 25%:  0.73, 50%:  0.82, 75%:  0.89, 95%:  1.01, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.6025 - output_0_loss: 0.6080 - output_1_loss: 0.5088 - output_2_loss: 0.4857 - val_loss: 4.5872 - val_output_0_loss: 1.6029 - val_output_1_loss: 1.4987 - val_output_2_loss: 1.4857\n",
      "Epoch 80/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.4811 - output_0_loss: 0.5579 - output_1_loss: 0.4701 - output_2_loss: 0.4531\n",
      "Epoch 00080: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.10, 5%:  0.30, 25%:  0.62, 50%:  1.07, 75%:  1.50, 95%:  3.20, 100%:  3.77) \n",
      "confidence - mean:  0.78 (0%:  0.16, 5%:  0.58, 25%:  0.72, 50%:  0.78, 75%:  0.87, 95%:  0.97, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.4815 - output_0_loss: 0.5580 - output_1_loss: 0.4702 - output_2_loss: 0.4533 - val_loss: 6.0357 - val_output_0_loss: 2.2812 - val_output_1_loss: 1.8868 - val_output_2_loss: 1.8676\n",
      "Epoch 81/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.7866 - output_0_loss: 0.6690 - output_1_loss: 0.5676 - output_2_loss: 0.5499\n",
      "Epoch 00081: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.39 (0%:  0.12, 5%:  0.32, 25%:  0.59, 50%:  1.00, 75%:  1.62, 95%:  3.43, 100%:  6.87) \n",
      "confidence - mean:  0.76 (0%:  0.14, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.87, 95%:  0.95, 100%:  0.98) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.7866 - output_0_loss: 0.6687 - output_1_loss: 0.5678 - output_2_loss: 0.5501 - val_loss: 8.5321 - val_output_0_loss: 2.9492 - val_output_1_loss: 2.8200 - val_output_2_loss: 2.7629\n",
      "Epoch 82/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.8423 - output_0_loss: 0.6818 - output_1_loss: 0.5906 - output_2_loss: 0.5699\n",
      "Epoch 00082: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.30, 5%:  0.34, 25%:  0.65, 50%:  0.93, 75%:  1.67, 95%:  3.10, 100%:  4.06) \n",
      "confidence - mean:  0.76 (0%:  0.10, 5%:  0.52, 25%:  0.70, 50%:  0.77, 75%:  0.87, 95%:  0.96, 100%:  0.97) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.8391 - output_0_loss: 0.6806 - output_1_loss: 0.5896 - output_2_loss: 0.5690 - val_loss: 6.8325 - val_output_0_loss: 2.4925 - val_output_1_loss: 2.2061 - val_output_2_loss: 2.1339\n",
      "Epoch 83/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.6604 - output_0_loss: 0.6148 - output_1_loss: 0.5316 - output_2_loss: 0.5141\n",
      "Epoch 00083: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.36 (0%:  0.07, 5%:  0.24, 25%:  0.74, 50%:  1.14, 75%:  1.56, 95%:  3.63, 100%:  4.54) \n",
      "confidence - mean:  0.79 (0%:  0.53, 5%:  0.60, 25%:  0.72, 50%:  0.78, 75%:  0.87, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.6577 - output_0_loss: 0.6138 - output_1_loss: 0.5306 - output_2_loss: 0.5132 - val_loss: 5.9625 - val_output_0_loss: 2.1088 - val_output_1_loss: 1.9387 - val_output_2_loss: 1.9150\n",
      "Epoch 84/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.0542 - output_0_loss: 0.7652 - output_1_loss: 0.6549 - output_2_loss: 0.6340\n",
      "Epoch 00084: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.36 (0%:  0.12, 5%:  0.26, 25%:  0.78, 50%:  1.08, 75%:  1.49, 95%:  3.62, 100%:  5.62) \n",
      "confidence - mean:  0.80 (0%:  0.50, 5%:  0.60, 25%:  0.75, 50%:  0.82, 75%:  0.89, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.0495 - output_0_loss: 0.7633 - output_1_loss: 0.6535 - output_2_loss: 0.6327 - val_loss: 6.6533 - val_output_0_loss: 2.3351 - val_output_1_loss: 2.1941 - val_output_2_loss: 2.1241\n",
      "Epoch 85/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9124 - output_0_loss: 0.7024 - output_1_loss: 0.6164 - output_2_loss: 0.5936\n",
      "Epoch 00085: val_loss did not improve from 4.57874\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.49 (0%:  0.08, 5%:  0.32, 25%:  0.75, 50%:  1.20, 75%:  1.58, 95%:  3.21, 100%:  7.76) \n",
      "confidence - mean:  0.74 (0%:  0.12, 5%:  0.36, 25%:  0.69, 50%:  0.78, 75%:  0.85, 95%:  0.93, 100%:  0.96) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.9169 - output_0_loss: 0.7037 - output_1_loss: 0.6181 - output_2_loss: 0.5951 - val_loss: 17.1500 - val_output_0_loss: 7.0772 - val_output_1_loss: 5.1751 - val_output_2_loss: 4.8977\n",
      "Epoch 86/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.1644 - output_0_loss: 0.7973 - output_1_loss: 0.6951 - output_2_loss: 0.6720\n",
      "Epoch 00086: val_loss improved from 4.57874 to 4.30882, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.16 (0%:  0.13, 5%:  0.27, 25%:  0.68, 50%:  0.96, 75%:  1.42, 95%:  2.36, 100%:  3.96) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.63, 25%:  0.72, 50%:  0.78, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 2.1641 - output_0_loss: 0.7967 - output_1_loss: 0.6952 - output_2_loss: 0.6722 - val_loss: 4.3088 - val_output_0_loss: 1.5448 - val_output_1_loss: 1.3998 - val_output_2_loss: 1.3643\n",
      "Epoch 87/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.4564 - output_0_loss: 0.5427 - output_1_loss: 0.4650 - output_2_loss: 0.4487\n",
      "Epoch 00087: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.13, 5%:  0.26, 25%:  0.65, 50%:  1.03, 75%:  1.44, 95%:  3.29, 100%:  6.35) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.59, 25%:  0.74, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.4563 - output_0_loss: 0.5428 - output_1_loss: 0.4649 - output_2_loss: 0.4486 - val_loss: 5.7106 - val_output_0_loss: 1.9565 - val_output_1_loss: 1.9009 - val_output_2_loss: 1.8531\n",
      "Epoch 88/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.3411 - output_0_loss: 0.5094 - output_1_loss: 0.4239 - output_2_loss: 0.4078\n",
      "Epoch 00088: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.32 (0%:  0.21, 5%:  0.40, 25%:  0.73, 50%:  1.12, 75%:  1.52, 95%:  3.04, 100%:  4.38) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.63, 25%:  0.73, 50%:  0.80, 75%:  0.90, 95%:  0.97, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.3412 - output_0_loss: 0.5094 - output_1_loss: 0.4239 - output_2_loss: 0.4078 - val_loss: 5.3768 - val_output_0_loss: 1.8842 - val_output_1_loss: 1.7707 - val_output_2_loss: 1.7219\n",
      "Epoch 89/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.4488 - output_0_loss: 0.5335 - output_1_loss: 0.4656 - output_2_loss: 0.4496  - ET\n",
      "Epoch 00089: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.14, 5%:  0.21, 25%:  0.60, 50%:  1.04, 75%:  1.54, 95%:  3.06, 100%:  3.87) \n",
      "confidence - mean:  0.78 (0%:  0.53, 5%:  0.60, 25%:  0.69, 50%:  0.75, 75%:  0.90, 95%:  0.97, 100%:  1.04) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.4481 - output_0_loss: 0.5333 - output_1_loss: 0.4654 - output_2_loss: 0.4494 - val_loss: 5.6333 - val_output_0_loss: 2.1517 - val_output_1_loss: 1.8024 - val_output_2_loss: 1.6792\n",
      "Epoch 90/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.4672 - output_0_loss: 0.5428 - output_1_loss: 0.4698 - output_2_loss: 0.4546\n",
      "Epoch 00090: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.18, 5%:  0.33, 25%:  0.65, 50%:  1.14, 75%:  1.55, 95%:  2.74, 100%:  4.95) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.64, 25%:  0.72, 50%:  0.80, 75%:  0.90, 95%:  0.97, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.4683 - output_0_loss: 0.5432 - output_1_loss: 0.4701 - output_2_loss: 0.4550 - val_loss: 4.9608 - val_output_0_loss: 1.7291 - val_output_1_loss: 1.6389 - val_output_2_loss: 1.5929\n",
      "Epoch 91/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.4079 - output_0_loss: 0.5320 - output_1_loss: 0.4468 - output_2_loss: 0.4290\n",
      "Epoch 00091: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.07, 5%:  0.34, 25%:  0.79, 50%:  1.07, 75%:  1.36, 95%:  3.07, 100%:  5.79) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.74, 50%:  0.82, 75%:  0.90, 95%:  0.98, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.4154 - output_0_loss: 0.5340 - output_1_loss: 0.4493 - output_2_loss: 0.4321 - val_loss: 4.8138 - val_output_0_loss: 1.7004 - val_output_1_loss: 1.5692 - val_output_2_loss: 1.5442\n",
      "Epoch 92/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.5562 - output_0_loss: 0.5845 - output_1_loss: 0.4953 - output_2_loss: 0.4764\n",
      "Epoch 00092: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.04, 5%:  0.34, 25%:  0.77, 50%:  1.09, 75%:  1.51, 95%:  3.03, 100%:  5.05) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.73, 50%:  0.81, 75%:  0.89, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.5768 - output_0_loss: 0.5915 - output_1_loss: 0.5021 - output_2_loss: 0.4832 - val_loss: 5.0880 - val_output_0_loss: 1.7520 - val_output_1_loss: 1.6906 - val_output_2_loss: 1.6454\n",
      "Epoch 93/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9115 - output_0_loss: 0.7280 - output_1_loss: 0.6068 - output_2_loss: 0.5766\n",
      "Epoch 00093: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  7.48 (0%:  0.22, 5%:  0.33, 25%:  0.75, 50%:  1.16, 75%:  2.03, 95%:  3.98, 100%: 180.65) \n",
      "confidence - mean:  0.63 (0%:  0.03, 5%:  0.08, 25%:  0.56, 50%:  0.71, 75%:  0.82, 95%:  0.92, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.9075 - output_0_loss: 0.7266 - output_1_loss: 0.6055 - output_2_loss: 0.5754 - val_loss: 32.9176 - val_output_0_loss: 15.7966 - val_output_1_loss: 8.7766 - val_output_2_loss: 8.3444\n",
      "Epoch 94/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.0241 - output_0_loss: 0.7412 - output_1_loss: 0.6505 - output_2_loss: 0.6324\n",
      "Epoch 00094: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.12, 5%:  0.35, 25%:  0.64, 50%:  0.98, 75%:  1.65, 95%:  2.70, 100%:  4.32) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.63, 25%:  0.72, 50%:  0.80, 75%:  0.88, 95%:  0.97, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 2.0470 - output_0_loss: 0.7489 - output_1_loss: 0.6581 - output_2_loss: 0.6399 - val_loss: 5.5361 - val_output_0_loss: 2.0314 - val_output_1_loss: 1.8034 - val_output_2_loss: 1.7013\n",
      "Epoch 95/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.4623 - output_0_loss: 0.9176 - output_1_loss: 0.7899 - output_2_loss: 0.7547\n",
      "Epoch 00095: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.15 (0%:  0.15, 5%:  0.36, 25%:  0.82, 50%:  1.05, 75%:  1.59, 95%:  4.06, 100%: 40.07) \n",
      "confidence - mean:  0.68 (0%:  0.03, 5%:  0.10, 25%:  0.63, 50%:  0.75, 75%:  0.88, 95%:  0.97, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.4558 - output_0_loss: 0.9153 - output_1_loss: 0.7879 - output_2_loss: 0.7527 - val_loss: 14.8535 - val_output_0_loss: 4.9515 - val_output_1_loss: 4.9278 - val_output_2_loss: 4.9742\n",
      "Epoch 96/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 2.1594 - output_0_loss: 0.8024 - output_1_loss: 0.6922 - output_2_loss: 0.6649\n",
      "Epoch 00096: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.33 (0%:  0.12, 5%:  0.23, 25%:  0.70, 50%:  1.01, 75%:  1.51, 95%:  3.69, 100%:  4.69) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.61, 25%:  0.72, 50%:  0.80, 75%:  0.88, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 2.1490 - output_0_loss: 0.7986 - output_1_loss: 0.6888 - output_2_loss: 0.6616 - val_loss: 5.7083 - val_output_0_loss: 1.9828 - val_output_1_loss: 1.8759 - val_output_2_loss: 1.8495\n",
      "Epoch 97/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.7673 - output_0_loss: 0.6539 - output_1_loss: 0.5657 - output_2_loss: 0.5477\n",
      "Epoch 00097: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.26 (0%:  0.11, 5%:  0.34, 25%:  0.61, 50%:  1.02, 75%:  1.58, 95%:  3.37, 100%: 55.80) \n",
      "confidence - mean:  0.78 (0%:  0.00, 5%:  0.57, 25%:  0.72, 50%:  0.80, 75%:  0.90, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.7598 - output_0_loss: 0.6512 - output_1_loss: 0.5633 - output_2_loss: 0.5453 - val_loss: 7.8706 - val_output_0_loss: 2.6835 - val_output_1_loss: 2.5965 - val_output_2_loss: 2.5906\n",
      "Epoch 98/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9460 - output_0_loss: 0.7197 - output_1_loss: 0.6261 - output_2_loss: 0.6002\n",
      "Epoch 00098: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.07, 5%:  0.33, 25%:  0.70, 50%:  1.04, 75%:  1.38, 95%:  3.42, 100%:  6.54) \n",
      "confidence - mean:  0.80 (0%:  0.54, 5%:  0.59, 25%:  0.72, 50%:  0.82, 75%:  0.90, 95%:  0.97, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.9688 - output_0_loss: 0.7279 - output_1_loss: 0.6333 - output_2_loss: 0.6076 - val_loss: 5.5164 - val_output_0_loss: 1.9203 - val_output_1_loss: 1.8144 - val_output_2_loss: 1.7817\n",
      "Epoch 99/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.5313 - output_0_loss: 0.5662 - output_1_loss: 0.4903 - output_2_loss: 0.4748\n",
      "Epoch 00099: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.05, 5%:  0.17, 25%:  0.73, 50%:  1.13, 75%:  1.35, 95%:  3.36, 100%:  5.28) \n",
      "confidence - mean:  0.79 (0%:  0.19, 5%:  0.57, 25%:  0.70, 50%:  0.79, 75%:  0.89, 95%:  1.00, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 1.5281 - output_0_loss: 0.5649 - output_1_loss: 0.4893 - output_2_loss: 0.4738 - val_loss: 5.7441 - val_output_0_loss: 1.9897 - val_output_1_loss: 1.8908 - val_output_2_loss: 1.8636\n",
      "Epoch 100/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.3281 - output_0_loss: 0.4913 - output_1_loss: 0.4248 - output_2_loss: 0.4119\n",
      "Epoch 00100: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.18, 5%:  0.41, 25%:  0.67, 50%:  1.04, 75%:  1.39, 95%:  3.33, 100%:  4.14) \n",
      "confidence - mean:  0.80 (0%:  0.55, 5%:  0.61, 25%:  0.72, 50%:  0.79, 75%:  0.89, 95%:  0.99, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.3270 - output_0_loss: 0.4909 - output_1_loss: 0.4245 - output_2_loss: 0.4116 - val_loss: 4.9676 - val_output_0_loss: 1.7537 - val_output_1_loss: 1.6298 - val_output_2_loss: 1.5841\n",
      "Epoch 101/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.2908 - output_0_loss: 0.4852 - output_1_loss: 0.4111 - output_2_loss: 0.3945  - ETA: 2:2\n",
      "Epoch 00101: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.30 (0%:  0.13, 5%:  0.29, 25%:  0.69, 50%:  1.19, 75%:  1.52, 95%:  3.19, 100%:  4.66) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.79, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.2854 - output_0_loss: 0.4832 - output_1_loss: 0.4094 - output_2_loss: 0.3929 - val_loss: 5.2037 - val_output_0_loss: 1.7848 - val_output_1_loss: 1.7219 - val_output_2_loss: 1.6970\n",
      "Epoch 102/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.2420 - output_0_loss: 0.4654 - output_1_loss: 0.3958 - output_2_loss: 0.3807\n",
      "Epoch 00102: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.05, 5%:  0.37, 25%:  0.75, 50%:  1.08, 75%:  1.41, 95%:  2.99, 100%:  5.86) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.72, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.2390 - output_0_loss: 0.4643 - output_1_loss: 0.3949 - output_2_loss: 0.3799 - val_loss: 5.1465 - val_output_0_loss: 1.7642 - val_output_1_loss: 1.6953 - val_output_2_loss: 1.6870\n",
      "Epoch 103/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.2819 - output_0_loss: 0.4777 - output_1_loss: 0.4095 - output_2_loss: 0.3947\n",
      "Epoch 00103: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 28.15 (0%:  0.10, 5%:  0.41, 25%:  0.95, 50%:  1.40, 75%:  5.35, 95%: 154.06, 100%: 172.10) \n",
      "confidence - mean:  0.55 (0%:  0.01, 5%:  0.02, 25%:  0.17, 50%:  0.66, 75%:  0.80, 95%:  0.93, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.2885 - output_0_loss: 0.4800 - output_1_loss: 0.4116 - output_2_loss: 0.3968 - val_loss: 34.3070 - val_output_0_loss: 11.7735 - val_output_1_loss: 11.4067 - val_output_2_loss: 11.1268\n",
      "Epoch 104/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.9521 - output_0_loss: 0.7295 - output_1_loss: 0.6238 - output_2_loss: 0.5988\n",
      "Epoch 00104: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.29 (0%:  0.05, 5%:  0.26, 25%:  0.63, 50%:  1.09, 75%:  1.41, 95%:  3.43, 100%:  5.78) \n",
      "confidence - mean:  0.80 (0%:  0.53, 5%:  0.63, 25%:  0.73, 50%:  0.79, 75%:  0.90, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.9412 - output_0_loss: 0.7254 - output_1_loss: 0.6203 - output_2_loss: 0.5955 - val_loss: 5.8268 - val_output_0_loss: 2.0271 - val_output_1_loss: 1.9411 - val_output_2_loss: 1.8586\n",
      "Epoch 105/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.7190 - output_0_loss: 0.6462 - output_1_loss: 0.5480 - output_2_loss: 0.5249\n",
      "Epoch 00105: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.09, 5%:  0.25, 25%:  0.55, 50%:  0.95, 75%:  1.46, 95%:  3.31, 100%:  4.26) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.72, 50%:  0.80, 75%:  0.93, 95%:  0.98, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.7085 - output_0_loss: 0.6423 - output_1_loss: 0.5446 - output_2_loss: 0.5217 - val_loss: 4.7635 - val_output_0_loss: 1.6662 - val_output_1_loss: 1.5607 - val_output_2_loss: 1.5366\n",
      "Epoch 106/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.3067 - output_0_loss: 0.4867 - output_1_loss: 0.4184 - output_2_loss: 0.4015\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 4.30882\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.13, 5%:  0.36, 25%:  0.61, 50%:  0.97, 75%:  1.41, 95%:  3.55, 100%:  6.07) \n",
      "confidence - mean:  0.81 (0%:  0.59, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.3034 - output_0_loss: 0.4855 - output_1_loss: 0.4174 - output_2_loss: 0.4005 - val_loss: 5.1410 - val_output_0_loss: 1.7635 - val_output_1_loss: 1.7134 - val_output_2_loss: 1.6641\n",
      "Epoch 107/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.1954 - output_0_loss: 0.4463 - output_1_loss: 0.3818 - output_2_loss: 0.3673\n",
      "Epoch 00107: val_loss improved from 4.30882 to 4.28687, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.08, 5%:  0.30, 25%:  0.68, 50%:  1.03, 75%:  1.40, 95%:  3.12, 100%:  3.86) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.91, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 1.1920 - output_0_loss: 0.4451 - output_1_loss: 0.3807 - output_2_loss: 0.3662 - val_loss: 4.2869 - val_output_0_loss: 1.4800 - val_output_1_loss: 1.4144 - val_output_2_loss: 1.3925\n",
      "Epoch 108/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.9823 - output_0_loss: 0.3714 - output_1_loss: 0.3127 - output_2_loss: 0.2983\n",
      "Epoch 00108: val_loss did not improve from 4.28687\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.13, 5%:  0.23, 25%:  0.65, 50%:  1.10, 75%:  1.42, 95%:  3.01, 100%:  4.26) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.74, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 0.9800 - output_0_loss: 0.3706 - output_1_loss: 0.3119 - output_2_loss: 0.2975 - val_loss: 4.5249 - val_output_0_loss: 1.5511 - val_output_1_loss: 1.4969 - val_output_2_loss: 1.4769\n",
      "Epoch 109/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.9525 - output_0_loss: 0.3644 - output_1_loss: 0.3019 - output_2_loss: 0.2861\n",
      "Epoch 00109: val_loss did not improve from 4.28687\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.07, 5%:  0.18, 25%:  0.70, 50%:  1.11, 75%:  1.41, 95%:  3.04, 100%:  4.71) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.59, 25%:  0.74, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.9519 - output_0_loss: 0.3643 - output_1_loss: 0.3017 - output_2_loss: 0.2859 - val_loss: 4.6432 - val_output_0_loss: 1.5879 - val_output_1_loss: 1.5371 - val_output_2_loss: 1.5182\n",
      "Epoch 110/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.0283 - output_0_loss: 0.3919 - output_1_loss: 0.3260 - output_2_loss: 0.3105\n",
      "Epoch 00110: val_loss did not improve from 4.28687\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.11, 5%:  0.26, 25%:  0.67, 50%:  1.12, 75%:  1.44, 95%:  3.13, 100%:  5.11) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.74, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 1.0392 - output_0_loss: 0.3961 - output_1_loss: 0.3293 - output_2_loss: 0.3138 - val_loss: 4.7951 - val_output_0_loss: 1.6328 - val_output_1_loss: 1.5900 - val_output_2_loss: 1.5723\n",
      "Epoch 111/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.9550 - output_0_loss: 0.3731 - output_1_loss: 0.2997 - output_2_loss: 0.2822\n",
      "Epoch 00111: val_loss did not improve from 4.28687\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.05, 5%:  0.33, 25%:  0.72, 50%:  1.12, 75%:  1.37, 95%:  2.95, 100%:  4.94) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.74, 50%:  0.81, 75%:  0.91, 95%:  1.00, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.9529 - output_0_loss: 0.3724 - output_1_loss: 0.2990 - output_2_loss: 0.2815 - val_loss: 4.6554 - val_output_0_loss: 1.5937 - val_output_1_loss: 1.5423 - val_output_2_loss: 1.5193\n",
      "Epoch 112/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.9935 - output_0_loss: 0.3782 - output_1_loss: 0.3155 - output_2_loss: 0.2998\n",
      "Epoch 00112: val_loss did not improve from 4.28687\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.05, 5%:  0.24, 25%:  0.72, 50%:  1.04, 75%:  1.42, 95%:  2.87, 100%:  4.09) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.73, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.9896 - output_0_loss: 0.3769 - output_1_loss: 0.3142 - output_2_loss: 0.2985 - val_loss: 4.3409 - val_output_0_loss: 1.4944 - val_output_1_loss: 1.4360 - val_output_2_loss: 1.4105\n",
      "Epoch 113/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8700 - output_0_loss: 0.3327 - output_1_loss: 0.2756 - output_2_loss: 0.2617\n",
      "Epoch 00113: val_loss improved from 4.28687 to 4.27701, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.17 (0%:  0.05, 5%:  0.15, 25%:  0.69, 50%:  1.04, 75%:  1.39, 95%:  2.85, 100%:  4.15) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.73, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.8894 - output_0_loss: 0.3396 - output_1_loss: 0.2820 - output_2_loss: 0.2679 - val_loss: 4.2770 - val_output_0_loss: 1.4669 - val_output_1_loss: 1.4170 - val_output_2_loss: 1.3931\n",
      "Epoch 114/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8809 - output_0_loss: 0.3428 - output_1_loss: 0.2771 - output_2_loss: 0.2610\n",
      "Epoch 00114: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.11, 5%:  0.30, 25%:  0.74, 50%:  1.10, 75%:  1.42, 95%:  3.10, 100%:  4.48) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 0.8835 - output_0_loss: 0.3438 - output_1_loss: 0.2779 - output_2_loss: 0.2618 - val_loss: 4.8743 - val_output_0_loss: 1.6592 - val_output_1_loss: 1.6173 - val_output_2_loss: 1.5978\n",
      "Epoch 115/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7738 - output_0_loss: 0.3017 - output_1_loss: 0.2431 - output_2_loss: 0.2289\n",
      "Epoch 00115: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.10, 5%:  0.29, 25%:  0.71, 50%:  1.13, 75%:  1.36, 95%:  3.07, 100%:  5.39) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.72, 50%:  0.82, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7712 - output_0_loss: 0.3008 - output_1_loss: 0.2423 - output_2_loss: 0.2281 - val_loss: 4.9208 - val_output_0_loss: 1.6743 - val_output_1_loss: 1.6292 - val_output_2_loss: 1.6173\n",
      "Epoch 116/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8306 - output_0_loss: 0.3214 - output_1_loss: 0.2622 - output_2_loss: 0.2471\n",
      "Epoch 00116: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.14, 5%:  0.23, 25%:  0.69, 50%:  1.12, 75%:  1.29, 95%:  3.05, 100%:  4.60) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.82, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.8287 - output_0_loss: 0.3206 - output_1_loss: 0.2616 - output_2_loss: 0.2465 - val_loss: 4.5132 - val_output_0_loss: 1.5433 - val_output_1_loss: 1.4948 - val_output_2_loss: 1.4751\n",
      "Epoch 117/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8665 - output_0_loss: 0.3330 - output_1_loss: 0.2744 - output_2_loss: 0.2591\n",
      "Epoch 00117: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.28 (0%:  0.04, 5%:  0.28, 25%:  0.79, 50%:  1.10, 75%:  1.44, 95%:  3.04, 100%:  4.88) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.92, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.8632 - output_0_loss: 0.3317 - output_1_loss: 0.2733 - output_2_loss: 0.2581 - val_loss: 4.9364 - val_output_0_loss: 1.6706 - val_output_1_loss: 1.6394 - val_output_2_loss: 1.6264\n",
      "Epoch 118/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7620 - output_0_loss: 0.2960 - output_1_loss: 0.2401 - output_2_loss: 0.2259\n",
      "Epoch 00118: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.07, 5%:  0.28, 25%:  0.70, 50%:  1.05, 75%:  1.40, 95%:  3.21, 100%:  4.48) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.74, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7588 - output_0_loss: 0.2949 - output_1_loss: 0.2390 - output_2_loss: 0.2249 - val_loss: 4.7270 - val_output_0_loss: 1.6099 - val_output_1_loss: 1.5709 - val_output_2_loss: 1.5463\n",
      "Epoch 119/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8734 - output_0_loss: 0.3364 - output_1_loss: 0.2757 - output_2_loss: 0.2613  - ETA: 2:14 - lo\n",
      "Epoch 00119: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.05, 5%:  0.31, 25%:  0.76, 50%:  1.09, 75%:  1.39, 95%:  3.11, 100%:  3.97) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.74, 50%:  0.82, 75%:  0.92, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.8750 - output_0_loss: 0.3369 - output_1_loss: 0.2762 - output_2_loss: 0.2618 - val_loss: 4.7118 - val_output_0_loss: 1.6039 - val_output_1_loss: 1.5629 - val_output_2_loss: 1.5450\n",
      "Epoch 120/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7924 - output_0_loss: 0.3064 - output_1_loss: 0.2504 - output_2_loss: 0.2356\n",
      "Epoch 00120: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.05, 5%:  0.30, 25%:  0.74, 50%:  1.08, 75%:  1.40, 95%:  3.04, 100%:  4.48) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7921 - output_0_loss: 0.3063 - output_1_loss: 0.2503 - output_2_loss: 0.2355 - val_loss: 4.6413 - val_output_0_loss: 1.5831 - val_output_1_loss: 1.5397 - val_output_2_loss: 1.5185\n",
      "Epoch 121/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7895 - output_0_loss: 0.3066 - output_1_loss: 0.2484 - output_2_loss: 0.2345\n",
      "Epoch 00121: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.07, 5%:  0.15, 25%:  0.70, 50%:  1.10, 75%:  1.39, 95%:  2.98, 100%:  4.15) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7882 - output_0_loss: 0.3061 - output_1_loss: 0.2480 - output_2_loss: 0.2341 - val_loss: 4.4626 - val_output_0_loss: 1.5209 - val_output_1_loss: 1.4824 - val_output_2_loss: 1.4593\n",
      "Epoch 122/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.9026 - output_0_loss: 0.3463 - output_1_loss: 0.2851 - output_2_loss: 0.2712\n",
      "Epoch 00122: val_loss did not improve from 4.27701\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.18, 5%:  0.31, 25%:  0.70, 50%:  1.05, 75%:  1.35, 95%:  3.09, 100%:  3.64) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.9037 - output_0_loss: 0.3468 - output_1_loss: 0.2854 - output_2_loss: 0.2715 - val_loss: 4.4048 - val_output_0_loss: 1.5056 - val_output_1_loss: 1.4663 - val_output_2_loss: 1.4329\n",
      "Epoch 123/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8028 - output_0_loss: 0.3079 - output_1_loss: 0.2546 - output_2_loss: 0.2403\n",
      "Epoch 00123: val_loss improved from 4.27701 to 4.24483, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.08, 5%:  0.33, 25%:  0.71, 50%:  1.05, 75%:  1.35, 95%:  3.04, 100%:  3.65) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.73, 50%:  0.80, 75%:  0.91, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7993 - output_0_loss: 0.3067 - output_1_loss: 0.2535 - output_2_loss: 0.2392 - val_loss: 4.2448 - val_output_0_loss: 1.4584 - val_output_1_loss: 1.4032 - val_output_2_loss: 1.3832\n",
      "Epoch 124/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8374 - output_0_loss: 0.3247 - output_1_loss: 0.2633 - output_2_loss: 0.2494\n",
      "Epoch 00124: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.07, 5%:  0.18, 25%:  0.66, 50%:  0.97, 75%:  1.44, 95%:  2.96, 100%:  4.03) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.90, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.8333 - output_0_loss: 0.3231 - output_1_loss: 0.2619 - output_2_loss: 0.2482 - val_loss: 4.4206 - val_output_0_loss: 1.5127 - val_output_1_loss: 1.4672 - val_output_2_loss: 1.4407\n",
      "Epoch 125/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7964 - output_0_loss: 0.3060 - output_1_loss: 0.2520 - output_2_loss: 0.2384\n",
      "Epoch 00125: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.17 (0%:  0.11, 5%:  0.16, 25%:  0.65, 50%:  1.10, 75%:  1.31, 95%:  3.00, 100%:  3.92) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.73, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7940 - output_0_loss: 0.3051 - output_1_loss: 0.2512 - output_2_loss: 0.2376 - val_loss: 4.2553 - val_output_0_loss: 1.4569 - val_output_1_loss: 1.4070 - val_output_2_loss: 1.3914\n",
      "Epoch 126/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7112 - output_0_loss: 0.2764 - output_1_loss: 0.2240 - output_2_loss: 0.2108\n",
      "Epoch 00126: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.08, 5%:  0.25, 25%:  0.67, 50%:  1.05, 75%:  1.32, 95%:  3.11, 100%:  3.75) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.59, 25%:  0.73, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7102 - output_0_loss: 0.2760 - output_1_loss: 0.2237 - output_2_loss: 0.2105 - val_loss: 4.3264 - val_output_0_loss: 1.4808 - val_output_1_loss: 1.4348 - val_output_2_loss: 1.4109\n",
      "Epoch 127/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6834 - output_0_loss: 0.2645 - output_1_loss: 0.2154 - output_2_loss: 0.2035  - ETA: 1:21 - loss: 0.6685 - output_0_lo\n",
      "Epoch 00127: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.10, 5%:  0.23, 25%:  0.75, 50%:  1.07, 75%:  1.37, 95%:  2.99, 100%:  4.60) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6814 - output_0_loss: 0.2638 - output_1_loss: 0.2148 - output_2_loss: 0.2028 - val_loss: 4.6693 - val_output_0_loss: 1.5832 - val_output_1_loss: 1.5540 - val_output_2_loss: 1.5321\n",
      "Epoch 128/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7433 - output_0_loss: 0.2884 - output_1_loss: 0.2339 - output_2_loss: 0.2211\n",
      "Epoch 00128: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.10, 5%:  0.36, 25%:  0.77, 50%:  1.06, 75%:  1.40, 95%:  3.25, 100%:  3.86) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.73, 50%:  0.80, 75%:  0.90, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7442 - output_0_loss: 0.2889 - output_1_loss: 0.2340 - output_2_loss: 0.2213 - val_loss: 4.7558 - val_output_0_loss: 1.6262 - val_output_1_loss: 1.5764 - val_output_2_loss: 1.5533\n",
      "Epoch 129/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7163 - output_0_loss: 0.2775 - output_1_loss: 0.2252 - output_2_loss: 0.2137\n",
      "Epoch 00129: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.04, 5%:  0.29, 25%:  0.70, 50%:  1.05, 75%:  1.46, 95%:  2.95, 100%:  3.58) \n",
      "confidence - mean:  0.80 (0%:  0.53, 5%:  0.60, 25%:  0.73, 50%:  0.80, 75%:  0.90, 95%:  0.98, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7161 - output_0_loss: 0.2774 - output_1_loss: 0.2251 - output_2_loss: 0.2136 - val_loss: 4.3406 - val_output_0_loss: 1.4882 - val_output_1_loss: 1.4382 - val_output_2_loss: 1.4142\n",
      "Epoch 130/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7755 - output_0_loss: 0.3017 - output_1_loss: 0.2441 - output_2_loss: 0.2297\n",
      "Epoch 00130: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.08, 5%:  0.18, 25%:  0.67, 50%:  1.11, 75%:  1.37, 95%:  2.91, 100%:  4.43) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7787 - output_0_loss: 0.3027 - output_1_loss: 0.2453 - output_2_loss: 0.2308 - val_loss: 4.5361 - val_output_0_loss: 1.5422 - val_output_1_loss: 1.5056 - val_output_2_loss: 1.4882\n",
      "Epoch 131/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.8123 - output_0_loss: 0.3097 - output_1_loss: 0.2581 - output_2_loss: 0.2445\n",
      "Epoch 00131: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.04, 5%:  0.35, 25%:  0.59, 50%:  1.16, 75%:  1.43, 95%:  2.95, 100%:  4.94) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.75, 50%:  0.80, 75%:  0.90, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.8143 - output_0_loss: 0.3105 - output_1_loss: 0.2587 - output_2_loss: 0.2451 - val_loss: 4.8404 - val_output_0_loss: 1.6617 - val_output_1_loss: 1.6017 - val_output_2_loss: 1.5770\n",
      "Epoch 132/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6968 - output_0_loss: 0.2700 - output_1_loss: 0.2203 - output_2_loss: 0.2065\n",
      "Epoch 00132: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.11, 5%:  0.26, 25%:  0.68, 50%:  1.08, 75%:  1.43, 95%:  3.39, 100%:  3.66) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.59, 25%:  0.74, 50%:  0.81, 75%:  0.92, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6960 - output_0_loss: 0.2698 - output_1_loss: 0.2200 - output_2_loss: 0.2063 - val_loss: 4.5794 - val_output_0_loss: 1.5620 - val_output_1_loss: 1.5200 - val_output_2_loss: 1.4974\n",
      "Epoch 133/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7574 - output_0_loss: 0.2925 - output_1_loss: 0.2394 - output_2_loss: 0.2255\n",
      "Epoch 00133: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.05, 5%:  0.23, 25%:  0.68, 50%:  1.08, 75%:  1.44, 95%:  3.18, 100%:  3.58) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.73, 50%:  0.80, 75%:  0.90, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7770 - output_0_loss: 0.2995 - output_1_loss: 0.2457 - output_2_loss: 0.2318 - val_loss: 4.5180 - val_output_0_loss: 1.5405 - val_output_1_loss: 1.4987 - val_output_2_loss: 1.4789\n",
      "Epoch 134/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7504 - output_0_loss: 0.2914 - output_1_loss: 0.2362 - output_2_loss: 0.2227\n",
      "Epoch 00134: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.30 (0%:  0.16, 5%:  0.33, 25%:  0.69, 50%:  1.23, 75%:  1.48, 95%:  2.97, 100%:  4.77) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.61, 25%:  0.73, 50%:  0.80, 75%:  0.90, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7491 - output_0_loss: 0.2909 - output_1_loss: 0.2358 - output_2_loss: 0.2224 - val_loss: 5.0514 - val_output_0_loss: 1.7199 - val_output_1_loss: 1.6764 - val_output_2_loss: 1.6551\n",
      "Epoch 135/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7186 - output_0_loss: 0.2782 - output_1_loss: 0.2264 - output_2_loss: 0.2139\n",
      "Epoch 00135: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.18, 5%:  0.38, 25%:  0.65, 50%:  1.05, 75%:  1.44, 95%:  2.99, 100%:  4.16) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.73, 50%:  0.81, 75%:  0.91, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7183 - output_0_loss: 0.2782 - output_1_loss: 0.2263 - output_2_loss: 0.2138 - val_loss: 4.5131 - val_output_0_loss: 1.5377 - val_output_1_loss: 1.4984 - val_output_2_loss: 1.4770\n",
      "Epoch 136/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6824 - output_0_loss: 0.2636 - output_1_loss: 0.2158 - output_2_loss: 0.2031\n",
      "Epoch 00136: val_loss did not improve from 4.24483\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.15, 5%:  0.30, 25%:  0.64, 50%:  1.04, 75%:  1.44, 95%:  2.97, 100%:  3.66) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.74, 50%:  0.81, 75%:  0.92, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6791 - output_0_loss: 0.2624 - output_1_loss: 0.2147 - output_2_loss: 0.2020 - val_loss: 4.2958 - val_output_0_loss: 1.4666 - val_output_1_loss: 1.4225 - val_output_2_loss: 1.4067\n",
      "Epoch 137/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7097 - output_0_loss: 0.2780 - output_1_loss: 0.2225 - output_2_loss: 0.2091\n",
      "Epoch 00137: val_loss improved from 4.24483 to 4.11960, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.14, 5%:  0.39, 25%:  0.77, 50%:  1.01, 75%:  1.35, 95%:  2.89, 100%:  3.65) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.7078 - output_0_loss: 0.2773 - output_1_loss: 0.2220 - output_2_loss: 0.2085 - val_loss: 4.1196 - val_output_0_loss: 1.3993 - val_output_1_loss: 1.3680 - val_output_2_loss: 1.3523\n",
      "Epoch 138/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6566 - output_0_loss: 0.2557 - output_1_loss: 0.2063 - output_2_loss: 0.1946\n",
      "Epoch 00138: val_loss did not improve from 4.11960\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.07, 5%:  0.19, 25%:  0.64, 50%:  1.04, 75%:  1.46, 95%:  2.83, 100%:  3.42) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6598 - output_0_loss: 0.2569 - output_1_loss: 0.2073 - output_2_loss: 0.1956 - val_loss: 4.1660 - val_output_0_loss: 1.4222 - val_output_1_loss: 1.3796 - val_output_2_loss: 1.3642\n",
      "Epoch 139/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7458 - output_0_loss: 0.2883 - output_1_loss: 0.2353 - output_2_loss: 0.2222\n",
      "Epoch 00139: val_loss improved from 4.11960 to 4.07372, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.22, 5%:  0.29, 25%:  0.72, 50%:  1.06, 75%:  1.40, 95%:  2.61, 100%:  3.65) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.57, 25%:  0.73, 50%:  0.80, 75%:  0.91, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7419 - output_0_loss: 0.2869 - output_1_loss: 0.2340 - output_2_loss: 0.2210 - val_loss: 4.0737 - val_output_0_loss: 1.3947 - val_output_1_loss: 1.3492 - val_output_2_loss: 1.3299\n",
      "Epoch 140/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7519 - output_0_loss: 0.2898 - output_1_loss: 0.2377 - output_2_loss: 0.2244\n",
      "Epoch 00140: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.22, 5%:  0.29, 25%:  0.64, 50%:  1.14, 75%:  1.42, 95%:  3.22, 100%:  3.98) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.73, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7497 - output_0_loss: 0.2890 - output_1_loss: 0.2370 - output_2_loss: 0.2236 - val_loss: 4.6124 - val_output_0_loss: 1.5679 - val_output_1_loss: 1.5297 - val_output_2_loss: 1.5147\n",
      "Epoch 141/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7713 - output_0_loss: 0.2963 - output_1_loss: 0.2447 - output_2_loss: 0.2303\n",
      "Epoch 00141: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.08, 5%:  0.33, 25%:  0.73, 50%:  1.17, 75%:  1.48, 95%:  3.16, 100%:  4.18) \n",
      "confidence - mean:  0.82 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7688 - output_0_loss: 0.2954 - output_1_loss: 0.2438 - output_2_loss: 0.2295 - val_loss: 4.6720 - val_output_0_loss: 1.5859 - val_output_1_loss: 1.5514 - val_output_2_loss: 1.5346\n",
      "Epoch 142/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6634 - output_0_loss: 0.2617 - output_1_loss: 0.2075 - output_2_loss: 0.1942\n",
      "Epoch 00142: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.05, 5%:  0.35, 25%:  0.61, 50%:  1.13, 75%:  1.38, 95%:  2.92, 100%:  4.60) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.90, 95%:  0.99, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6623 - output_0_loss: 0.2613 - output_1_loss: 0.2071 - output_2_loss: 0.1939 - val_loss: 4.2956 - val_output_0_loss: 1.4616 - val_output_1_loss: 1.4218 - val_output_2_loss: 1.4123\n",
      "Epoch 143/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7216 - output_0_loss: 0.2779 - output_1_loss: 0.2281 - output_2_loss: 0.2156\n",
      "Epoch 00143: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.08, 5%:  0.20, 25%:  0.67, 50%:  1.12, 75%:  1.36, 95%:  3.18, 100%:  3.59) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.73, 50%:  0.81, 75%:  0.91, 95%:  0.98, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7188 - output_0_loss: 0.2770 - output_1_loss: 0.2271 - output_2_loss: 0.2147 - val_loss: 4.3519 - val_output_0_loss: 1.4854 - val_output_1_loss: 1.4407 - val_output_2_loss: 1.4259\n",
      "Epoch 144/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6918 - output_0_loss: 0.2710 - output_1_loss: 0.2169 - output_2_loss: 0.2039\n",
      "Epoch 00144: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.25, 5%:  0.43, 25%:  0.70, 50%:  1.11, 75%:  1.29, 95%:  3.14, 100%:  4.38) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.79, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6919 - output_0_loss: 0.2711 - output_1_loss: 0.2170 - output_2_loss: 0.2039 - val_loss: 4.7321 - val_output_0_loss: 1.6105 - val_output_1_loss: 1.5711 - val_output_2_loss: 1.5505\n",
      "Epoch 145/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6742 - output_0_loss: 0.2620 - output_1_loss: 0.2123 - output_2_loss: 0.2000\n",
      "Epoch 00145: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.05, 5%:  0.22, 25%:  0.68, 50%:  0.98, 75%:  1.36, 95%:  3.11, 100%:  3.71) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.93, 95%:  0.98, 100%:  0.99) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6733 - output_0_loss: 0.2617 - output_1_loss: 0.2119 - output_2_loss: 0.1997 - val_loss: 4.1950 - val_output_0_loss: 1.4313 - val_output_1_loss: 1.3911 - val_output_2_loss: 1.3726\n",
      "Epoch 146/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7060 - output_0_loss: 0.2780 - output_1_loss: 0.2206 - output_2_loss: 0.2075\n",
      "Epoch 00146: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.07, 5%:  0.30, 25%:  0.70, 50%:  1.17, 75%:  1.39, 95%:  3.06, 100%:  4.11) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7080 - output_0_loss: 0.2788 - output_1_loss: 0.2211 - output_2_loss: 0.2080 - val_loss: 4.3452 - val_output_0_loss: 1.4946 - val_output_1_loss: 1.4379 - val_output_2_loss: 1.4127\n",
      "Epoch 147/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7160 - output_0_loss: 0.2781 - output_1_loss: 0.2255 - output_2_loss: 0.2123\n",
      "Epoch 00147: val_loss did not improve from 4.07372\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.27 (0%:  0.08, 5%:  0.37, 25%:  0.79, 50%:  1.07, 75%:  1.43, 95%:  3.04, 100%:  4.66) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.75, 50%:  0.81, 75%:  0.90, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7129 - output_0_loss: 0.2770 - output_1_loss: 0.2245 - output_2_loss: 0.2114 - val_loss: 4.7769 - val_output_0_loss: 1.6984 - val_output_1_loss: 1.5514 - val_output_2_loss: 1.5271\n",
      "Epoch 148/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7021 - output_0_loss: 0.2710 - output_1_loss: 0.2216 - output_2_loss: 0.2096\n",
      "Epoch 00148: val_loss improved from 4.07372 to 4.06428, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.14, 5%:  0.33, 25%:  0.72, 50%:  1.01, 75%:  1.45, 95%:  3.00, 100%:  3.44) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.7046 - output_0_loss: 0.2719 - output_1_loss: 0.2223 - output_2_loss: 0.2104 - val_loss: 4.0643 - val_output_0_loss: 1.3860 - val_output_1_loss: 1.3482 - val_output_2_loss: 1.3301\n",
      "Epoch 149/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6663 - output_0_loss: 0.2605 - output_1_loss: 0.2092 - output_2_loss: 0.1966\n",
      "Epoch 00149: val_loss improved from 4.06428 to 4.03692, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.13, 5%:  0.34, 25%:  0.66, 50%:  1.06, 75%:  1.38, 95%:  3.08, 100%:  3.53) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.59, 25%:  0.73, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6710 - output_0_loss: 0.2622 - output_1_loss: 0.2107 - output_2_loss: 0.1981 - val_loss: 4.0369 - val_output_0_loss: 1.3750 - val_output_1_loss: 1.3374 - val_output_2_loss: 1.3245\n",
      "Epoch 150/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7233 - output_0_loss: 0.2816 - output_1_loss: 0.2278 - output_2_loss: 0.2139\n",
      "Epoch 00150: val_loss did not improve from 4.03692\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.08, 5%:  0.27, 25%:  0.70, 50%:  1.03, 75%:  1.41, 95%:  3.02, 100%:  3.81) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.93, 95%:  1.00, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.7217 - output_0_loss: 0.2811 - output_1_loss: 0.2273 - output_2_loss: 0.2133 - val_loss: 4.1793 - val_output_0_loss: 1.4229 - val_output_1_loss: 1.3886 - val_output_2_loss: 1.3678\n",
      "Epoch 151/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6547 - output_0_loss: 0.2539 - output_1_loss: 0.2067 - output_2_loss: 0.1941\n",
      "Epoch 00151: val_loss improved from 4.03692 to 3.78432, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.16 (0%:  0.25, 5%:  0.32, 25%:  0.69, 50%:  1.01, 75%:  1.38, 95%:  3.03, 100%:  3.42) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.75, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.6524 - output_0_loss: 0.2531 - output_1_loss: 0.2059 - output_2_loss: 0.1934 - val_loss: 3.7843 - val_output_0_loss: 1.2994 - val_output_1_loss: 1.2503 - val_output_2_loss: 1.2346\n",
      "Epoch 152/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5837 - output_0_loss: 0.2272 - output_1_loss: 0.1839 - output_2_loss: 0.1726\n",
      "Epoch 00152: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.19, 5%:  0.32, 25%:  0.74, 50%:  1.06, 75%:  1.45, 95%:  3.01, 100%:  3.44) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.73, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 225s 2s/step - loss: 0.5818 - output_0_loss: 0.2265 - output_1_loss: 0.1833 - output_2_loss: 0.1720 - val_loss: 4.2164 - val_output_0_loss: 1.4351 - val_output_1_loss: 1.3984 - val_output_2_loss: 1.3829\n",
      "Epoch 153/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6232 - output_0_loss: 0.2423 - output_1_loss: 0.1964 - output_2_loss: 0.1845\n",
      "Epoch 00153: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.05, 5%:  0.34, 25%:  0.74, 50%:  1.13, 75%:  1.41, 95%:  2.82, 100%:  4.55) \n",
      "confidence - mean:  0.82 (0%:  0.54, 5%:  0.61, 25%:  0.75, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.6222 - output_0_loss: 0.2419 - output_1_loss: 0.1961 - output_2_loss: 0.1842 - val_loss: 4.4155 - val_output_0_loss: 1.4985 - val_output_1_loss: 1.4638 - val_output_2_loss: 1.4533\n",
      "Epoch 154/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5667 - output_0_loss: 0.2233 - output_1_loss: 0.1775 - output_2_loss: 0.1659\n",
      "Epoch 00154: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.22, 5%:  0.47, 25%:  0.68, 50%:  1.02, 75%:  1.48, 95%:  3.05, 100%:  3.87) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5662 - output_0_loss: 0.2231 - output_1_loss: 0.1773 - output_2_loss: 0.1658 - val_loss: 4.2730 - val_output_0_loss: 1.4541 - val_output_1_loss: 1.4171 - val_output_2_loss: 1.4018\n",
      "Epoch 155/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5840 - output_0_loss: 0.2283 - output_1_loss: 0.1836 - output_2_loss: 0.1721\n",
      "Epoch 00155: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.16 (0%:  0.04, 5%:  0.37, 25%:  0.67, 50%:  1.04, 75%:  1.37, 95%:  2.82, 100%:  3.42) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.59, 25%:  0.75, 50%:  0.79, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5834 - output_0_loss: 0.2281 - output_1_loss: 0.1834 - output_2_loss: 0.1719 - val_loss: 3.8518 - val_output_0_loss: 1.3203 - val_output_1_loss: 1.2739 - val_output_2_loss: 1.2575\n",
      "Epoch 156/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6528 - output_0_loss: 0.2552 - output_1_loss: 0.2049 - output_2_loss: 0.1928\n",
      "Epoch 00156: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.07, 5%:  0.30, 25%:  0.63, 50%:  1.12, 75%:  1.35, 95%:  2.82, 100%:  4.33) \n",
      "confidence - mean:  0.81 (0%:  0.53, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6509 - output_0_loss: 0.2544 - output_1_loss: 0.2043 - output_2_loss: 0.1922 - val_loss: 4.2156 - val_output_0_loss: 1.4337 - val_output_1_loss: 1.3948 - val_output_2_loss: 1.3871\n",
      "Epoch 157/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6164 - output_0_loss: 0.2424 - output_1_loss: 0.1927 - output_2_loss: 0.1813\n",
      "Epoch 00157: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.07, 5%:  0.30, 25%:  0.55, 50%:  1.08, 75%:  1.55, 95%:  3.05, 100%:  4.86) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.61, 25%:  0.73, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6150 - output_0_loss: 0.2418 - output_1_loss: 0.1923 - output_2_loss: 0.1809 - val_loss: 4.7137 - val_output_0_loss: 1.6195 - val_output_1_loss: 1.5611 - val_output_2_loss: 1.5331\n",
      "Epoch 158/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6296 - output_0_loss: 0.2437 - output_1_loss: 0.1991 - output_2_loss: 0.1868\n",
      "Epoch 00158: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.14, 5%:  0.42, 25%:  0.72, 50%:  1.03, 75%:  1.32, 95%:  3.05, 100%:  3.49) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6294 - output_0_loss: 0.2437 - output_1_loss: 0.1990 - output_2_loss: 0.1867 - val_loss: 4.0078 - val_output_0_loss: 1.3742 - val_output_1_loss: 1.3252 - val_output_2_loss: 1.3084\n",
      "Epoch 159/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6905 - output_0_loss: 0.2678 - output_1_loss: 0.2181 - output_2_loss: 0.2046\n",
      "Epoch 00159: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.04, 5%:  0.40, 25%:  0.77, 50%:  1.12, 75%:  1.40, 95%:  2.76, 100%:  3.13) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.58, 25%:  0.73, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6887 - output_0_loss: 0.2671 - output_1_loss: 0.2176 - output_2_loss: 0.2040 - val_loss: 3.9108 - val_output_0_loss: 1.3429 - val_output_1_loss: 1.2956 - val_output_2_loss: 1.2723\n",
      "Epoch 160/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6275 - output_0_loss: 0.2440 - output_1_loss: 0.1978 - output_2_loss: 0.1857\n",
      "Epoch 00160: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.18 (0%:  0.22, 5%:  0.41, 25%:  0.78, 50%:  1.02, 75%:  1.41, 95%:  2.69, 100%:  3.42) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.59, 25%:  0.74, 50%:  0.81, 75%:  0.91, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6282 - output_0_loss: 0.2442 - output_1_loss: 0.1980 - output_2_loss: 0.1861 - val_loss: 3.8135 - val_output_0_loss: 1.2992 - val_output_1_loss: 1.2621 - val_output_2_loss: 1.2523\n",
      "Epoch 161/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5769 - output_0_loss: 0.2244 - output_1_loss: 0.1816 - output_2_loss: 0.1708\n",
      "Epoch 00161: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.05, 5%:  0.29, 25%:  0.65, 50%:  1.09, 75%:  1.48, 95%:  3.16, 100%:  3.70) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.73, 50%:  0.79, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5766 - output_0_loss: 0.2243 - output_1_loss: 0.1816 - output_2_loss: 0.1708 - val_loss: 4.3636 - val_output_0_loss: 1.4915 - val_output_1_loss: 1.4452 - val_output_2_loss: 1.4270\n",
      "Epoch 162/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5591 - output_0_loss: 0.2223 - output_1_loss: 0.1744 - output_2_loss: 0.1623\n",
      "Epoch 00162: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.25 (0%:  0.14, 5%:  0.25, 25%:  0.77, 50%:  1.09, 75%:  1.42, 95%:  2.84, 100%:  5.39) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5572 - output_0_loss: 0.2216 - output_1_loss: 0.1738 - output_2_loss: 0.1618 - val_loss: 4.7315 - val_output_0_loss: 1.5998 - val_output_1_loss: 1.5714 - val_output_2_loss: 1.5603\n",
      "Epoch 163/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5441 - output_0_loss: 0.2143 - output_1_loss: 0.1704 - output_2_loss: 0.1594\n",
      "Epoch 00163: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.07, 5%:  0.29, 25%:  0.75, 50%:  1.07, 75%:  1.39, 95%:  3.12, 100%:  3.78) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.73, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5471 - output_0_loss: 0.2155 - output_1_loss: 0.1714 - output_2_loss: 0.1603 - val_loss: 4.4345 - val_output_0_loss: 1.5128 - val_output_1_loss: 1.4709 - val_output_2_loss: 1.4508\n",
      "Epoch 164/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6488 - output_0_loss: 0.2517 - output_1_loss: 0.2055 - output_2_loss: 0.1917\n",
      "Epoch 00164: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.15 (0%:  0.18, 5%:  0.36, 25%:  0.70, 50%:  1.05, 75%:  1.30, 95%:  2.67, 100%:  3.41) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.79, 75%:  0.91, 95%:  0.98, 100%:  1.00) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6469 - output_0_loss: 0.2510 - output_1_loss: 0.2048 - output_2_loss: 0.1912 - val_loss: 3.8627 - val_output_0_loss: 1.3287 - val_output_1_loss: 1.2765 - val_output_2_loss: 1.2575\n",
      "Epoch 165/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6659 - output_0_loss: 0.2577 - output_1_loss: 0.2102 - output_2_loss: 0.1980\n",
      "Epoch 00165: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.16 (0%:  0.25, 5%:  0.30, 25%:  0.73, 50%:  0.97, 75%:  1.32, 95%:  3.07, 100%:  3.42) \n",
      "confidence - mean:  0.82 (0%:  0.55, 5%:  0.60, 25%:  0.76, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.03) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6825 - output_0_loss: 0.2632 - output_1_loss: 0.2159 - output_2_loss: 0.2034 - val_loss: 3.8983 - val_output_0_loss: 1.3406 - val_output_1_loss: 1.2879 - val_output_2_loss: 1.2698\n",
      "Epoch 166/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6756 - output_0_loss: 0.2603 - output_1_loss: 0.2140 - output_2_loss: 0.2012\n",
      "Epoch 00166: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.30, 5%:  0.42, 25%:  0.74, 50%:  1.02, 75%:  1.31, 95%:  2.87, 100%:  4.18) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.62, 25%:  0.74, 50%:  0.79, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6750 - output_0_loss: 0.2602 - output_1_loss: 0.2138 - output_2_loss: 0.2010 - val_loss: 4.0937 - val_output_0_loss: 1.3981 - val_output_1_loss: 1.3575 - val_output_2_loss: 1.3381\n",
      "Epoch 167/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6792 - output_0_loss: 0.2630 - output_1_loss: 0.2144 - output_2_loss: 0.2018\n",
      "Epoch 00167: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.14 (0%:  0.14, 5%:  0.31, 25%:  0.65, 50%:  1.01, 75%:  1.36, 95%:  2.54, 100%:  3.59) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.58, 25%:  0.75, 50%:  0.79, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6774 - output_0_loss: 0.2623 - output_1_loss: 0.2138 - output_2_loss: 0.2012 - val_loss: 3.9826 - val_output_0_loss: 1.4130 - val_output_1_loss: 1.3105 - val_output_2_loss: 1.2591\n",
      "Epoch 168/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.7413 - output_0_loss: 0.2843 - output_1_loss: 0.2359 - output_2_loss: 0.2212\n",
      "Epoch 00168: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.16, 5%:  0.44, 25%:  0.69, 50%:  1.03, 75%:  1.38, 95%:  2.96, 100%:  3.75) \n",
      "confidence - mean:  0.82 (0%:  0.54, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.7413 - output_0_loss: 0.2842 - output_1_loss: 0.2359 - output_2_loss: 0.2212 - val_loss: 4.1887 - val_output_0_loss: 1.4287 - val_output_1_loss: 1.3894 - val_output_2_loss: 1.3705\n",
      "Epoch 169/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6172 - output_0_loss: 0.2416 - output_1_loss: 0.1936 - output_2_loss: 0.1819\n",
      "Epoch 00169: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.21, 5%:  0.37, 25%:  0.68, 50%:  1.13, 75%:  1.33, 95%:  3.07, 100%:  4.90) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6161 - output_0_loss: 0.2413 - output_1_loss: 0.1933 - output_2_loss: 0.1816 - val_loss: 4.4361 - val_output_0_loss: 1.5013 - val_output_1_loss: 1.4718 - val_output_2_loss: 1.4629\n",
      "Epoch 170/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5770 - output_0_loss: 0.2229 - output_1_loss: 0.1822 - output_2_loss: 0.1719\n",
      "Epoch 00170: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.08, 5%:  0.31, 25%:  0.78, 50%:  1.05, 75%:  1.31, 95%:  3.11, 100%:  3.71) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.75, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.5759 - output_0_loss: 0.2225 - output_1_loss: 0.1819 - output_2_loss: 0.1716 - val_loss: 4.3322 - val_output_0_loss: 1.4695 - val_output_1_loss: 1.4376 - val_output_2_loss: 1.4251\n",
      "Epoch 171/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5867 - output_0_loss: 0.2272 - output_1_loss: 0.1849 - output_2_loss: 0.1745\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.26 (0%:  0.25, 5%:  0.42, 25%:  0.72, 50%:  1.16, 75%:  1.39, 95%:  3.24, 100%:  5.00) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.61, 25%:  0.72, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.02) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5952 - output_0_loss: 0.2301 - output_1_loss: 0.1877 - output_2_loss: 0.1774 - val_loss: 4.7941 - val_output_0_loss: 1.6293 - val_output_1_loss: 1.5916 - val_output_2_loss: 1.5732\n",
      "Epoch 172/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5799 - output_0_loss: 0.2314 - output_1_loss: 0.1811 - output_2_loss: 0.1675\n",
      "Epoch 00172: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.22, 5%:  0.35, 25%:  0.70, 50%:  1.06, 75%:  1.35, 95%:  3.21, 100%:  3.75) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5972 - output_0_loss: 0.2376 - output_1_loss: 0.1866 - output_2_loss: 0.1730 - val_loss: 4.2791 - val_output_0_loss: 1.4576 - val_output_1_loss: 1.4172 - val_output_2_loss: 1.4043\n",
      "Epoch 173/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5034 - output_0_loss: 0.2001 - output_1_loss: 0.1574 - output_2_loss: 0.1460\n",
      "Epoch 00173: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.19, 5%:  0.34, 25%:  0.70, 50%:  1.07, 75%:  1.36, 95%:  3.16, 100%:  3.54) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.79, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.5043 - output_0_loss: 0.2003 - output_1_loss: 0.1577 - output_2_loss: 0.1463 - val_loss: 4.2195 - val_output_0_loss: 1.4366 - val_output_1_loss: 1.3986 - val_output_2_loss: 1.3843\n",
      "Epoch 174/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5294 - output_0_loss: 0.2087 - output_1_loss: 0.1661 - output_2_loss: 0.1545\n",
      "Epoch 00174: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.08, 5%:  0.32, 25%:  0.70, 50%:  1.06, 75%:  1.35, 95%:  3.03, 100%:  3.54) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5290 - output_0_loss: 0.2085 - output_1_loss: 0.1660 - output_2_loss: 0.1544 - val_loss: 4.1474 - val_output_0_loss: 1.4132 - val_output_1_loss: 1.3738 - val_output_2_loss: 1.3603\n",
      "Epoch 175/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5284 - output_0_loss: 0.2113 - output_1_loss: 0.1646 - output_2_loss: 0.1525\n",
      "Epoch 00175: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.15, 5%:  0.35, 25%:  0.70, 50%:  1.04, 75%:  1.32, 95%:  3.17, 100%:  3.54) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5307 - output_0_loss: 0.2123 - output_1_loss: 0.1653 - output_2_loss: 0.1531 - val_loss: 4.1817 - val_output_0_loss: 1.4235 - val_output_1_loss: 1.3867 - val_output_2_loss: 1.3715\n",
      "Epoch 176/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.6212 - output_0_loss: 0.2440 - output_1_loss: 0.1950 - output_2_loss: 0.1822\n",
      "Epoch 00176: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.22, 5%:  0.32, 25%:  0.67, 50%:  1.08, 75%:  1.33, 95%:  3.22, 100%:  3.63) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.6199 - output_0_loss: 0.2436 - output_1_loss: 0.1945 - output_2_loss: 0.1817 - val_loss: 4.3093 - val_output_0_loss: 1.4675 - val_output_1_loss: 1.4295 - val_output_2_loss: 1.4122\n",
      "Epoch 177/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4859 - output_0_loss: 0.1934 - output_1_loss: 0.1519 - output_2_loss: 0.1407\n",
      "Epoch 00177: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.16, 5%:  0.34, 25%:  0.68, 50%:  1.07, 75%:  1.30, 95%:  3.25, 100%:  3.58) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.4840 - output_0_loss: 0.1927 - output_1_loss: 0.1512 - output_2_loss: 0.1401 - val_loss: 4.2652 - val_output_0_loss: 1.4525 - val_output_1_loss: 1.4141 - val_output_2_loss: 1.3986\n",
      "Epoch 178/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5451 - output_0_loss: 0.2132 - output_1_loss: 0.1714 - output_2_loss: 0.1605\n",
      "Epoch 00178: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.19, 5%:  0.31, 25%:  0.70, 50%:  1.05, 75%:  1.30, 95%:  3.08, 100%:  3.51) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5440 - output_0_loss: 0.2127 - output_1_loss: 0.1711 - output_2_loss: 0.1602 - val_loss: 4.1795 - val_output_0_loss: 1.4219 - val_output_1_loss: 1.3857 - val_output_2_loss: 1.3720\n",
      "Epoch 179/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5417 - output_0_loss: 0.2125 - output_1_loss: 0.1703 - output_2_loss: 0.1589\n",
      "Epoch 00179: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.19, 5%:  0.37, 25%:  0.75, 50%:  1.06, 75%:  1.35, 95%:  3.10, 100%:  4.15) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5404 - output_0_loss: 0.2120 - output_1_loss: 0.1699 - output_2_loss: 0.1585 - val_loss: 4.3656 - val_output_0_loss: 1.4808 - val_output_1_loss: 1.4496 - val_output_2_loss: 1.4352\n",
      "Epoch 180/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5881 - output_0_loss: 0.2305 - output_1_loss: 0.1850 - output_2_loss: 0.1726\n",
      "Epoch 00180: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.14, 5%:  0.42, 25%:  0.67, 50%:  1.11, 75%:  1.34, 95%:  3.11, 100%:  4.66) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.92, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5897 - output_0_loss: 0.2311 - output_1_loss: 0.1856 - output_2_loss: 0.1731 - val_loss: 4.4913 - val_output_0_loss: 1.5225 - val_output_1_loss: 1.4928 - val_output_2_loss: 1.4760\n",
      "Epoch 181/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5656 - output_0_loss: 0.2230 - output_1_loss: 0.1770 - output_2_loss: 0.1656\n",
      "Epoch 00181: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.19 (0%:  0.25, 5%:  0.30, 25%:  0.69, 50%:  1.09, 75%:  1.30, 95%:  3.07, 100%:  3.51) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5671 - output_0_loss: 0.2237 - output_1_loss: 0.1774 - output_2_loss: 0.1660 - val_loss: 4.0762 - val_output_0_loss: 1.3834 - val_output_1_loss: 1.3535 - val_output_2_loss: 1.3393\n",
      "Epoch 182/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5802 - output_0_loss: 0.2251 - output_1_loss: 0.1838 - output_2_loss: 0.1713\n",
      "Epoch 00182: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.20 (0%:  0.04, 5%:  0.28, 25%:  0.70, 50%:  1.06, 75%:  1.30, 95%:  2.90, 100%:  3.75) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5791 - output_0_loss: 0.2247 - output_1_loss: 0.1834 - output_2_loss: 0.1710 - val_loss: 4.1101 - val_output_0_loss: 1.3938 - val_output_1_loss: 1.3645 - val_output_2_loss: 1.3519\n",
      "Epoch 183/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5160 - output_0_loss: 0.2043 - output_1_loss: 0.1618 - output_2_loss: 0.1499\n",
      "Epoch 00183: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.22, 5%:  0.37, 25%:  0.73, 50%:  1.11, 75%:  1.35, 95%:  3.09, 100%:  4.32) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.81, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5150 - output_0_loss: 0.2039 - output_1_loss: 0.1615 - output_2_loss: 0.1496 - val_loss: 4.4804 - val_output_0_loss: 1.5132 - val_output_1_loss: 1.4899 - val_output_2_loss: 1.4773\n",
      "Epoch 184/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5602 - output_0_loss: 0.2206 - output_1_loss: 0.1757 - output_2_loss: 0.1639\n",
      "Epoch 00184: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.22, 5%:  0.32, 25%:  0.70, 50%:  1.06, 75%:  1.32, 95%:  3.26, 100%:  3.86) \n",
      "confidence - mean:  0.81 (0%:  0.54, 5%:  0.60, 25%:  0.75, 50%:  0.81, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5595 - output_0_loss: 0.2205 - output_1_loss: 0.1754 - output_2_loss: 0.1636 - val_loss: 4.4204 - val_output_0_loss: 1.4977 - val_output_1_loss: 1.4681 - val_output_2_loss: 1.4546\n",
      "Epoch 185/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5601 - output_0_loss: 0.2193 - output_1_loss: 0.1762 - output_2_loss: 0.1646\n",
      "Epoch 00185: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.25, 5%:  0.34, 25%:  0.70, 50%:  1.06, 75%:  1.31, 95%:  3.22, 100%:  3.92) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.92, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5606 - output_0_loss: 0.2195 - output_1_loss: 0.1763 - output_2_loss: 0.1648 - val_loss: 4.2657 - val_output_0_loss: 1.4477 - val_output_1_loss: 1.4161 - val_output_2_loss: 1.4020\n",
      "Epoch 186/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5531 - output_0_loss: 0.2156 - output_1_loss: 0.1744 - output_2_loss: 0.1631\n",
      "Epoch 00186: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.30, 5%:  0.33, 25%:  0.70, 50%:  1.06, 75%:  1.30, 95%:  3.21, 100%:  3.53) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5521 - output_0_loss: 0.2152 - output_1_loss: 0.1740 - output_2_loss: 0.1628 - val_loss: 4.2127 - val_output_0_loss: 1.4310 - val_output_1_loss: 1.3976 - val_output_2_loss: 1.3842\n",
      "Epoch 187/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5498 - output_0_loss: 0.2161 - output_1_loss: 0.1729 - output_2_loss: 0.1608\n",
      "Epoch 00187: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.25, 5%:  0.29, 25%:  0.71, 50%:  1.06, 75%:  1.37, 95%:  3.17, 100%:  3.53) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5532 - output_0_loss: 0.2177 - output_1_loss: 0.1739 - output_2_loss: 0.1616 - val_loss: 4.2610 - val_output_0_loss: 1.4484 - val_output_1_loss: 1.4136 - val_output_2_loss: 1.3990\n",
      "Epoch 188/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5104 - output_0_loss: 0.2006 - output_1_loss: 0.1605 - output_2_loss: 0.1493\n",
      "Epoch 00188: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.26, 5%:  0.35, 25%:  0.70, 50%:  1.10, 75%:  1.37, 95%:  3.19, 100%:  3.81) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.75, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.5121 - output_0_loss: 0.2013 - output_1_loss: 0.1611 - output_2_loss: 0.1497 - val_loss: 4.3839 - val_output_0_loss: 1.4842 - val_output_1_loss: 1.4554 - val_output_2_loss: 1.4443\n",
      "Epoch 189/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5177 - output_0_loss: 0.2038 - output_1_loss: 0.1624 - output_2_loss: 0.1515\n",
      "Epoch 00189: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.26, 5%:  0.30, 25%:  0.70, 50%:  1.07, 75%:  1.35, 95%:  3.15, 100%:  3.98) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5157 - output_0_loss: 0.2031 - output_1_loss: 0.1618 - output_2_loss: 0.1508 - val_loss: 4.3480 - val_output_0_loss: 1.4725 - val_output_1_loss: 1.4445 - val_output_2_loss: 1.4309\n",
      "Epoch 190/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5421 - output_0_loss: 0.2129 - output_1_loss: 0.1702 - output_2_loss: 0.1589\n",
      "Epoch 00190: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.25, 5%:  0.35, 25%:  0.70, 50%:  1.06, 75%:  1.35, 95%:  3.20, 100%:  3.59) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.90, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5392 - output_0_loss: 0.2119 - output_1_loss: 0.1693 - output_2_loss: 0.1580 - val_loss: 4.1907 - val_output_0_loss: 1.4216 - val_output_1_loss: 1.3910 - val_output_2_loss: 1.3780\n",
      "Epoch 191/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5237 - output_0_loss: 0.2064 - output_1_loss: 0.1643 - output_2_loss: 0.1529\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.22, 5%:  0.29, 25%:  0.73, 50%:  1.10, 75%:  1.37, 95%:  3.11, 100%:  3.44) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5217 - output_0_loss: 0.2057 - output_1_loss: 0.1637 - output_2_loss: 0.1523 - val_loss: 4.1807 - val_output_0_loss: 1.4165 - val_output_1_loss: 1.3885 - val_output_2_loss: 1.3757\n",
      "Epoch 192/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4850 - output_0_loss: 0.1912 - output_1_loss: 0.1528 - output_2_loss: 0.1410\n",
      "Epoch 00192: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.22, 5%:  0.29, 25%:  0.70, 50%:  1.09, 75%:  1.36, 95%:  3.15, 100%:  3.53) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.4839 - output_0_loss: 0.1908 - output_1_loss: 0.1525 - output_2_loss: 0.1406 - val_loss: 4.2162 - val_output_0_loss: 1.4319 - val_output_1_loss: 1.3987 - val_output_2_loss: 1.3856\n",
      "Epoch 193/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4603 - output_0_loss: 0.1849 - output_1_loss: 0.1434 - output_2_loss: 0.1320\n",
      "Epoch 00193: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.22, 5%:  0.30, 25%:  0.65, 50%:  1.10, 75%:  1.39, 95%:  3.15, 100%:  3.75) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.4587 - output_0_loss: 0.1844 - output_1_loss: 0.1429 - output_2_loss: 0.1315 - val_loss: 4.3341 - val_output_0_loss: 1.4703 - val_output_1_loss: 1.4388 - val_output_2_loss: 1.4250\n",
      "Epoch 194/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5661 - output_0_loss: 0.2231 - output_1_loss: 0.1774 - output_2_loss: 0.1655\n",
      "Epoch 00194: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.18, 5%:  0.30, 25%:  0.70, 50%:  1.11, 75%:  1.36, 95%:  3.13, 100%:  4.20) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.61, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5713 - output_0_loss: 0.2252 - output_1_loss: 0.1790 - output_2_loss: 0.1671 - val_loss: 4.4070 - val_output_0_loss: 1.4935 - val_output_1_loss: 1.4634 - val_output_2_loss: 1.4501\n",
      "Epoch 195/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4941 - output_0_loss: 0.1962 - output_1_loss: 0.1546 - output_2_loss: 0.1432\n",
      "Epoch 00195: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.22 (0%:  0.22, 5%:  0.30, 25%:  0.70, 50%:  1.11, 75%:  1.37, 95%:  3.15, 100%:  3.92) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.4930 - output_0_loss: 0.1958 - output_1_loss: 0.1543 - output_2_loss: 0.1429 - val_loss: 4.3440 - val_output_0_loss: 1.4730 - val_output_1_loss: 1.4421 - val_output_2_loss: 1.4289\n",
      "Epoch 196/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4995 - output_0_loss: 0.1980 - output_1_loss: 0.1563 - output_2_loss: 0.1451\n",
      "Epoch 00196: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.22, 5%:  0.29, 25%:  0.70, 50%:  1.10, 75%:  1.33, 95%:  3.13, 100%:  3.51) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.4993 - output_0_loss: 0.1980 - output_1_loss: 0.1563 - output_2_loss: 0.1451 - val_loss: 4.1820 - val_output_0_loss: 1.4192 - val_output_1_loss: 1.3877 - val_output_2_loss: 1.3751\n",
      "Epoch 197/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5470 - output_0_loss: 0.2153 - output_1_loss: 0.1720 - output_2_loss: 0.1597\n",
      "Epoch 00197: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.21 (0%:  0.22, 5%:  0.30, 25%:  0.70, 50%:  1.12, 75%:  1.35, 95%:  3.13, 100%:  3.47) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.59, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  0.99, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5441 - output_0_loss: 0.2143 - output_1_loss: 0.1711 - output_2_loss: 0.1587 - val_loss: 4.1673 - val_output_0_loss: 1.4151 - val_output_1_loss: 1.3824 - val_output_2_loss: 1.3698\n",
      "Epoch 198/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5200 - output_0_loss: 0.2070 - output_1_loss: 0.1629 - output_2_loss: 0.1501\n",
      "Epoch 00198: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.22, 5%:  0.29, 25%:  0.71, 50%:  1.12, 75%:  1.37, 95%:  3.10, 100%:  4.09) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5181 - output_0_loss: 0.2063 - output_1_loss: 0.1623 - output_2_loss: 0.1496 - val_loss: 4.3971 - val_output_0_loss: 1.4902 - val_output_1_loss: 1.4602 - val_output_2_loss: 1.4467\n",
      "Epoch 199/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5056 - output_0_loss: 0.2011 - output_1_loss: 0.1583 - output_2_loss: 0.1462\n",
      "Epoch 00199: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.22, 5%:  0.27, 25%:  0.70, 50%:  1.11, 75%:  1.36, 95%:  3.10, 100%:  3.86) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5043 - output_0_loss: 0.2006 - output_1_loss: 0.1579 - output_2_loss: 0.1459 - val_loss: 4.3438 - val_output_0_loss: 1.4729 - val_output_1_loss: 1.4423 - val_output_2_loss: 1.4285\n",
      "Epoch 200/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4777 - output_0_loss: 0.1893 - output_1_loss: 0.1496 - output_2_loss: 0.1388\n",
      "Epoch 00200: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.23 (0%:  0.22, 5%:  0.30, 25%:  0.69, 50%:  1.11, 75%:  1.36, 95%:  3.14, 100%:  3.86) \n",
      "confidence - mean:  0.81 (0%:  0.55, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.4788 - output_0_loss: 0.1897 - output_1_loss: 0.1499 - output_2_loss: 0.1391 - val_loss: 4.3397 - val_output_0_loss: 1.4722 - val_output_1_loss: 1.4405 - val_output_2_loss: 1.4271\n",
      "Epoch 201/500\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.5923 - output_0_loss: 0.2343 - output_1_loss: 0.1858 - output_2_loss: 0.1721\n",
      "Epoch 00201: val_loss did not improve from 3.78432\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.24 (0%:  0.22, 5%:  0.37, 25%:  0.71, 50%:  1.10, 75%:  1.33, 95%:  3.13, 100%:  4.04) \n",
      "confidence - mean:  0.81 (0%:  0.56, 5%:  0.60, 25%:  0.74, 50%:  0.80, 75%:  0.91, 95%:  1.00, 100%:  1.01) \n",
      "\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.5900 - output_0_loss: 0.2334 - output_1_loss: 0.1851 - output_2_loss: 0.1714 - val_loss: 4.3794 - val_output_0_loss: 1.4846 - val_output_1_loss: 1.4539 - val_output_2_loss: 1.4409\n",
      "Epoch 00201: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    batch_size=3,\n",
    "    validation_batch_size=2,\n",
    "    callbacks=callbacks,\n",
    "    epochs=500, # Increase the number of epochs to train the model longer\n",
    "    #epochs=200,\n",
    "    n_workers=8,\n",
    "    steps_per_epoch=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and resume training\n",
    "\n",
    "This loads the saved model and passes it the augmentation pipeline and `DataGenerator` from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\n",
    "    HOME + \"/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet_merged_3.h5\",\n",
    "    augmenter=augmenter,\n",
    "    generator=data_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better choose parameters for `model.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'StackedDenseNet',\n",
       " 'n_stacks': 2,\n",
       " 'n_transitions': 7,\n",
       " 'growth_rate': 32,\n",
       " 'bottleneck_factor': 1,\n",
       " 'compression_factor': 0.5,\n",
       " 'pretrained': True,\n",
       " 'subpixel': True,\n",
       " 'n_train': 64,\n",
       " 'n_validation': 15,\n",
       " 'validation_split': 0.2,\n",
       " 'downsample_factor': 3,\n",
       " 'output_shape': (48, 48),\n",
       " 'n_output_channels': 54,\n",
       " 'shuffle': True,\n",
       " 'sigma': 5,\n",
       " 'output_sigma': 0.625,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 1,\n",
       " 'random_seed': 1,\n",
       " 'augmenter': True,\n",
       " 'datapath': '/home/urs/Documents/programming/my_data_spider/spider_cropped_annotation_set_merged_3.h5',\n",
       " 'dataset': 'images',\n",
       " 'generator': 'DataGenerator',\n",
       " 'n_samples': 79,\n",
       " 'image_shape': (384, 384, 3),\n",
       " 'keypoints_shape': (26, 2)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resume training, simply call `model.fit` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/1000\n",
      "19/20 [===========================>..] - ETA: 15s - loss: 10.8165 - output_0_loss: 4.7228 - output_1_loss: 3.2244 - output_2_loss: 2.8693\n",
      "Epoch 00001: val_loss improved from inf to 14.83121, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet_merged_3.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25683.91 (0%:  0.00, 5%:  0.23, 25%:  0.57, 50%:  1.32, 75%:  4.39, 95%: 141691.64, 100%: 141805.36) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "20/20 [==============================] - 331s 17s/step - loss: 10.9398 - output_0_loss: 4.7920 - output_1_loss: 3.2574 - output_2_loss: 2.8903 - val_loss: 14.8312 - val_output_0_loss: 6.0363 - val_output_1_loss: 4.5486 - val_output_2_loss: 4.2463\n",
      "Epoch 2/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.6606 - output_0_loss: 4.6818 - output_1_loss: 3.1729 - output_2_loss: 2.8059\n",
      "Epoch 00002: val_loss improved from 14.83121 to 14.77573, saving model to /home/urs/Documents/programming/my_data_spider/best_model_cropped_StackedDenseNet_merged_3.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21400.32 (0%:  0.00, 5%:  0.23, 25%:  0.57, 50%:  1.30, 75%:  3.33, 95%: 141638.24, 100%: 141789.09) \n",
      "confidence - mean:  0.62 (0%:  0.01, 5%:  0.01, 25%:  0.56, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.8185 - output_0_loss: 4.7533 - output_1_loss: 3.2183 - output_2_loss: 2.8469 - val_loss: 14.7757 - val_output_0_loss: 6.0152 - val_output_1_loss: 4.5337 - val_output_2_loss: 4.2268\n",
      "Epoch 3/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1864 - output_0_loss: 4.4846 - output_1_loss: 3.0190 - output_2_loss: 2.6828\n",
      "Epoch 00003: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24126.50 (0%:  0.00, 5%:  0.22, 25%:  0.60, 50%:  1.32, 75%:  3.73, 95%: 141684.44, 100%: 141805.52) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 10.1849 - output_0_loss: 4.4987 - output_1_loss: 3.0118 - output_2_loss: 2.6744 - val_loss: 15.0044 - val_output_0_loss: 6.0655 - val_output_1_loss: 4.6089 - val_output_2_loss: 4.3300\n",
      "Epoch 4/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.2653 - output_0_loss: 4.5175 - output_1_loss: 3.0434 - output_2_loss: 2.7043\n",
      "Epoch 00004: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21400.24 (0%:  0.00, 5%:  0.18, 25%:  0.58, 50%:  1.27, 75%:  3.17, 95%: 141628.30, 100%: 141788.75) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.55, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "20/20 [==============================] - 337s 17s/step - loss: 10.3208 - output_0_loss: 4.5446 - output_1_loss: 3.0580 - output_2_loss: 2.7182 - val_loss: 15.0521 - val_output_0_loss: 6.0605 - val_output_1_loss: 4.6323 - val_output_2_loss: 4.3593\n",
      "Epoch 5/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.3228 - output_0_loss: 4.5252 - output_1_loss: 3.0679 - output_2_loss: 2.7297\n",
      "Epoch 00005: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23740.96 (0%:  0.00, 5%:  0.23, 25%:  0.57, 50%:  1.32, 75%:  3.64, 95%: 141726.13, 100%: 141805.80) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.72, 75%:  0.83, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 10.2468 - output_0_loss: 4.5025 - output_1_loss: 3.0400 - output_2_loss: 2.7042 - val_loss: 14.9970 - val_output_0_loss: 6.0347 - val_output_1_loss: 4.6201 - val_output_2_loss: 4.3421\n",
      "Epoch 6/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.2828 - output_0_loss: 4.5384 - output_1_loss: 3.0437 - output_2_loss: 2.7007\n",
      "Epoch 00006: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 19071.18 (0%:  0.08, 5%:  0.23, 25%:  0.52, 50%:  1.22, 75%:  2.95, 95%: 141701.79, 100%: 141806.31) \n",
      "confidence - mean:  0.63 (0%:  0.00, 5%:  0.01, 25%:  0.58, 50%:  0.74, 75%:  0.83, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 333s 17s/step - loss: 10.4280 - output_0_loss: 4.5917 - output_1_loss: 3.0901 - output_2_loss: 2.7462 - val_loss: 15.0066 - val_output_0_loss: 6.0305 - val_output_1_loss: 4.6270 - val_output_2_loss: 4.3490\n",
      "Epoch 7/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.3725 - output_0_loss: 4.5591 - output_1_loss: 3.0739 - output_2_loss: 2.7395\n",
      "Epoch 00007: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25295.49 (0%:  0.00, 5%:  0.21, 25%:  0.58, 50%:  1.34, 75%:  3.82, 95%: 141748.72, 100%: 141806.27) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.3695 - output_0_loss: 4.5680 - output_1_loss: 3.0691 - output_2_loss: 2.7324 - val_loss: 14.9059 - val_output_0_loss: 6.0039 - val_output_1_loss: 4.5906 - val_output_2_loss: 4.3113\n",
      "Epoch 8/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.5139 - output_0_loss: 4.6259 - output_1_loss: 3.1188 - output_2_loss: 2.7692\n",
      "Epoch 00008: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21400.64 (0%:  0.00, 5%:  0.21, 25%:  0.57, 50%:  1.22, 75%:  3.17, 95%: 141638.28, 100%: 141789.70) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.56, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 10.5705 - output_0_loss: 4.6534 - output_1_loss: 3.1355 - output_2_loss: 2.7816 - val_loss: 14.9958 - val_output_0_loss: 6.0261 - val_output_1_loss: 4.6206 - val_output_2_loss: 4.3491\n",
      "Epoch 9/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7982 - output_0_loss: 4.3746 - output_1_loss: 2.8784 - output_2_loss: 2.5453\n",
      "Epoch 00009: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21399.65 (0%:  0.00, 5%:  0.23, 25%:  0.56, 50%:  1.21, 75%:  3.10, 95%: 141627.42, 100%: 141789.55) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.55, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.9187 - output_0_loss: 4.4184 - output_1_loss: 2.9195 - output_2_loss: 2.5808 - val_loss: 14.9176 - val_output_0_loss: 6.0032 - val_output_1_loss: 4.5925 - val_output_2_loss: 4.3220\n",
      "Epoch 10/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.3705 - output_0_loss: 4.5359 - output_1_loss: 3.0878 - output_2_loss: 2.7468\n",
      "Epoch 00010: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22962.49 (0%:  0.00, 5%:  0.23, 25%:  0.57, 50%:  1.22, 75%:  3.53, 95%: 141726.20, 100%: 141793.48) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.4286 - output_0_loss: 4.5588 - output_1_loss: 3.1068 - output_2_loss: 2.7630 - val_loss: 15.1232 - val_output_0_loss: 6.0513 - val_output_1_loss: 4.6624 - val_output_2_loss: 4.4095\n",
      "Epoch 11/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1630 - output_0_loss: 4.4810 - output_1_loss: 3.0132 - output_2_loss: 2.6687\n",
      "Epoch 00011: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.74 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  3.56, 95%: 141658.78, 100%: 141793.48) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 10.1372 - output_0_loss: 4.4610 - output_1_loss: 3.0082 - output_2_loss: 2.6680 - val_loss: 14.9854 - val_output_0_loss: 5.9983 - val_output_1_loss: 4.6180 - val_output_2_loss: 4.3691\n",
      "Epoch 12/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9187 - output_0_loss: 4.3859 - output_1_loss: 2.9330 - output_2_loss: 2.5998\n",
      "Epoch 00012: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24516.41 (0%:  0.08, 5%:  0.22, 25%:  0.57, 50%:  1.26, 75%:  3.76, 95%: 141701.81, 100%: 141805.92) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 10.1408 - output_0_loss: 4.4780 - output_1_loss: 3.0004 - output_2_loss: 2.6624 - val_loss: 14.9915 - val_output_0_loss: 5.9934 - val_output_1_loss: 4.6221 - val_output_2_loss: 4.3760\n",
      "Epoch 13/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6921 - output_0_loss: 4.3032 - output_1_loss: 2.8599 - output_2_loss: 2.5290\n",
      "Epoch 00013: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21398.68 (0%:  0.00, 5%:  0.18, 25%:  0.56, 50%:  1.26, 75%:  3.23, 95%: 141626.45, 100%: 141789.25) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.7859 - output_0_loss: 4.3295 - output_1_loss: 2.8928 - output_2_loss: 2.5636 - val_loss: 15.0184 - val_output_0_loss: 6.0114 - val_output_1_loss: 4.6270 - val_output_2_loss: 4.3801\n",
      "Epoch 14/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.0311 - output_0_loss: 4.4312 - output_1_loss: 2.9675 - output_2_loss: 2.6324\n",
      "Epoch 00014: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.90 (0%:  0.00, 5%:  0.19, 25%:  0.57, 50%:  1.27, 75%:  3.69, 95%: 141691.64, 100%: 141805.62) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.9848 - output_0_loss: 4.4138 - output_1_loss: 2.9534 - output_2_loss: 2.6177 - val_loss: 14.9311 - val_output_0_loss: 5.9979 - val_output_1_loss: 4.5964 - val_output_2_loss: 4.3368\n",
      "Epoch 15/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.0785 - output_0_loss: 4.4784 - output_1_loss: 2.9650 - output_2_loss: 2.6351\n",
      "Epoch 00015: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21398.92 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.24, 75%:  3.34, 95%: 141626.39, 100%: 141789.20) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.55, 50%:  0.74, 75%:  0.82, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.0643 - output_0_loss: 4.4746 - output_1_loss: 2.9613 - output_2_loss: 2.6284 - val_loss: 14.8724 - val_output_0_loss: 5.9757 - val_output_1_loss: 4.5821 - val_output_2_loss: 4.3146\n",
      "Epoch 16/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9834 - output_0_loss: 4.4043 - output_1_loss: 2.9558 - output_2_loss: 2.6233 \n",
      "Epoch 00016: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22962.30 (0%:  0.00, 5%:  0.21, 25%:  0.58, 50%:  1.23, 75%:  3.62, 95%: 141701.74, 100%: 141805.62) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9536 - output_0_loss: 4.3930 - output_1_loss: 2.9454 - output_2_loss: 2.6152 - val_loss: 14.8078 - val_output_0_loss: 5.9500 - val_output_1_loss: 4.5577 - val_output_2_loss: 4.3001\n",
      "Epoch 17/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9697 - output_0_loss: 4.4321 - output_1_loss: 2.9396 - output_2_loss: 2.5980\n",
      "Epoch 00017: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24126.36 (0%:  0.08, 5%:  0.21, 25%:  0.58, 50%:  1.27, 75%:  3.84, 95%: 141681.55, 100%: 141805.36) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9095 - output_0_loss: 4.4074 - output_1_loss: 2.9214 - output_2_loss: 2.5807 - val_loss: 14.8677 - val_output_0_loss: 5.9701 - val_output_1_loss: 4.5791 - val_output_2_loss: 4.3186\n",
      "Epoch 18/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.2507 - output_0_loss: 4.5313 - output_1_loss: 3.0318 - output_2_loss: 2.6875\n",
      "Epoch 00018: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24516.75 (0%:  0.08, 5%:  0.18, 25%:  0.64, 50%:  1.32, 75%:  3.84, 95%: 141691.31, 100%: 141793.31) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 10.2894 - output_0_loss: 4.5523 - output_1_loss: 3.0421 - output_2_loss: 2.6950 - val_loss: 14.9801 - val_output_0_loss: 5.9910 - val_output_1_loss: 4.6193 - val_output_2_loss: 4.3698\n",
      "Epoch 19/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8484 - output_0_loss: 4.3919 - output_1_loss: 2.8964 - output_2_loss: 2.5601\n",
      "Epoch 00019: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.78 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.40, 75%:  4.69, 95%: 141691.44, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.40, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.8189 - output_0_loss: 4.3776 - output_1_loss: 2.8895 - output_2_loss: 2.5518 - val_loss: 15.0185 - val_output_0_loss: 6.0075 - val_output_1_loss: 4.6222 - val_output_2_loss: 4.3889\n",
      "Epoch 20/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8056 - output_0_loss: 4.3851 - output_1_loss: 2.8806 - output_2_loss: 2.5399\n",
      "Epoch 00020: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.75 (0%:  0.00, 5%:  0.18, 25%:  0.63, 50%:  1.29, 75%:  3.86, 95%: 141659.07, 100%: 141793.38) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8805 - output_0_loss: 4.4098 - output_1_loss: 2.9063 - output_2_loss: 2.5644 - val_loss: 14.9600 - val_output_0_loss: 5.9992 - val_output_1_loss: 4.5980 - val_output_2_loss: 4.3628\n",
      "Epoch 21/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8801 - output_0_loss: 4.3526 - output_1_loss: 2.9254 - output_2_loss: 2.6021\n",
      "Epoch 00021: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25293.98 (0%:  0.08, 5%:  0.21, 25%:  0.65, 50%:  1.32, 75%:  4.13, 95%: 141742.87, 100%: 141793.31) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9941 - output_0_loss: 4.4090 - output_1_loss: 2.9570 - output_2_loss: 2.6281 - val_loss: 14.9163 - val_output_0_loss: 5.9822 - val_output_1_loss: 4.5925 - val_output_2_loss: 4.3416\n",
      "Epoch 22/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7954 - output_0_loss: 4.3886 - output_1_loss: 2.8753 - output_2_loss: 2.5315\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.88 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.22, 75%:  4.18, 95%: 141685.50, 100%: 141793.09) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9662 - output_0_loss: 4.4607 - output_1_loss: 2.9286 - output_2_loss: 2.5770 - val_loss: 15.0385 - val_output_0_loss: 5.9972 - val_output_1_loss: 4.6429 - val_output_2_loss: 4.3984\n",
      "Epoch 23/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.0418 - output_0_loss: 4.4538 - output_1_loss: 2.9635 - output_2_loss: 2.6244\n",
      "Epoch 00023: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.62 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.22, 75%:  4.18, 95%: 141685.47, 100%: 141793.09) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.9389 - output_0_loss: 4.4144 - output_1_loss: 2.9308 - output_2_loss: 2.5937 - val_loss: 15.0411 - val_output_0_loss: 5.9974 - val_output_1_loss: 4.6440 - val_output_2_loss: 4.3997\n",
      "Epoch 24/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7319 - output_0_loss: 4.3487 - output_1_loss: 2.8546 - output_2_loss: 2.5286\n",
      "Epoch 00024: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26069.74 (0%:  0.08, 5%:  0.21, 25%:  0.63, 50%:  1.28, 75%:  3.70, 95%: 141685.48, 100%: 141793.09) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.50, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8530 - output_0_loss: 4.3935 - output_1_loss: 2.8945 - output_2_loss: 2.5650 - val_loss: 15.0420 - val_output_0_loss: 6.0001 - val_output_1_loss: 4.6436 - val_output_2_loss: 4.3983\n",
      "Epoch 25/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9250 - output_0_loss: 4.4073 - output_1_loss: 2.9277 - output_2_loss: 2.5901\n",
      "Epoch 00025: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22960.20 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.22, 75%:  3.65, 95%: 141685.58, 100%: 141793.14) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8378 - output_0_loss: 4.3758 - output_1_loss: 2.8997 - output_2_loss: 2.5623 - val_loss: 15.0577 - val_output_0_loss: 6.0095 - val_output_1_loss: 4.6469 - val_output_2_loss: 4.4013\n",
      "Epoch 26/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8129 - output_0_loss: 4.3856 - output_1_loss: 2.8818 - output_2_loss: 2.5455\n",
      "Epoch 00026: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21397.81 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.22, 75%:  3.29, 95%: 141625.07, 100%: 141789.14) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.55, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9818 - output_0_loss: 4.4463 - output_1_loss: 2.9366 - output_2_loss: 2.5989 - val_loss: 15.0528 - val_output_0_loss: 6.0075 - val_output_1_loss: 4.6429 - val_output_2_loss: 4.4023\n",
      "Epoch 27/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1278 - output_0_loss: 4.4607 - output_1_loss: 3.0031 - output_2_loss: 2.6641\n",
      "Epoch 00027: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24123.66 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.20, 75%:  3.79, 95%: 141643.84, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 10.1272 - output_0_loss: 4.4723 - output_1_loss: 2.9979 - output_2_loss: 2.6569 - val_loss: 15.0796 - val_output_0_loss: 6.0144 - val_output_1_loss: 4.6520 - val_output_2_loss: 4.4131\n",
      "Epoch 28/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1363 - output_0_loss: 4.5070 - output_1_loss: 2.9895 - output_2_loss: 2.6398\n",
      "Epoch 00028: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25680.63 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  4.03, 95%: 141659.01, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 10.1302 - output_0_loss: 4.5029 - output_1_loss: 2.9880 - output_2_loss: 2.6392 - val_loss: 15.0727 - val_output_0_loss: 6.0164 - val_output_1_loss: 4.6481 - val_output_2_loss: 4.4082\n",
      "Epoch 29/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9524 - output_0_loss: 4.4388 - output_1_loss: 2.9267 - output_2_loss: 2.5869\n",
      "Epoch 00029: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23737.64 (0%:  0.00, 5%:  0.18, 25%:  0.61, 50%:  1.26, 75%:  3.74, 95%: 141667.81, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.9048 - output_0_loss: 4.4105 - output_1_loss: 2.9174 - output_2_loss: 2.5769 - val_loss: 15.0829 - val_output_0_loss: 6.0150 - val_output_1_loss: 4.6532 - val_output_2_loss: 4.4147\n",
      "Epoch 30/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4758 - output_0_loss: 4.2391 - output_1_loss: 2.7795 - output_2_loss: 2.4573\n",
      "Epoch 00030: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.28 (0%:  0.00, 5%:  0.18, 25%:  0.64, 50%:  1.32, 75%:  3.88, 95%: 141685.68, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.72, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.5886 - output_0_loss: 4.2833 - output_1_loss: 2.8161 - output_2_loss: 2.4892 - val_loss: 15.0689 - val_output_0_loss: 6.0079 - val_output_1_loss: 4.6495 - val_output_2_loss: 4.4115\n",
      "Epoch 31/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7699 - output_0_loss: 4.3367 - output_1_loss: 2.8830 - output_2_loss: 2.5502\n",
      "Epoch 00031: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26069.05 (0%:  0.08, 5%:  0.18, 25%:  0.60, 50%:  1.23, 75%:  3.51, 95%: 141658.94, 100%: 141793.14) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8683 - output_0_loss: 4.3836 - output_1_loss: 2.9115 - output_2_loss: 2.5732 - val_loss: 15.0355 - val_output_0_loss: 6.0000 - val_output_1_loss: 4.6372 - val_output_2_loss: 4.3983\n",
      "Epoch 32/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9835 - output_0_loss: 4.4384 - output_1_loss: 2.9435 - output_2_loss: 2.6017\n",
      "Epoch 00032: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24123.31 (0%:  0.08, 5%:  0.19, 25%:  0.60, 50%:  1.26, 75%:  3.94, 95%: 141638.28, 100%: 141793.14) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.0184 - output_0_loss: 4.4502 - output_1_loss: 2.9552 - output_2_loss: 2.6130 - val_loss: 15.0239 - val_output_0_loss: 6.0002 - val_output_1_loss: 4.6315 - val_output_2_loss: 4.3922\n",
      "Epoch 33/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8920 - output_0_loss: 4.3714 - output_1_loss: 2.9283 - output_2_loss: 2.5922\n",
      "Epoch 00033: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.87 (0%:  0.00, 5%:  0.18, 25%:  0.59, 50%:  1.41, 75%:  4.97, 95%: 141685.65, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9451 - output_0_loss: 4.3921 - output_1_loss: 2.9448 - output_2_loss: 2.6082 - val_loss: 15.0237 - val_output_0_loss: 5.9997 - val_output_1_loss: 4.6331 - val_output_2_loss: 4.3909\n",
      "Epoch 34/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8035 - output_0_loss: 4.3749 - output_1_loss: 2.8895 - output_2_loss: 2.5391\n",
      "Epoch 00034: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.09 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.20, 75%:  3.71, 95%: 141643.74, 100%: 141793.25) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.50, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.7796 - output_0_loss: 4.3644 - output_1_loss: 2.8815 - output_2_loss: 2.5337 - val_loss: 15.0040 - val_output_0_loss: 5.9981 - val_output_1_loss: 4.6252 - val_output_2_loss: 4.3807\n",
      "Epoch 35/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9931 - output_0_loss: 4.4212 - output_1_loss: 2.9518 - output_2_loss: 2.6201\n",
      "Epoch 00035: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.67 (0%:  0.00, 5%:  0.18, 25%:  0.58, 50%:  1.41, 75%:  4.80, 95%: 141685.62, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.46, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8320 - output_0_loss: 4.3533 - output_1_loss: 2.9037 - output_2_loss: 2.5750 - val_loss: 14.9799 - val_output_0_loss: 5.9925 - val_output_1_loss: 4.6154 - val_output_2_loss: 4.3720\n",
      "Epoch 36/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8336 - output_0_loss: 4.3642 - output_1_loss: 2.9010 - output_2_loss: 2.5683\n",
      "Epoch 00036: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.53 (0%:  0.00, 5%:  0.18, 25%:  0.56, 50%:  1.23, 75%:  3.99, 95%: 141658.92, 100%: 141793.25) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.9155 - output_0_loss: 4.3995 - output_1_loss: 2.9264 - output_2_loss: 2.5897 - val_loss: 14.9589 - val_output_0_loss: 5.9855 - val_output_1_loss: 4.6076 - val_output_2_loss: 4.3657\n",
      "Epoch 37/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8383 - output_0_loss: 4.3894 - output_1_loss: 2.8931 - output_2_loss: 2.5557\n",
      "Epoch 00037: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.42 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  3.64, 95%: 141641.04, 100%: 141793.25) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.50, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8422 - output_0_loss: 4.3934 - output_1_loss: 2.8946 - output_2_loss: 2.5543 - val_loss: 14.9139 - val_output_0_loss: 5.9660 - val_output_1_loss: 4.5928 - val_output_2_loss: 4.3552\n",
      "Epoch 38/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9056 - output_0_loss: 4.4338 - output_1_loss: 2.9036 - output_2_loss: 2.5683 \n",
      "Epoch 00038: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.58 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.24, 75%:  4.81, 95%: 141667.80, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.01) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.0531 - output_0_loss: 4.4894 - output_1_loss: 2.9528 - output_2_loss: 2.6109 - val_loss: 14.9171 - val_output_0_loss: 5.9670 - val_output_1_loss: 4.5929 - val_output_2_loss: 4.3572\n",
      "Epoch 39/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5385 - output_0_loss: 4.2758 - output_1_loss: 2.7985 - output_2_loss: 2.4642\n",
      "Epoch 00039: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24123.69 (0%:  0.08, 5%:  0.21, 25%:  0.64, 50%:  1.27, 75%:  3.79, 95%: 141639.64, 100%: 141793.25) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.4809 - output_0_loss: 4.2445 - output_1_loss: 2.7832 - output_2_loss: 2.4531 - val_loss: 14.9329 - val_output_0_loss: 5.9678 - val_output_1_loss: 4.5993 - val_output_2_loss: 4.3658\n",
      "Epoch 40/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7427 - output_0_loss: 4.3421 - output_1_loss: 2.8663 - output_2_loss: 2.5342\n",
      "Epoch 00040: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.22 (0%:  0.08, 5%:  0.18, 25%:  0.62, 50%:  1.27, 75%:  3.82, 95%: 141667.70, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.8887 - output_0_loss: 4.4000 - output_1_loss: 2.9130 - output_2_loss: 2.5756 - val_loss: 14.9441 - val_output_0_loss: 5.9660 - val_output_1_loss: 4.6043 - val_output_2_loss: 4.3738\n",
      "Epoch 41/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8607 - output_0_loss: 4.3950 - output_1_loss: 2.9010 - output_2_loss: 2.5647\n",
      "Epoch 00041: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.31 (0%:  0.08, 5%:  0.18, 25%:  0.65, 50%:  1.35, 75%:  3.99, 95%: 141643.27, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.74, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8830 - output_0_loss: 4.3996 - output_1_loss: 2.9092 - output_2_loss: 2.5743 - val_loss: 14.9636 - val_output_0_loss: 5.9699 - val_output_1_loss: 4.6127 - val_output_2_loss: 4.3809\n",
      "Epoch 42/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7801 - output_0_loss: 4.3549 - output_1_loss: 2.8795 - output_2_loss: 2.5457\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21398.44 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  3.23, 95%: 141624.99, 100%: 141789.31) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.74, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.6923 - output_0_loss: 4.3156 - output_1_loss: 2.8538 - output_2_loss: 2.5229 - val_loss: 14.9793 - val_output_0_loss: 5.9820 - val_output_1_loss: 4.6143 - val_output_2_loss: 4.3830\n",
      "Epoch 43/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9466 - output_0_loss: 4.4160 - output_1_loss: 2.9347 - output_2_loss: 2.5959\n",
      "Epoch 00043: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.20 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.41, 75%:  4.79, 95%: 141685.62, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.73, 75%:  0.81, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.9523 - output_0_loss: 4.4284 - output_1_loss: 2.9332 - output_2_loss: 2.5907 - val_loss: 14.9631 - val_output_0_loss: 5.9774 - val_output_1_loss: 4.6089 - val_output_2_loss: 4.3768\n",
      "Epoch 44/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7418 - output_0_loss: 4.4043 - output_1_loss: 2.8447 - output_2_loss: 2.4928\n",
      "Epoch 00044: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.47 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  4.18, 95%: 141667.71, 100%: 141793.25) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.46, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.9270 - output_0_loss: 4.4710 - output_1_loss: 2.9040 - output_2_loss: 2.5520 - val_loss: 14.9777 - val_output_0_loss: 5.9796 - val_output_1_loss: 4.6139 - val_output_2_loss: 4.3842\n",
      "Epoch 45/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5983 - output_0_loss: 4.2740 - output_1_loss: 2.8292 - output_2_loss: 2.4951\n",
      "Epoch 00045: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.15 (0%:  0.08, 5%:  0.18, 25%:  0.64, 50%:  1.24, 75%:  3.81, 95%: 141667.76, 100%: 141793.25) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.7098 - output_0_loss: 4.3121 - output_1_loss: 2.8658 - output_2_loss: 2.5319 - val_loss: 14.9800 - val_output_0_loss: 5.9802 - val_output_1_loss: 4.6147 - val_output_2_loss: 4.3852\n",
      "Epoch 46/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4258 - output_0_loss: 4.2611 - output_1_loss: 2.7496 - output_2_loss: 2.4151\n",
      "Epoch 00046: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24514.91 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.26, 75%:  3.81, 95%: 141667.76, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.4801 - output_0_loss: 4.2704 - output_1_loss: 2.7727 - output_2_loss: 2.4370 - val_loss: 14.9628 - val_output_0_loss: 5.9750 - val_output_1_loss: 4.6095 - val_output_2_loss: 4.3783\n",
      "Epoch 47/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5147 - output_0_loss: 4.2641 - output_1_loss: 2.7926 - output_2_loss: 2.4580\n",
      "Epoch 00047: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21398.47 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.21, 75%:  3.21, 95%: 141624.99, 100%: 141789.30) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.74, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.3933 - output_0_loss: 4.1992 - output_1_loss: 2.7617 - output_2_loss: 2.4324 - val_loss: 14.9627 - val_output_0_loss: 5.9753 - val_output_1_loss: 4.6095 - val_output_2_loss: 4.3779\n",
      "Epoch 48/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9807 - output_0_loss: 4.4497 - output_1_loss: 2.9399 - output_2_loss: 2.5911\n",
      "Epoch 00048: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.07 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.25, 75%:  3.78, 95%: 141639.64, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9252 - output_0_loss: 4.4302 - output_1_loss: 2.9215 - output_2_loss: 2.5735 - val_loss: 14.9555 - val_output_0_loss: 5.9712 - val_output_1_loss: 4.6076 - val_output_2_loss: 4.3767\n",
      "Epoch 49/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8469 - output_0_loss: 4.3731 - output_1_loss: 2.9055 - output_2_loss: 2.5683\n",
      "Epoch 00049: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.70 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.25, 75%:  4.18, 95%: 141658.95, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9224 - output_0_loss: 4.4046 - output_1_loss: 2.9269 - output_2_loss: 2.5908 - val_loss: 14.9469 - val_output_0_loss: 5.9675 - val_output_1_loss: 4.6051 - val_output_2_loss: 4.3744\n",
      "Epoch 50/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4426 - output_0_loss: 4.2523 - output_1_loss: 2.7638 - output_2_loss: 2.4265\n",
      "Epoch 00050: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.43 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.21, 75%:  3.64, 95%: 141643.35, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.5277 - output_0_loss: 4.2863 - output_1_loss: 2.7895 - output_2_loss: 2.4518 - val_loss: 14.9379 - val_output_0_loss: 5.9637 - val_output_1_loss: 4.6023 - val_output_2_loss: 4.3719\n",
      "Epoch 51/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.2169 - output_0_loss: 4.5349 - output_1_loss: 3.0132 - output_2_loss: 2.6687\n",
      "Epoch 00051: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26069.71 (0%:  0.08, 5%:  0.18, 25%:  0.59, 50%:  1.26, 75%:  3.51, 95%: 141667.76, 100%: 141793.25) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.2332 - output_0_loss: 4.5433 - output_1_loss: 3.0167 - output_2_loss: 2.6732 - val_loss: 14.9501 - val_output_0_loss: 5.9703 - val_output_1_loss: 4.6058 - val_output_2_loss: 4.3741\n",
      "Epoch 52/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.0283 - output_0_loss: 4.4430 - output_1_loss: 2.9632 - output_2_loss: 2.6221\n",
      "Epoch 00052: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.68 (0%:  0.08, 5%:  0.18, 25%:  0.64, 50%:  1.34, 75%:  4.00, 95%: 141643.51, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.74, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.8905 - output_0_loss: 4.3867 - output_1_loss: 2.9204 - output_2_loss: 2.5834 - val_loss: 14.9501 - val_output_0_loss: 5.9704 - val_output_1_loss: 4.6062 - val_output_2_loss: 4.3735\n",
      "Epoch 53/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7460 - output_0_loss: 4.3564 - output_1_loss: 2.8679 - output_2_loss: 2.5217\n",
      "Epoch 00053: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.86 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.24, 75%:  4.11, 95%: 141667.80, 100%: 141793.25) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9903 - output_0_loss: 4.4552 - output_1_loss: 2.9436 - output_2_loss: 2.5915 - val_loss: 14.9376 - val_output_0_loss: 5.9674 - val_output_1_loss: 4.6017 - val_output_2_loss: 4.3685\n",
      "Epoch 54/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7408 - output_0_loss: 4.3644 - output_1_loss: 2.8597 - output_2_loss: 2.5168\n",
      "Epoch 00054: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.62 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.39, 75%:  4.76, 95%: 141685.60, 100%: 141793.31) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.46, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9411 - output_0_loss: 4.4476 - output_1_loss: 2.9207 - output_2_loss: 2.5728 - val_loss: 14.9293 - val_output_0_loss: 5.9646 - val_output_1_loss: 4.5990 - val_output_2_loss: 4.3657\n",
      "Epoch 55/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.2408 - output_0_loss: 4.5307 - output_1_loss: 3.0224 - output_2_loss: 2.6877\n",
      "Epoch 00055: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.56 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.24, 75%:  4.79, 95%: 141685.59, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.46, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.01) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.2629 - output_0_loss: 4.5486 - output_1_loss: 3.0262 - output_2_loss: 2.6881 - val_loss: 14.9415 - val_output_0_loss: 5.9685 - val_output_1_loss: 4.6028 - val_output_2_loss: 4.3702\n",
      "Epoch 56/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7558 - output_0_loss: 4.3534 - output_1_loss: 2.8698 - output_2_loss: 2.5325\n",
      "Epoch 00056: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.22 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.23, 75%:  4.79, 95%: 141685.59, 100%: 141793.25) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.46, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.01) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.7261 - output_0_loss: 4.3306 - output_1_loss: 2.8647 - output_2_loss: 2.5308 - val_loss: 14.9368 - val_output_0_loss: 5.9675 - val_output_1_loss: 4.6012 - val_output_2_loss: 4.3681\n",
      "Epoch 57/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9948 - output_0_loss: 4.4488 - output_1_loss: 2.9473 - output_2_loss: 2.5987\n",
      "Epoch 00057: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22960.92 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.22, 75%:  3.51, 95%: 141667.81, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.9209 - output_0_loss: 4.4222 - output_1_loss: 2.9236 - output_2_loss: 2.5751 - val_loss: 14.9403 - val_output_0_loss: 5.9688 - val_output_1_loss: 4.6018 - val_output_2_loss: 4.3697\n",
      "Epoch 58/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6406 - output_0_loss: 4.3143 - output_1_loss: 2.8300 - output_2_loss: 2.4964\n",
      "Epoch 00058: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.42 (0%:  0.08, 5%:  0.18, 25%:  0.64, 50%:  1.24, 75%:  3.81, 95%: 141658.53, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.4678 - output_0_loss: 4.2471 - output_1_loss: 2.7748 - output_2_loss: 2.4459 - val_loss: 14.9354 - val_output_0_loss: 5.9678 - val_output_1_loss: 4.6002 - val_output_2_loss: 4.3674\n",
      "Epoch 59/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1399 - output_0_loss: 4.4937 - output_1_loss: 2.9919 - output_2_loss: 2.6543\n",
      "Epoch 00059: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.15 (0%:  0.08, 5%:  0.18, 25%:  0.64, 50%:  1.32, 75%:  3.91, 95%: 141641.00, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.74, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 10.1776 - output_0_loss: 4.5247 - output_1_loss: 2.9985 - output_2_loss: 2.6544 - val_loss: 14.9350 - val_output_0_loss: 5.9674 - val_output_1_loss: 4.5997 - val_output_2_loss: 4.3679\n",
      "Epoch 60/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9122 - output_0_loss: 4.4124 - output_1_loss: 2.9226 - output_2_loss: 2.5771\n",
      "Epoch 00060: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.59 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.31, 75%:  3.90, 95%: 141667.76, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.9399 - output_0_loss: 4.4385 - output_1_loss: 2.9249 - output_2_loss: 2.5765 - val_loss: 14.9394 - val_output_0_loss: 5.9667 - val_output_1_loss: 4.6025 - val_output_2_loss: 4.3703\n",
      "Epoch 61/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8349 - output_0_loss: 4.3923 - output_1_loss: 2.8894 - output_2_loss: 2.5531\n",
      "Epoch 00061: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 19068.80 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.18, 75%:  2.95, 95%: 141659.00, 100%: 141793.19) \n",
      "confidence - mean:  0.63 (0%:  0.00, 5%:  0.01, 25%:  0.59, 50%:  0.74, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8205 - output_0_loss: 4.3861 - output_1_loss: 2.8851 - output_2_loss: 2.5492 - val_loss: 14.9434 - val_output_0_loss: 5.9665 - val_output_1_loss: 4.6048 - val_output_2_loss: 4.3721\n",
      "Epoch 62/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9124 - output_0_loss: 4.4133 - output_1_loss: 2.9177 - output_2_loss: 2.5813\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 19069.09 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.18, 75%:  2.95, 95%: 141667.82, 100%: 141793.19) \n",
      "confidence - mean:  0.63 (0%:  0.00, 5%:  0.01, 25%:  0.59, 50%:  0.74, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8854 - output_0_loss: 4.4053 - output_1_loss: 2.9069 - output_2_loss: 2.5732 - val_loss: 14.9529 - val_output_0_loss: 5.9678 - val_output_1_loss: 4.6085 - val_output_2_loss: 4.3766\n",
      "Epoch 63/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7399 - output_0_loss: 4.3311 - output_1_loss: 2.8754 - output_2_loss: 2.5333\n",
      "Epoch 00063: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.71 (0%:  0.08, 5%:  0.18, 25%:  0.64, 50%:  1.32, 75%:  3.99, 95%: 141643.36, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.74, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.5856 - output_0_loss: 4.2579 - output_1_loss: 2.8314 - output_2_loss: 2.4962 - val_loss: 14.9528 - val_output_0_loss: 5.9670 - val_output_1_loss: 4.6081 - val_output_2_loss: 4.3778\n",
      "Epoch 64/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.4518 - output_0_loss: 4.5919 - output_1_loss: 3.1028 - output_2_loss: 2.7572\n",
      "Epoch 00064: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.51 (0%:  0.08, 5%:  0.18, 25%:  0.60, 50%:  1.26, 75%:  3.77, 95%: 141658.97, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 10.4191 - output_0_loss: 4.5881 - output_1_loss: 3.0899 - output_2_loss: 2.7412 - val_loss: 14.9586 - val_output_0_loss: 5.9698 - val_output_1_loss: 4.6092 - val_output_2_loss: 4.3796\n",
      "Epoch 65/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7537 - output_0_loss: 4.3571 - output_1_loss: 2.8688 - output_2_loss: 2.5278\n",
      "Epoch 00065: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.83 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.31, 75%:  3.99, 95%: 141667.85, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8450 - output_0_loss: 4.3879 - output_1_loss: 2.8987 - output_2_loss: 2.5584 - val_loss: 14.9342 - val_output_0_loss: 5.9610 - val_output_1_loss: 4.6015 - val_output_2_loss: 4.3718\n",
      "Epoch 66/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4310 - output_0_loss: 4.2211 - output_1_loss: 2.7700 - output_2_loss: 2.4400\n",
      "Epoch 00066: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.53 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  3.62, 95%: 141640.98, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.4546 - output_0_loss: 4.2264 - output_1_loss: 2.7796 - output_2_loss: 2.4485 - val_loss: 14.9650 - val_output_0_loss: 5.9722 - val_output_1_loss: 4.6117 - val_output_2_loss: 4.3811\n",
      "Epoch 67/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6737 - output_0_loss: 4.3218 - output_1_loss: 2.8465 - output_2_loss: 2.5054\n",
      "Epoch 00067: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.80 (0%:  0.08, 5%:  0.18, 25%:  0.60, 50%:  1.27, 75%:  3.71, 95%: 141667.89, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.6286 - output_0_loss: 4.3082 - output_1_loss: 2.8297 - output_2_loss: 2.4906 - val_loss: 14.9662 - val_output_0_loss: 5.9713 - val_output_1_loss: 4.6125 - val_output_2_loss: 4.3825\n",
      "Epoch 68/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4372 - output_0_loss: 4.2374 - output_1_loss: 2.7684 - output_2_loss: 2.4314\n",
      "Epoch 00068: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.75 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.25, 75%:  3.77, 95%: 141667.85, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.5323 - output_0_loss: 4.2789 - output_1_loss: 2.7964 - output_2_loss: 2.4570 - val_loss: 14.9499 - val_output_0_loss: 5.9643 - val_output_1_loss: 4.6074 - val_output_2_loss: 4.3782\n",
      "Epoch 69/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6335 - output_0_loss: 4.2750 - output_1_loss: 2.8462 - output_2_loss: 2.5123\n",
      "Epoch 00069: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.45 (0%:  0.08, 5%:  0.18, 25%:  0.63, 50%:  1.28, 75%:  3.78, 95%: 141639.63, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.5889 - output_0_loss: 4.2569 - output_1_loss: 2.8327 - output_2_loss: 2.4993 - val_loss: 14.9472 - val_output_0_loss: 5.9644 - val_output_1_loss: 4.6060 - val_output_2_loss: 4.3767\n",
      "Epoch 70/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6460 - output_0_loss: 4.3066 - output_1_loss: 2.8329 - output_2_loss: 2.5065\n",
      "Epoch 00070: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.45 (0%:  0.08, 5%:  0.18, 25%:  0.63, 50%:  1.27, 75%:  3.78, 95%: 141639.59, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.50, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.7234 - output_0_loss: 4.3376 - output_1_loss: 2.8588 - output_2_loss: 2.5270 - val_loss: 14.9472 - val_output_0_loss: 5.9677 - val_output_1_loss: 4.6046 - val_output_2_loss: 4.3748\n",
      "Epoch 71/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8772 - output_0_loss: 4.3875 - output_1_loss: 2.9118 - output_2_loss: 2.5779\n",
      "Epoch 00071: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22960.92 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.23, 75%:  3.48, 95%: 141667.89, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8712 - output_0_loss: 4.3989 - output_1_loss: 2.9028 - output_2_loss: 2.5695 - val_loss: 14.9336 - val_output_0_loss: 5.9614 - val_output_1_loss: 4.6010 - val_output_2_loss: 4.3713\n",
      "Epoch 72/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9054 - output_0_loss: 4.4047 - output_1_loss: 2.9173 - output_2_loss: 2.5834\n",
      "Epoch 00072: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.26 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.40, 75%:  4.84, 95%: 141667.84, 100%: 141793.19) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.7899 - output_0_loss: 4.3603 - output_1_loss: 2.8808 - output_2_loss: 2.5488 - val_loss: 14.9522 - val_output_0_loss: 5.9670 - val_output_1_loss: 4.6071 - val_output_2_loss: 4.3781\n",
      "Epoch 73/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7731 - output_0_loss: 4.3698 - output_1_loss: 2.8661 - output_2_loss: 2.5371\n",
      "Epoch 00073: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.26 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.40, 75%:  4.84, 95%: 141667.84, 100%: 141793.19) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.6592 - output_0_loss: 4.3209 - output_1_loss: 2.8330 - output_2_loss: 2.5053 - val_loss: 14.9280 - val_output_0_loss: 5.9597 - val_output_1_loss: 4.5994 - val_output_2_loss: 4.3690\n",
      "Epoch 74/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8030 - output_0_loss: 4.3776 - output_1_loss: 2.8846 - output_2_loss: 2.5409\n",
      "Epoch 00074: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.79 (0%:  0.00, 5%:  0.18, 25%:  0.60, 50%:  1.28, 75%:  3.70, 95%: 141667.85, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.7243 - output_0_loss: 4.3492 - output_1_loss: 2.8591 - output_2_loss: 2.5161 - val_loss: 14.9333 - val_output_0_loss: 5.9640 - val_output_1_loss: 4.6002 - val_output_2_loss: 4.3691\n",
      "Epoch 75/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1845 - output_0_loss: 4.5137 - output_1_loss: 3.0039 - output_2_loss: 2.6668\n",
      "Epoch 00075: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.80 (0%:  0.00, 5%:  0.18, 25%:  0.58, 50%:  1.28, 75%:  3.71, 95%: 141667.81, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.9664 - output_0_loss: 4.4234 - output_1_loss: 2.9381 - output_2_loss: 2.6049 - val_loss: 14.9140 - val_output_0_loss: 5.9584 - val_output_1_loss: 4.5936 - val_output_2_loss: 4.3620\n",
      "Epoch 76/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7977 - output_0_loss: 4.3669 - output_1_loss: 2.8851 - output_2_loss: 2.5457\n",
      "Epoch 00076: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22960.92 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.21, 75%:  3.51, 95%: 141667.81, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.7808 - output_0_loss: 4.3624 - output_1_loss: 2.8790 - output_2_loss: 2.5394 - val_loss: 14.9120 - val_output_0_loss: 5.9578 - val_output_1_loss: 4.5927 - val_output_2_loss: 4.3615\n",
      "Epoch 77/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8700 - output_0_loss: 4.4080 - output_1_loss: 2.9027 - output_2_loss: 2.5593\n",
      "Epoch 00077: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26071.20 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.24, 75%:  4.82, 95%: 141667.76, 100%: 141793.19) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.01) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8077 - output_0_loss: 4.3825 - output_1_loss: 2.8828 - output_2_loss: 2.5424 - val_loss: 14.9107 - val_output_0_loss: 5.9579 - val_output_1_loss: 4.5918 - val_output_2_loss: 4.3609\n",
      "Epoch 78/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7541 - output_0_loss: 4.3404 - output_1_loss: 2.8713 - output_2_loss: 2.5424\n",
      "Epoch 00078: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 19069.08 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.17, 75%:  2.95, 95%: 141667.76, 100%: 141793.19) \n",
      "confidence - mean:  0.63 (0%:  0.00, 5%:  0.01, 25%:  0.59, 50%:  0.74, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.7375 - output_0_loss: 4.3350 - output_1_loss: 2.8654 - output_2_loss: 2.5371 - val_loss: 14.9034 - val_output_0_loss: 5.9558 - val_output_1_loss: 4.5895 - val_output_2_loss: 4.3581\n",
      "Epoch 79/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6669 - output_0_loss: 4.3415 - output_1_loss: 2.8357 - output_2_loss: 2.4897\n",
      "Epoch 00079: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.24 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.25, 75%:  3.79, 95%: 141658.54, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.54, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.6313 - output_0_loss: 4.3256 - output_1_loss: 2.8252 - output_2_loss: 2.4805 - val_loss: 14.8914 - val_output_0_loss: 5.9526 - val_output_1_loss: 4.5854 - val_output_2_loss: 4.3534\n",
      "Epoch 80/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8240 - output_0_loss: 4.3673 - output_1_loss: 2.8972 - output_2_loss: 2.5595\n",
      "Epoch 00080: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.82 (0%:  0.00, 5%:  0.18, 25%:  0.58, 50%:  1.21, 75%:  3.64, 95%: 141643.48, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.7459 - output_0_loss: 4.3414 - output_1_loss: 2.8694 - output_2_loss: 2.5351 - val_loss: 14.9091 - val_output_0_loss: 5.9589 - val_output_1_loss: 4.5911 - val_output_2_loss: 4.3591\n",
      "Epoch 81/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5685 - output_0_loss: 4.3198 - output_1_loss: 2.7941 - output_2_loss: 2.4547\n",
      "Epoch 00081: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.48 (0%:  0.00, 5%:  0.18, 25%:  0.64, 50%:  1.31, 75%:  3.93, 95%: 141643.48, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.6805 - output_0_loss: 4.3694 - output_1_loss: 2.8289 - output_2_loss: 2.4823 - val_loss: 14.9060 - val_output_0_loss: 5.9577 - val_output_1_loss: 4.5903 - val_output_2_loss: 4.3579\n",
      "Epoch 82/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8825 - output_0_loss: 4.4004 - output_1_loss: 2.9094 - output_2_loss: 2.5727\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.79 (0%:  0.00, 5%:  0.18, 25%:  0.60, 50%:  1.25, 75%:  3.77, 95%: 141667.72, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8878 - output_0_loss: 4.3955 - output_1_loss: 2.9135 - output_2_loss: 2.5787 - val_loss: 14.9060 - val_output_0_loss: 5.9570 - val_output_1_loss: 4.5911 - val_output_2_loss: 4.3579\n",
      "Epoch 83/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7499 - output_0_loss: 4.3734 - output_1_loss: 2.8664 - output_2_loss: 2.5101\n",
      "Epoch 00083: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.62 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.24, 75%:  3.64, 95%: 141667.72, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8388 - output_0_loss: 4.4080 - output_1_loss: 2.8944 - output_2_loss: 2.5364 - val_loss: 14.9079 - val_output_0_loss: 5.9587 - val_output_1_loss: 4.5916 - val_output_2_loss: 4.3576\n",
      "Epoch 84/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8959 - output_0_loss: 4.3935 - output_1_loss: 2.9255 - output_2_loss: 2.5769\n",
      "Epoch 00084: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.47 (0%:  0.00, 5%:  0.18, 25%:  0.61, 50%:  1.25, 75%:  3.81, 95%: 141667.72, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8593 - output_0_loss: 4.3723 - output_1_loss: 2.9151 - output_2_loss: 2.5719 - val_loss: 14.9168 - val_output_0_loss: 5.9623 - val_output_1_loss: 4.5943 - val_output_2_loss: 4.3603\n",
      "Epoch 85/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6409 - output_0_loss: 4.2889 - output_1_loss: 2.8417 - output_2_loss: 2.5104\n",
      "Epoch 00085: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.84 (0%:  0.00, 5%:  0.18, 25%:  0.64, 50%:  1.31, 75%:  3.94, 95%: 141667.72, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.72, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.6717 - output_0_loss: 4.3066 - output_1_loss: 2.8498 - output_2_loss: 2.5153 - val_loss: 14.9289 - val_output_0_loss: 5.9658 - val_output_1_loss: 4.5983 - val_output_2_loss: 4.3649\n",
      "Epoch 86/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8404 - output_0_loss: 4.4086 - output_1_loss: 2.8885 - output_2_loss: 2.5433\n",
      "Epoch 00086: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24123.93 (0%:  0.08, 5%:  0.18, 25%:  0.63, 50%:  1.25, 75%:  3.82, 95%: 141638.48, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.7785 - output_0_loss: 4.3836 - output_1_loss: 2.8691 - output_2_loss: 2.5258 - val_loss: 14.9183 - val_output_0_loss: 5.9631 - val_output_1_loss: 4.5947 - val_output_2_loss: 4.3604\n",
      "Epoch 87/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8951 - output_0_loss: 4.4304 - output_1_loss: 2.9021 - output_2_loss: 2.5627\n",
      "Epoch 00087: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.51 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.24, 75%:  4.01, 95%: 141658.98, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.7510 - output_0_loss: 4.3674 - output_1_loss: 2.8595 - output_2_loss: 2.5242 - val_loss: 14.9112 - val_output_0_loss: 5.9613 - val_output_1_loss: 4.5923 - val_output_2_loss: 4.3576\n",
      "Epoch 88/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4952 - output_0_loss: 4.2561 - output_1_loss: 2.7861 - output_2_loss: 2.4530\n",
      "Epoch 00088: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 23738.80 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.26, 75%:  3.77, 95%: 141667.72, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.51, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.4982 - output_0_loss: 4.2608 - output_1_loss: 2.7851 - output_2_loss: 2.4522 - val_loss: 14.9085 - val_output_0_loss: 5.9601 - val_output_1_loss: 4.5917 - val_output_2_loss: 4.3567\n",
      "Epoch 89/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8480 - output_0_loss: 4.3828 - output_1_loss: 2.9000 - output_2_loss: 2.5653\n",
      "Epoch 00089: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.02 (0%:  0.08, 5%:  0.18, 25%:  0.60, 50%:  1.24, 75%:  3.62, 95%: 141658.98, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8148 - output_0_loss: 4.3605 - output_1_loss: 2.8939 - output_2_loss: 2.5604 - val_loss: 14.9160 - val_output_0_loss: 5.9643 - val_output_1_loss: 4.5932 - val_output_2_loss: 4.3586\n",
      "Epoch 90/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.4881 - output_0_loss: 4.2620 - output_1_loss: 2.7789 - output_2_loss: 2.4472\n",
      "Epoch 00090: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 22960.33 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.20, 75%:  3.51, 95%: 141658.98, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.5329 - output_0_loss: 4.2677 - output_1_loss: 2.7976 - output_2_loss: 2.4676 - val_loss: 14.9211 - val_output_0_loss: 5.9654 - val_output_1_loss: 4.5960 - val_output_2_loss: 4.3597\n",
      "Epoch 91/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7680 - output_0_loss: 4.3618 - output_1_loss: 2.8740 - output_2_loss: 2.5322\n",
      "Epoch 00091: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.31 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.25, 75%:  3.62, 95%: 141667.81, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.8318 - output_0_loss: 4.3987 - output_1_loss: 2.8884 - output_2_loss: 2.5446 - val_loss: 14.9257 - val_output_0_loss: 5.9649 - val_output_1_loss: 4.5980 - val_output_2_loss: 4.3628\n",
      "Epoch 92/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5410 - output_0_loss: 4.2750 - output_1_loss: 2.8008 - output_2_loss: 2.4652\n",
      "Epoch 00092: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 21398.55 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.22, 75%:  3.25, 95%: 141625.07, 100%: 141789.30) \n",
      "confidence - mean:  0.62 (0%:  0.00, 5%:  0.01, 25%:  0.55, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.5327 - output_0_loss: 4.2647 - output_1_loss: 2.7998 - output_2_loss: 2.4682 - val_loss: 14.9411 - val_output_0_loss: 5.9692 - val_output_1_loss: 4.6033 - val_output_2_loss: 4.3686\n",
      "Epoch 93/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.8845 - output_0_loss: 4.3984 - output_1_loss: 2.9129 - output_2_loss: 2.5732\n",
      "Epoch 00093: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25681.21 (0%:  0.08, 5%:  0.18, 25%:  0.57, 50%:  1.24, 75%:  4.16, 95%: 141643.56, 100%: 141793.27) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.47, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.7376 - output_0_loss: 4.3331 - output_1_loss: 2.8694 - output_2_loss: 2.5351 - val_loss: 14.9481 - val_output_0_loss: 5.9718 - val_output_1_loss: 4.6054 - val_output_2_loss: 4.3709\n",
      "Epoch 94/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.6476 - output_0_loss: 4.3150 - output_1_loss: 2.8342 - output_2_loss: 2.4985\n",
      "Epoch 00094: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.67 (0%:  0.08, 5%:  0.18, 25%:  0.60, 50%:  1.39, 75%:  4.82, 95%: 141658.93, 100%: 141793.19) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.46, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 9.8008 - output_0_loss: 4.3814 - output_1_loss: 2.8795 - output_2_loss: 2.5399 - val_loss: 14.9328 - val_output_0_loss: 5.9673 - val_output_1_loss: 4.5999 - val_output_2_loss: 4.3656\n",
      "Epoch 95/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5957 - output_0_loss: 4.2993 - output_1_loss: 2.8174 - output_2_loss: 2.4790\n",
      "Epoch 00095: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25291.82 (0%:  0.00, 5%:  0.18, 25%:  0.63, 50%:  1.23, 75%:  3.81, 95%: 141641.05, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.5841 - output_0_loss: 4.2818 - output_1_loss: 2.8178 - output_2_loss: 2.4845 - val_loss: 14.9398 - val_output_0_loss: 5.9698 - val_output_1_loss: 4.6019 - val_output_2_loss: 4.3682\n",
      "Epoch 96/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.3275 - output_0_loss: 4.2014 - output_1_loss: 2.7311 - output_2_loss: 2.3949\n",
      "Epoch 00096: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25291.85 (0%:  0.00, 5%:  0.18, 25%:  0.61, 50%:  1.25, 75%:  3.81, 95%: 141641.05, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.3646 - output_0_loss: 4.2186 - output_1_loss: 2.7418 - output_2_loss: 2.4043 - val_loss: 14.9300 - val_output_0_loss: 5.9638 - val_output_1_loss: 4.5994 - val_output_2_loss: 4.3667\n",
      "Epoch 97/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.5006 - output_0_loss: 4.2362 - output_1_loss: 2.7963 - output_2_loss: 2.4681\n",
      "Epoch 00097: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.33 (0%:  0.08, 5%:  0.18, 25%:  0.58, 50%:  1.24, 75%:  3.62, 95%: 141658.91, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.52, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.4947 - output_0_loss: 4.2284 - output_1_loss: 2.7971 - output_2_loss: 2.4693 - val_loss: 14.9440 - val_output_0_loss: 5.9672 - val_output_1_loss: 4.6039 - val_output_2_loss: 4.3729\n",
      "Epoch 98/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9039 - output_0_loss: 4.3994 - output_1_loss: 2.9203 - output_2_loss: 2.5842\n",
      "Epoch 00098: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24124.12 (0%:  0.00, 5%:  0.18, 25%:  0.61, 50%:  1.25, 75%:  3.81, 95%: 141638.52, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.49, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.8383 - output_0_loss: 4.3847 - output_1_loss: 2.8955 - output_2_loss: 2.5582 - val_loss: 14.9520 - val_output_0_loss: 5.9714 - val_output_1_loss: 4.6065 - val_output_2_loss: 4.3742\n",
      "Epoch 99/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.7450 - output_0_loss: 4.3429 - output_1_loss: 2.8705 - output_2_loss: 2.5316\n",
      "Epoch 00099: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 26070.69 (0%:  0.00, 5%:  0.18, 25%:  0.58, 50%:  1.39, 75%:  4.68, 95%: 141658.92, 100%: 141793.19) \n",
      "confidence - mean:  0.59 (0%:  0.00, 5%:  0.01, 25%:  0.45, 50%:  0.73, 75%:  0.82, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.6241 - output_0_loss: 4.2932 - output_1_loss: 2.8337 - output_2_loss: 2.4972 - val_loss: 14.9283 - val_output_0_loss: 5.9653 - val_output_1_loss: 4.5979 - val_output_2_loss: 4.3651\n",
      "Epoch 100/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.3758 - output_0_loss: 4.1850 - output_1_loss: 2.7607 - output_2_loss: 2.4301\n",
      "Epoch 00100: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 19068.45 (0%:  0.00, 5%:  0.18, 25%:  0.57, 50%:  1.15, 75%:  2.96, 95%: 141658.90, 100%: 141793.19) \n",
      "confidence - mean:  0.63 (0%:  0.00, 5%:  0.01, 25%:  0.59, 50%:  0.74, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 336s 17s/step - loss: 9.5266 - output_0_loss: 4.2518 - output_1_loss: 2.8051 - output_2_loss: 2.4698 - val_loss: 14.9377 - val_output_0_loss: 5.9675 - val_output_1_loss: 4.6008 - val_output_2_loss: 4.3693\n",
      "Epoch 101/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 9.9499 - output_0_loss: 4.4293 - output_1_loss: 2.9269 - output_2_loss: 2.5937\n",
      "Epoch 00101: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 24515.50 (0%:  0.08, 5%:  0.18, 25%:  0.61, 50%:  1.31, 75%:  3.97, 95%: 141658.90, 100%: 141793.19) \n",
      "confidence - mean:  0.60 (0%:  0.00, 5%:  0.01, 25%:  0.48, 50%:  0.73, 75%:  0.82, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 335s 17s/step - loss: 9.7967 - output_0_loss: 4.3711 - output_1_loss: 2.8767 - output_2_loss: 2.5489 - val_loss: 14.9298 - val_output_0_loss: 5.9654 - val_output_1_loss: 4.5986 - val_output_2_loss: 4.3658\n",
      "Epoch 102/1000\n",
      "19/20 [===========================>..] - ETA: 16s - loss: 10.1659 - output_0_loss: 4.4966 - output_1_loss: 3.0054 - output_2_loss: 2.6639\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 14.77573\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 25292.13 (0%:  0.00, 5%:  0.20, 25%:  0.61, 50%:  1.22, 75%:  3.80, 95%: 141641.00, 100%: 141793.19) \n",
      "confidence - mean:  0.61 (0%:  0.00, 5%:  0.01, 25%:  0.53, 50%:  0.73, 75%:  0.83, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "20/20 [==============================] - 334s 17s/step - loss: 10.1489 - output_0_loss: 4.4958 - output_1_loss: 2.9981 - output_2_loss: 2.6550 - val_loss: 14.9268 - val_output_0_loss: 5.9643 - val_output_1_loss: 4.5983 - val_output_2_loss: 4.3642\n",
      "Epoch 00102: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    batch_size=20,\n",
    "    validation_batch_size=7,\n",
    "    callbacks=callbacks,\n",
    "    epochs=1000,\n",
    "    n_workers=8,\n",
    "    steps_per_epoch=20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
